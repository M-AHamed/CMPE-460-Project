{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoaVQa39Qg-2"
      },
      "source": [
        "### Start from here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "FsemivlgXABk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.set_floatx('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NzylSfJqXB5k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"C:\\\\Users\\\\Mohammad\\\\Desktop\\\\Uni\\\\Uni work\\\\Year 4\\\\Term 7, fall 2022\\\\CMPE 460 Deep Learning\\project\\\\CMPE-460-Project\\\\dataset\\\\car_price_prediction.csv\")\n",
        "\n",
        "\n",
        "# drop rows where the price is less than 100\n",
        "data = data[data['Price'] >= 100]\n",
        "data = data[~data['Model'].isin([\"GONOW\",\"IVECO DAYLY\"])]\n",
        "\n",
        "\n",
        "\n",
        "# Drop the totalPrice column\n",
        "data = data.drop('totalPrice', axis=1)\n",
        "data = data.drop('Wheel', axis=1)\n",
        "data = data.drop('no-tax', axis=1)\n",
        "data = data.drop('Engine volume', axis=1)\n",
        "\n",
        "data = data.drop(\"ID\", axis=1)\n",
        "\n",
        "data['Doors'] = data['Doors'].replace({'-May':'','-Mar':''}, regex=True)\n",
        "data['Doors'] = data['Doors'].str.replace('>5','5')\n",
        "\n",
        "# Drop rows with missing or empty values in the \"Doors\" column\n",
        "data = data[data['Doors'].str.strip() !='']\n",
        "data['Doors'] = data['Doors'].astype(int)\n",
        "\n",
        "data['Doors'] = data['Doors'].astype(int)\n",
        "\n",
        "# Gear box editing\n",
        "data['Gear box type'] = data['Gear box type'].replace({'Automatic': 1, 'Tiptronic': 2,'Variator':3, 'Manual':4})\n",
        "data = data[data['Gear box type'].isin([1,2,3,4])]\n",
        "\n",
        "data[\"Gear box type\"] = data[\"Gear box type\"].astype(int)\n",
        "\n",
        "# 'Automatic' is changed to 1\n",
        "# 'Tiptronic' is changed to 2\n",
        "# 'Variator' is changed to 3\n",
        "# 'Manual' is changed to 4\n",
        "\n",
        "\n",
        "# Replace values in the \"Leather interior\" column based on conditions\n",
        "data[\"Leather interior\"] = data[\"Leather interior\"].replace({\"Yes\": 1, \"No\": 0}) # Yes is 1; No is 0\n",
        "# keep the rows where the value of \"Leather interior\" is 0 or 1\n",
        "data = data[data[\"Leather interior\"].apply(lambda x: x in [0, 1])]\n",
        "\n",
        "\n",
        "# fuel type edit\n",
        "data[\"Fuel type\"] = data[\"Fuel type\"].replace({\"Hybrid\":1, \"Petrol\":2,\"Diesel\":3,\"CNG\":4,\"Plug-in Hybrid\":5,\"LPG\":6,\"Hydrogen\":7})\n",
        "allowed_fuel_types = [1, 2, 3, 4, 5, 6, 7]\n",
        "data = data[data[\"Fuel type\"].apply(lambda x: x in allowed_fuel_types)]\n",
        "\n",
        "# 'Hybrid' is changed to 1,\n",
        "# 'Petrol' is changed to 2, \n",
        "# 'Diesel' is changed to 3, \n",
        "# 'CNG' is changed to 4, \n",
        "# 'Plug-in Hybrid' is changed to 5, \n",
        "# 'LPG' is changed to 6,\n",
        "# 'Hydrogen' is changed to 7\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "y270nIi73Or1"
      },
      "outputs": [],
      "source": [
        "# Mapping\n",
        "\n",
        "data[\"Manufacturer\"] = data[\"Manufacturer\"].replace({\"LEXUS\":1, \"CHEVROLET\":2,\"GREATWALL\":3,\"HONDA\":4,\"FORD\":5,\"HYUNDAI\":6,\"TOYOTA\":7,\n",
        "                                                     \"MERCEDES-BENZ\":8, \"OPEL\":9,\"PORSCHE\":10,\"BMW\":11,\"JEEP\":12,\"VOLKSWAGEN\":13,\"AUDI\":14,\n",
        "                                                     \"RENAULT\":15, \"NISSAN\":16,\"SUBARU\":17,\"DAEWOO\":18,\"KIA\":19,\"MITSUBISHI\":20,\"SSANGYONG\":21,\n",
        "                                                     \"MAZDA\":22, \"GMC\":23,\"FIAT\":24,\"INFINITI\":25,\"ALFA ROMEO\":26,\"SUZUKI\":27,\"ACURA\":28,\n",
        "                                                     \"LINCOLN\":29, \"VAZ\":30,\"GAZ\":31,\"CITROEN\":32,\"LAND ROVER\":33,\"MINI\":34,\"DODGE\":35,\n",
        "                                                     \"CHRYSLER\":36, \"JAGUAR\":37,\"ISUZU\":38,\"SKODA\":39,\"DAIHATSU\":40,\"BUICK\":41,\"TESLA\":42,\n",
        "                                                     \"CADILLAC\":43, \"PEUGEOT\":44,\"BENTLEY\":45,\"VOLVO\":46,\"HAVAL\":47,\"HUMMER\":48,\"SCION\":49,\n",
        "                                                     \"UAZ\":50, \"MERCURY\":51,\"ZAZ\":52,\"ROVER\":53,\"SEAT\":54,\"LANCIA\":55,\"MOSKVICH\":56,\n",
        "                                                     \"MASERATI\":57, \"FERRARI\":58,\"SAAB\":59,\"LAMBORGHINI\":60,\"PONTIAC\":61,\"SATURN\":62,\"ASTON MARTIN\":63})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QDm5L0ceoDwP"
      },
      "outputs": [],
      "source": [
        "# Remove \"KM\"\n",
        "data[\"Mileage\"] = data[\"Mileage\"].str.replace(\"km\",\"\")\n",
        "data[\"Mileage\"] = data[\"Mileage\"].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "w69zpvwzBIOh"
      },
      "outputs": [],
      "source": [
        "data[\"Category\"] = data[\"Category\"].replace({\"Jeep\":1, \"Hatchback\":2,\"Sedan\":3,\"Microbus\":4,\"Goods wagon\":5,\"Universal\":6,\"Coupe\":7,\n",
        "                                             \"Minivan\":8, \"Cabriolet\":9,\"Limousine\":10,\"Pickup\":11})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FAqu17dBCMXJ"
      },
      "outputs": [],
      "source": [
        "# data[\"Color\"] = data[\"Color\"].replace({\"Silver\":1, \"Black\":2,\"White\":3,\"Grey\":4,\"Blue\":5,\"Green\":6,\"Red\":7,\n",
        "#                                                      \"Sky blue\":8, \"Orange\":9,\"Yellow\":10,\"Golden\":11,\"Beige\":12,\"Brown\":13,\"Carnelian red\":14,\n",
        "#                                                      \"Purple\":15, \"Pink\":16})\n",
        "\n",
        "# data = pd.get_dummies(data, columns=[\"Color\"])\n",
        "\n",
        "\n",
        "data = data.drop('Color', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "zQ8CH2hhDfBa"
      },
      "outputs": [],
      "source": [
        "data[\"Drive wheels\"] = data[\"Drive wheels\"].replace({\"4x4\":1, \"Front\":2,\"Rear\":3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "app2xqxfszs-"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the encoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the \"Model\" feature\n",
        "encoder.fit(data[\"Model\"])\n",
        "\n",
        "# Transform the \"Model\" feature to numeric\n",
        "data[\"Model\"] = encoder.transform(data[\"Model\"])\n",
        "\n",
        "\n",
        "# Initialize the encoder\n",
        "encoder1 = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the \"Model\" feature\n",
        "encoder1.fit(data[\"Manufacturer\"])\n",
        "\n",
        "# Transform the \"Model\" feature to numeric\n",
        "data[\"Manufacturer\"] = encoder1.transform(data[\"Manufacturer\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "qO-FIha7A4e9"
      },
      "outputs": [],
      "source": [
        "# Cat_types = data[\"Manufacturer\"].unique()\n",
        "# p = 0\n",
        "# for c in Cat_types:\n",
        "#     p += 1  \n",
        "#     print(p,c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7a5d314wl2Pu"
      },
      "outputs": [],
      "source": [
        "# # Assign each value of the \"Model\" column with the integer value of the corresponding \"Manufacturer\"\n",
        "# data[\"Model_enc\"] = data[\"Manufacturer\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "gP1yYYHUHytI",
        "outputId": "a921a052-75e5-4feb-e6fb-2bb8c7ed87b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Manufacturer</th>\n",
              "      <th>Model</th>\n",
              "      <th>Prod. year</th>\n",
              "      <th>Category</th>\n",
              "      <th>Leather interior</th>\n",
              "      <th>Fuel type</th>\n",
              "      <th>Mileage</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Gear box type</th>\n",
              "      <th>Drive wheels</th>\n",
              "      <th>Doors</th>\n",
              "      <th>Airbags</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1228</td>\n",
              "      <td>2010</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>186005.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>14727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>651</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>192000.0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>17639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>677</td>\n",
              "      <td>2006</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>200000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>8467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>654</td>\n",
              "      <td>2011</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>168966.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>677</td>\n",
              "      <td>2014</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>91901.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>12172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1138</th>\n",
              "      <td>11</td>\n",
              "      <td>491</td>\n",
              "      <td>2009</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>163866.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>16834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1139</th>\n",
              "      <td>6</td>\n",
              "      <td>431</td>\n",
              "      <td>2017</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>20877.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>1719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1140</th>\n",
              "      <td>4</td>\n",
              "      <td>735</td>\n",
              "      <td>2013</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>137000.0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>21652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1142</th>\n",
              "      <td>16</td>\n",
              "      <td>1542</td>\n",
              "      <td>2013</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>800.0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>23521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1143</th>\n",
              "      <td>6</td>\n",
              "      <td>258</td>\n",
              "      <td>2017</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9027.0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>54430</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1100 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Manufacturer  Model  Prod. year  Category  Leather interior  Fuel type  \\\n",
              "0                0   1228        2010         1                 1          1   \n",
              "1                1    651        2011         1                 0          2   \n",
              "2                3    677        2006         2                 0          2   \n",
              "3                4    654        2011         1                 1          1   \n",
              "4                3    677        2014         2                 1          2   \n",
              "...            ...    ...         ...       ...               ...        ...   \n",
              "1138            11    491        2009         1                 1          2   \n",
              "1139             6    431        2017         3                 1          2   \n",
              "1140             4    735        2013         3                 1          2   \n",
              "1142            16   1542        2013         1                 1          1   \n",
              "1143             6    258        2017         6                 1          1   \n",
              "\n",
              "       Mileage  Cylinders  Gear box type  Drive wheels  Doors  Airbags  Price  \n",
              "0     186005.0          6              1             1      4       12  14727  \n",
              "1     192000.0          6              2             1      4        8  17639  \n",
              "2     200000.0          4              3             2      4        2   8467  \n",
              "3     168966.0          4              1             1      4        0   4469  \n",
              "4      91901.0          4              1             2      4        4  12172  \n",
              "...        ...        ...            ...           ...    ...      ...    ...  \n",
              "1138  163866.0          4              1             2      4        4  16834  \n",
              "1139   20877.0          4              1             2      4       12   1719  \n",
              "1140  137000.0          4              2             2      4       12  21652  \n",
              "1142     800.0          6              1             1      4        6  23521  \n",
              "1143    9027.0          4              1             2      4        4  54430  \n",
              "\n",
              "[1100 rows x 13 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(1100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vPK1p5-W52O",
        "outputId": "40637d83-1339-4475-a565-cffe575a5527"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Manufacturer', 'Model', 'Prod. year', 'Category', 'Leather interior',\n",
              "       'Fuel type', 'Mileage', 'Cylinders', 'Gear box type', 'Drive wheels',\n",
              "       'Doors', 'Airbags', 'Price'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot: >"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x1500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "corr = data.corr()\n",
        "\n",
        "plt.figure(figsize=(20,15))\n",
        "sns.heatmap(corr, annot=True, cmap='RdYlGn')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Qv7kVLdn5cO7"
      },
      "outputs": [],
      "source": [
        "from keras.optimizers.optimizer_v2 import gradient_descent\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the features and labels\n",
        "X = data.drop(\"Price\", axis=1)\n",
        "y = data[\"Price\"]\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "scaler = QuantileTransformer(output_distribution='normal')\n",
        "y = scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# y = scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "# # Normalizing \n",
        "# tf.keras.layers.Normalization(\n",
        "#     axis=-1, mean=None, variance=None, invert=False)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    # keras.layers.Reshape(target_shape=(29 * 28,), input_shape=(28, 28)),\n",
        "    Dense(units=12, activation='relu'),\n",
        "    Dense(units=60, activation='softmax'),\n",
        "    Dense(units=120, activation='softmax'),\n",
        "    Dense(units=120, activation='softmax'),\n",
        "    Dense(units=60, activation='softmax'),\n",
        "    Dense(units=1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "from keras.optimizers import Adam\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "# model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpJhfgP2DqHH",
        "outputId": "d6412a81-30af-49b4-f5c3-4c0d83c75fdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.3454137448806673e-15"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# y.mean()\n",
        "X.mean()\n",
        "# y.std()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "aP9EccQ0A4Af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.55071997  0.08050688  0.90705885 ...  0.16115917  0.18681799\n",
            "   0.32245655]\n",
            " [-0.30066657  0.71383987  0.36753909 ...  0.16115917  0.18681799\n",
            "   1.25439765]\n",
            " [-0.44256432 -0.06735296  0.36753909 ...  0.16115917  0.18681799\n",
            "  -0.60948454]\n",
            " ...\n",
            " [-0.44256432  1.07856082  1.08689877 ...  0.16115917  0.18681799\n",
            "  -0.60948454]\n",
            " [ 1.118311   -0.32857201  0.00785925 ... -1.58964986  0.18681799\n",
            "  -0.143514  ]\n",
            " [-0.01687105 -1.43259217 -1.79053993 ...  0.16115917  0.18681799\n",
            "   0.08947128]]\n"
          ]
        }
      ],
      "source": [
        "num_features = X_train\n",
        "print(num_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJiYlXFZyVCX",
        "outputId": "4c0c44ba-df30-465c-adc6-589d858cc1b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (12958, 12)               156       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (12958, 60)               780       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (12958, 120)              7320      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (12958, 120)              14520     \n",
            "                                                                 \n",
            " dense_10 (Dense)            (12958, 60)               7260      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (12958, 1)                61        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,097\n",
            "Trainable params: 30,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model.build((12958, 12))\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "sIaA8LIC5cGQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 2/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 3/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 4/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 5/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 6/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 7/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 8/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 9/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 10/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 11/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 12/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 13/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 14/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 15/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 16/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 17/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 18/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 19/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 20/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 21/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 22/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 23/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 24/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 25/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 26/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 27/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 28/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 29/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 30/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 31/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 32/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 33/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 34/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 35/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 36/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 37/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 38/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 39/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 40/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 41/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 42/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 43/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 44/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 45/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 46/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 47/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 48/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 49/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 50/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 51/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 52/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 53/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 54/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0150\n",
            "Epoch 55/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 56/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 57/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 58/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 59/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 60/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 61/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0029 - val_loss: 1.0149\n",
            "Epoch 62/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0028 - val_loss: 1.0149\n",
            "Epoch 63/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0028 - val_loss: 1.0149\n",
            "Epoch 64/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0028 - val_loss: 1.0148\n",
            "Epoch 65/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 1.0028 - val_loss: 1.0148\n",
            "Epoch 66/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0027 - val_loss: 1.0148\n",
            "Epoch 67/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0027 - val_loss: 1.0147\n",
            "Epoch 68/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0026 - val_loss: 1.0146\n",
            "Epoch 69/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0026 - val_loss: 1.0145\n",
            "Epoch 70/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0024 - val_loss: 1.0144\n",
            "Epoch 71/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0023 - val_loss: 1.0142\n",
            "Epoch 72/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0021 - val_loss: 1.0140\n",
            "Epoch 73/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0018 - val_loss: 1.0137\n",
            "Epoch 74/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0015 - val_loss: 1.0133\n",
            "Epoch 75/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0010 - val_loss: 1.0128\n",
            "Epoch 76/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 1.0005 - val_loss: 1.0121\n",
            "Epoch 77/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9997 - val_loss: 1.0113\n",
            "Epoch 78/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9988 - val_loss: 1.0102\n",
            "Epoch 79/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9976 - val_loss: 1.0089\n",
            "Epoch 80/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9961 - val_loss: 1.0072\n",
            "Epoch 81/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9944 - val_loss: 1.0052\n",
            "Epoch 82/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9923 - val_loss: 1.0029\n",
            "Epoch 83/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9897 - val_loss: 1.0000\n",
            "Epoch 84/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.9867 - val_loss: 0.9967\n",
            "Epoch 85/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9831 - val_loss: 0.9927\n",
            "Epoch 86/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9789 - val_loss: 0.9880\n",
            "Epoch 87/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9741 - val_loss: 0.9828\n",
            "Epoch 88/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9685 - val_loss: 0.9768\n",
            "Epoch 89/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9622 - val_loss: 0.9700\n",
            "Epoch 90/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9551 - val_loss: 0.9624\n",
            "Epoch 91/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9472 - val_loss: 0.9540\n",
            "Epoch 92/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.9385 - val_loss: 0.9449\n",
            "Epoch 93/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9291 - val_loss: 0.9351\n",
            "Epoch 94/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9191 - val_loss: 0.9246\n",
            "Epoch 95/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.9085 - val_loss: 0.9137\n",
            "Epoch 96/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.8974 - val_loss: 0.9023\n",
            "Epoch 97/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.8860 - val_loss: 0.8906\n",
            "Epoch 98/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.8743 - val_loss: 0.8788\n",
            "Epoch 99/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.8625 - val_loss: 0.8668\n",
            "Epoch 100/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.8507 - val_loss: 0.8548\n",
            "Epoch 101/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.8389 - val_loss: 0.8428\n",
            "Epoch 102/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.8272 - val_loss: 0.8311\n",
            "Epoch 103/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.8158 - val_loss: 0.8195\n",
            "Epoch 104/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.8047 - val_loss: 0.8083\n",
            "Epoch 105/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.7940 - val_loss: 0.7974\n",
            "Epoch 106/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7837 - val_loss: 0.7870\n",
            "Epoch 107/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7739 - val_loss: 0.7771\n",
            "Epoch 108/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7647 - val_loss: 0.7675\n",
            "Epoch 109/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7559 - val_loss: 0.7588\n",
            "Epoch 110/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7478 - val_loss: 0.7504\n",
            "Epoch 111/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7402 - val_loss: 0.7428\n",
            "Epoch 112/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7332 - val_loss: 0.7356\n",
            "Epoch 113/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7267 - val_loss: 0.7289\n",
            "Epoch 114/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7207 - val_loss: 0.7228\n",
            "Epoch 115/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7153 - val_loss: 0.7174\n",
            "Epoch 116/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7103 - val_loss: 0.7123\n",
            "Epoch 117/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7059 - val_loss: 0.7076\n",
            "Epoch 118/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.7018 - val_loss: 0.7035\n",
            "Epoch 119/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6983 - val_loss: 0.6998\n",
            "Epoch 120/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6950 - val_loss: 0.6966\n",
            "Epoch 121/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6922 - val_loss: 0.6937\n",
            "Epoch 122/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6897 - val_loss: 0.6909\n",
            "Epoch 123/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6874 - val_loss: 0.6885\n",
            "Epoch 124/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6854 - val_loss: 0.6864\n",
            "Epoch 125/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6836 - val_loss: 0.6843\n",
            "Epoch 126/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6820 - val_loss: 0.6825\n",
            "Epoch 127/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6805 - val_loss: 0.6810\n",
            "Epoch 128/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6791 - val_loss: 0.6794\n",
            "Epoch 129/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6779 - val_loss: 0.6782\n",
            "Epoch 130/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6767 - val_loss: 0.6768\n",
            "Epoch 131/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6756 - val_loss: 0.6757\n",
            "Epoch 132/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6745 - val_loss: 0.6745\n",
            "Epoch 133/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6736 - val_loss: 0.6735\n",
            "Epoch 134/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6726 - val_loss: 0.6725\n",
            "Epoch 135/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6718 - val_loss: 0.6717\n",
            "Epoch 136/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6711 - val_loss: 0.6712\n",
            "Epoch 137/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6705 - val_loss: 0.6706\n",
            "Epoch 138/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6699 - val_loss: 0.6699\n",
            "Epoch 139/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6693 - val_loss: 0.6693\n",
            "Epoch 140/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6688 - val_loss: 0.6687\n",
            "Epoch 141/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6682 - val_loss: 0.6681\n",
            "Epoch 142/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6677 - val_loss: 0.6675\n",
            "Epoch 143/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6671 - val_loss: 0.6668\n",
            "Epoch 144/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6666 - val_loss: 0.6662\n",
            "Epoch 145/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6658 - val_loss: 0.6655\n",
            "Epoch 146/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6651 - val_loss: 0.6646\n",
            "Epoch 147/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6641 - val_loss: 0.6634\n",
            "Epoch 148/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6629 - val_loss: 0.6620\n",
            "Epoch 149/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6618 - val_loss: 0.6607\n",
            "Epoch 150/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6608 - val_loss: 0.6595\n",
            "Epoch 151/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6600 - val_loss: 0.6583\n",
            "Epoch 152/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6592 - val_loss: 0.6571\n",
            "Epoch 153/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6584 - val_loss: 0.6562\n",
            "Epoch 154/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6576 - val_loss: 0.6554\n",
            "Epoch 155/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6570 - val_loss: 0.6547\n",
            "Epoch 156/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6564 - val_loss: 0.6538\n",
            "Epoch 157/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6558 - val_loss: 0.6530\n",
            "Epoch 158/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6553 - val_loss: 0.6522\n",
            "Epoch 159/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6546 - val_loss: 0.6516\n",
            "Epoch 160/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.6540 - val_loss: 0.6508\n",
            "Epoch 161/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6535 - val_loss: 0.6500\n",
            "Epoch 162/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6528 - val_loss: 0.6494\n",
            "Epoch 163/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6524 - val_loss: 0.6490\n",
            "Epoch 164/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6518 - val_loss: 0.6482\n",
            "Epoch 165/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6513 - val_loss: 0.6474\n",
            "Epoch 166/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6507 - val_loss: 0.6470\n",
            "Epoch 167/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6501 - val_loss: 0.6464\n",
            "Epoch 168/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6496 - val_loss: 0.6459\n",
            "Epoch 169/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6491 - val_loss: 0.6453\n",
            "Epoch 170/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6485 - val_loss: 0.6449\n",
            "Epoch 171/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6481 - val_loss: 0.6444\n",
            "Epoch 172/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6475 - val_loss: 0.6439\n",
            "Epoch 173/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6470 - val_loss: 0.6433\n",
            "Epoch 174/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6465 - val_loss: 0.6428\n",
            "Epoch 175/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6460 - val_loss: 0.6421\n",
            "Epoch 176/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6456 - val_loss: 0.6417\n",
            "Epoch 177/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6449 - val_loss: 0.6412\n",
            "Epoch 178/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6445 - val_loss: 0.6407\n",
            "Epoch 179/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6439 - val_loss: 0.6401\n",
            "Epoch 180/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6433 - val_loss: 0.6395\n",
            "Epoch 181/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6428 - val_loss: 0.6389\n",
            "Epoch 182/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6423 - val_loss: 0.6383\n",
            "Epoch 183/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6418 - val_loss: 0.6378\n",
            "Epoch 184/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6412 - val_loss: 0.6373\n",
            "Epoch 185/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6406 - val_loss: 0.6368\n",
            "Epoch 186/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6401 - val_loss: 0.6362\n",
            "Epoch 187/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6395 - val_loss: 0.6357\n",
            "Epoch 188/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6390 - val_loss: 0.6352\n",
            "Epoch 189/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6384 - val_loss: 0.6346\n",
            "Epoch 190/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6379 - val_loss: 0.6340\n",
            "Epoch 191/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6372 - val_loss: 0.6335\n",
            "Epoch 192/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6366 - val_loss: 0.6330\n",
            "Epoch 193/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6361 - val_loss: 0.6325\n",
            "Epoch 194/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6354 - val_loss: 0.6321\n",
            "Epoch 195/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6349 - val_loss: 0.6316\n",
            "Epoch 196/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6343 - val_loss: 0.6312\n",
            "Epoch 197/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6337 - val_loss: 0.6306\n",
            "Epoch 198/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6332 - val_loss: 0.6301\n",
            "Epoch 199/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6326 - val_loss: 0.6297\n",
            "Epoch 200/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6320 - val_loss: 0.6293\n",
            "Epoch 201/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6315 - val_loss: 0.6288\n",
            "Epoch 202/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6309 - val_loss: 0.6284\n",
            "Epoch 203/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6303 - val_loss: 0.6281\n",
            "Epoch 204/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.6298 - val_loss: 0.6275\n",
            "Epoch 205/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6293 - val_loss: 0.6272\n",
            "Epoch 206/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6287 - val_loss: 0.6268\n",
            "Epoch 207/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.6282 - val_loss: 0.6264\n",
            "Epoch 208/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6276 - val_loss: 0.6259\n",
            "Epoch 209/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6270 - val_loss: 0.6256\n",
            "Epoch 210/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6265 - val_loss: 0.6253\n",
            "Epoch 211/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6260 - val_loss: 0.6250\n",
            "Epoch 212/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6255 - val_loss: 0.6245\n",
            "Epoch 213/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6249 - val_loss: 0.6243\n",
            "Epoch 214/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6244 - val_loss: 0.6239\n",
            "Epoch 215/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6239 - val_loss: 0.6236\n",
            "Epoch 216/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6234 - val_loss: 0.6233\n",
            "Epoch 217/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6228 - val_loss: 0.6229\n",
            "Epoch 218/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6223 - val_loss: 0.6225\n",
            "Epoch 219/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6219 - val_loss: 0.6221\n",
            "Epoch 220/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6214 - val_loss: 0.6217\n",
            "Epoch 221/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6209 - val_loss: 0.6214\n",
            "Epoch 222/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6203 - val_loss: 0.6210\n",
            "Epoch 223/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6198 - val_loss: 0.6208\n",
            "Epoch 224/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6194 - val_loss: 0.6204\n",
            "Epoch 225/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6189 - val_loss: 0.6200\n",
            "Epoch 226/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6184 - val_loss: 0.6197\n",
            "Epoch 227/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6180 - val_loss: 0.6194\n",
            "Epoch 228/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6176 - val_loss: 0.6191\n",
            "Epoch 229/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6171 - val_loss: 0.6188\n",
            "Epoch 230/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6167 - val_loss: 0.6184\n",
            "Epoch 231/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6162 - val_loss: 0.6180\n",
            "Epoch 232/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6159 - val_loss: 0.6177\n",
            "Epoch 233/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6155 - val_loss: 0.6174\n",
            "Epoch 234/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6150 - val_loss: 0.6170\n",
            "Epoch 235/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6146 - val_loss: 0.6166\n",
            "Epoch 236/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6142 - val_loss: 0.6163\n",
            "Epoch 237/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6137 - val_loss: 0.6159\n",
            "Epoch 238/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6134 - val_loss: 0.6156\n",
            "Epoch 239/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6130 - val_loss: 0.6152\n",
            "Epoch 240/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6126 - val_loss: 0.6148\n",
            "Epoch 241/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6122 - val_loss: 0.6144\n",
            "Epoch 242/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6117 - val_loss: 0.6140\n",
            "Epoch 243/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6114 - val_loss: 0.6137\n",
            "Epoch 244/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6109 - val_loss: 0.6133\n",
            "Epoch 245/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6106 - val_loss: 0.6129\n",
            "Epoch 246/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6101 - val_loss: 0.6124\n",
            "Epoch 247/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6097 - val_loss: 0.6120\n",
            "Epoch 248/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6093 - val_loss: 0.6118\n",
            "Epoch 249/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6089 - val_loss: 0.6113\n",
            "Epoch 250/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6085 - val_loss: 0.6109\n",
            "Epoch 251/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.6081 - val_loss: 0.6105\n",
            "Epoch 252/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.6076 - val_loss: 0.6102\n",
            "Epoch 253/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6073 - val_loss: 0.6098\n",
            "Epoch 254/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6069 - val_loss: 0.6094\n",
            "Epoch 255/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6065 - val_loss: 0.6091\n",
            "Epoch 256/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6060 - val_loss: 0.6087\n",
            "Epoch 257/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6055 - val_loss: 0.6083\n",
            "Epoch 258/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.6051 - val_loss: 0.6080\n",
            "Epoch 259/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6046 - val_loss: 0.6076\n",
            "Epoch 260/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6042 - val_loss: 0.6071\n",
            "Epoch 261/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6036 - val_loss: 0.6067\n",
            "Epoch 262/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6031 - val_loss: 0.6062\n",
            "Epoch 263/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6024 - val_loss: 0.6056\n",
            "Epoch 264/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.6016 - val_loss: 0.6048\n",
            "Epoch 265/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.6005 - val_loss: 0.6039\n",
            "Epoch 266/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.5988 - val_loss: 0.6020\n",
            "Epoch 267/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.5951 - val_loss: 0.5978\n",
            "Epoch 268/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5873 - val_loss: 0.5910\n",
            "Epoch 269/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5807 - val_loss: 0.5881\n",
            "Epoch 270/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5783 - val_loss: 0.5868\n",
            "Epoch 271/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5771 - val_loss: 0.5859\n",
            "Epoch 272/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5758 - val_loss: 0.5847\n",
            "Epoch 273/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5747 - val_loss: 0.5837\n",
            "Epoch 274/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5737 - val_loss: 0.5829\n",
            "Epoch 275/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5727 - val_loss: 0.5819\n",
            "Epoch 276/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5716 - val_loss: 0.5810\n",
            "Epoch 277/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5706 - val_loss: 0.5800\n",
            "Epoch 278/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5694 - val_loss: 0.5789\n",
            "Epoch 279/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5681 - val_loss: 0.5777\n",
            "Epoch 280/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5666 - val_loss: 0.5765\n",
            "Epoch 281/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.5651 - val_loss: 0.5752\n",
            "Epoch 282/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5633 - val_loss: 0.5736\n",
            "Epoch 283/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5615 - val_loss: 0.5720\n",
            "Epoch 284/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5595 - val_loss: 0.5702\n",
            "Epoch 285/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5573 - val_loss: 0.5684\n",
            "Epoch 286/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5551 - val_loss: 0.5663\n",
            "Epoch 287/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.5525 - val_loss: 0.5643\n",
            "Epoch 288/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5499 - val_loss: 0.5619\n",
            "Epoch 289/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5473 - val_loss: 0.5598\n",
            "Epoch 290/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5446 - val_loss: 0.5578\n",
            "Epoch 291/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.5421 - val_loss: 0.5557\n",
            "Epoch 292/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.5397 - val_loss: 0.5539\n",
            "Epoch 293/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.5377 - val_loss: 0.5521\n",
            "Epoch 294/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5358 - val_loss: 0.5506\n",
            "Epoch 295/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.5340 - val_loss: 0.5492\n",
            "Epoch 296/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.5324 - val_loss: 0.5479\n",
            "Epoch 297/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5309 - val_loss: 0.5467\n",
            "Epoch 298/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5296 - val_loss: 0.5455\n",
            "Epoch 299/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5283 - val_loss: 0.5444\n",
            "Epoch 300/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5272 - val_loss: 0.5435\n",
            "Epoch 301/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5259 - val_loss: 0.5422\n",
            "Epoch 302/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5249 - val_loss: 0.5413\n",
            "Epoch 303/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5239 - val_loss: 0.5403\n",
            "Epoch 304/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5228 - val_loss: 0.5393\n",
            "Epoch 305/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.5218 - val_loss: 0.5385\n",
            "Epoch 306/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5210 - val_loss: 0.5375\n",
            "Epoch 307/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5200 - val_loss: 0.5367\n",
            "Epoch 308/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5192 - val_loss: 0.5359\n",
            "Epoch 309/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5183 - val_loss: 0.5352\n",
            "Epoch 310/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5174 - val_loss: 0.5344\n",
            "Epoch 311/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5166 - val_loss: 0.5335\n",
            "Epoch 312/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5158 - val_loss: 0.5327\n",
            "Epoch 313/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5149 - val_loss: 0.5319\n",
            "Epoch 314/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5142 - val_loss: 0.5310\n",
            "Epoch 315/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5133 - val_loss: 0.5304\n",
            "Epoch 316/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5125 - val_loss: 0.5296\n",
            "Epoch 317/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.5116 - val_loss: 0.5290\n",
            "Epoch 318/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5108 - val_loss: 0.5283\n",
            "Epoch 319/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5099 - val_loss: 0.5276\n",
            "Epoch 320/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5090 - val_loss: 0.5269\n",
            "Epoch 321/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5084 - val_loss: 0.5262\n",
            "Epoch 322/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5075 - val_loss: 0.5254\n",
            "Epoch 323/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5067 - val_loss: 0.5249\n",
            "Epoch 324/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5059 - val_loss: 0.5241\n",
            "Epoch 325/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5052 - val_loss: 0.5235\n",
            "Epoch 326/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5044 - val_loss: 0.5229\n",
            "Epoch 327/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5036 - val_loss: 0.5221\n",
            "Epoch 328/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5029 - val_loss: 0.5216\n",
            "Epoch 329/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5021 - val_loss: 0.5211\n",
            "Epoch 330/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.5013 - val_loss: 0.5203\n",
            "Epoch 331/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.5005 - val_loss: 0.5198\n",
            "Epoch 332/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4998 - val_loss: 0.5193\n",
            "Epoch 333/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4989 - val_loss: 0.5187\n",
            "Epoch 334/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4983 - val_loss: 0.5181\n",
            "Epoch 335/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4975 - val_loss: 0.5176\n",
            "Epoch 336/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4967 - val_loss: 0.5168\n",
            "Epoch 337/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4960 - val_loss: 0.5166\n",
            "Epoch 338/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4953 - val_loss: 0.5164\n",
            "Epoch 339/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4946 - val_loss: 0.5155\n",
            "Epoch 340/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4938 - val_loss: 0.5150\n",
            "Epoch 341/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4932 - val_loss: 0.5144\n",
            "Epoch 342/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4924 - val_loss: 0.5138\n",
            "Epoch 343/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4918 - val_loss: 0.5134\n",
            "Epoch 344/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4911 - val_loss: 0.5128\n",
            "Epoch 345/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4905 - val_loss: 0.5125\n",
            "Epoch 346/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4898 - val_loss: 0.5116\n",
            "Epoch 347/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4892 - val_loss: 0.5111\n",
            "Epoch 348/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4888 - val_loss: 0.5111\n",
            "Epoch 349/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4879 - val_loss: 0.5106\n",
            "Epoch 350/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4873 - val_loss: 0.5101\n",
            "Epoch 351/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4867 - val_loss: 0.5096\n",
            "Epoch 352/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4861 - val_loss: 0.5091\n",
            "Epoch 353/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4853 - val_loss: 0.5083\n",
            "Epoch 354/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4849 - val_loss: 0.5081\n",
            "Epoch 355/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4842 - val_loss: 0.5078\n",
            "Epoch 356/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4840 - val_loss: 0.5071\n",
            "Epoch 357/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4832 - val_loss: 0.5067\n",
            "Epoch 358/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4827 - val_loss: 0.5061\n",
            "Epoch 359/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4820 - val_loss: 0.5059\n",
            "Epoch 360/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4816 - val_loss: 0.5053\n",
            "Epoch 361/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4809 - val_loss: 0.5050\n",
            "Epoch 362/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4805 - val_loss: 0.5041\n",
            "Epoch 363/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4801 - val_loss: 0.5035\n",
            "Epoch 364/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4795 - val_loss: 0.5036\n",
            "Epoch 365/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4790 - val_loss: 0.5028\n",
            "Epoch 366/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4785 - val_loss: 0.5022\n",
            "Epoch 367/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4779 - val_loss: 0.5016\n",
            "Epoch 368/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4775 - val_loss: 0.5015\n",
            "Epoch 369/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4770 - val_loss: 0.5010\n",
            "Epoch 370/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4765 - val_loss: 0.5001\n",
            "Epoch 371/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4761 - val_loss: 0.5000\n",
            "Epoch 372/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4757 - val_loss: 0.4991\n",
            "Epoch 373/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4752 - val_loss: 0.4986\n",
            "Epoch 374/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4746 - val_loss: 0.4983\n",
            "Epoch 375/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4742 - val_loss: 0.4983\n",
            "Epoch 376/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4739 - val_loss: 0.4976\n",
            "Epoch 377/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4733 - val_loss: 0.4971\n",
            "Epoch 378/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4728 - val_loss: 0.4964\n",
            "Epoch 379/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4725 - val_loss: 0.4961\n",
            "Epoch 380/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4720 - val_loss: 0.4963\n",
            "Epoch 381/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4716 - val_loss: 0.4957\n",
            "Epoch 382/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4712 - val_loss: 0.4952\n",
            "Epoch 383/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4707 - val_loss: 0.4947\n",
            "Epoch 384/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4703 - val_loss: 0.4941\n",
            "Epoch 385/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4697 - val_loss: 0.4935\n",
            "Epoch 386/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4694 - val_loss: 0.4934\n",
            "Epoch 387/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4690 - val_loss: 0.4933\n",
            "Epoch 388/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4686 - val_loss: 0.4923\n",
            "Epoch 389/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4682 - val_loss: 0.4918\n",
            "Epoch 390/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4679 - val_loss: 0.4913\n",
            "Epoch 391/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4675 - val_loss: 0.4911\n",
            "Epoch 392/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4669 - val_loss: 0.4905\n",
            "Epoch 393/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4666 - val_loss: 0.4902\n",
            "Epoch 394/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4661 - val_loss: 0.4895\n",
            "Epoch 395/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4658 - val_loss: 0.4895\n",
            "Epoch 396/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4653 - val_loss: 0.4886\n",
            "Epoch 397/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4651 - val_loss: 0.4881\n",
            "Epoch 398/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4644 - val_loss: 0.4877\n",
            "Epoch 399/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4642 - val_loss: 0.4876\n",
            "Epoch 400/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4638 - val_loss: 0.4871\n",
            "Epoch 401/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4633 - val_loss: 0.4869\n",
            "Epoch 402/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4630 - val_loss: 0.4867\n",
            "Epoch 403/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4625 - val_loss: 0.4865\n",
            "Epoch 404/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4623 - val_loss: 0.4858\n",
            "Epoch 405/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4620 - val_loss: 0.4851\n",
            "Epoch 406/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4617 - val_loss: 0.4847\n",
            "Epoch 407/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4614 - val_loss: 0.4844\n",
            "Epoch 408/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4609 - val_loss: 0.4838\n",
            "Epoch 409/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4605 - val_loss: 0.4837\n",
            "Epoch 410/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4599 - val_loss: 0.4830\n",
            "Epoch 411/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4596 - val_loss: 0.4829\n",
            "Epoch 412/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4593 - val_loss: 0.4824\n",
            "Epoch 413/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4589 - val_loss: 0.4820\n",
            "Epoch 414/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4584 - val_loss: 0.4814\n",
            "Epoch 415/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4582 - val_loss: 0.4814\n",
            "Epoch 416/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4577 - val_loss: 0.4812\n",
            "Epoch 417/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4574 - val_loss: 0.4800\n",
            "Epoch 418/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4571 - val_loss: 0.4802\n",
            "Epoch 419/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4568 - val_loss: 0.4795\n",
            "Epoch 420/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4563 - val_loss: 0.4795\n",
            "Epoch 421/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4558 - val_loss: 0.4788\n",
            "Epoch 422/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4557 - val_loss: 0.4789\n",
            "Epoch 423/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4553 - val_loss: 0.4784\n",
            "Epoch 424/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4550 - val_loss: 0.4779\n",
            "Epoch 425/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4547 - val_loss: 0.4775\n",
            "Epoch 426/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4544 - val_loss: 0.4774\n",
            "Epoch 427/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4538 - val_loss: 0.4775\n",
            "Epoch 428/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4536 - val_loss: 0.4770\n",
            "Epoch 429/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4532 - val_loss: 0.4762\n",
            "Epoch 430/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4527 - val_loss: 0.4759\n",
            "Epoch 431/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4525 - val_loss: 0.4754\n",
            "Epoch 432/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4522 - val_loss: 0.4755\n",
            "Epoch 433/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4517 - val_loss: 0.4747\n",
            "Epoch 434/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4514 - val_loss: 0.4739\n",
            "Epoch 435/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4513 - val_loss: 0.4735\n",
            "Epoch 436/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4507 - val_loss: 0.4743\n",
            "Epoch 437/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4504 - val_loss: 0.4733\n",
            "Epoch 438/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4500 - val_loss: 0.4731\n",
            "Epoch 439/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4498 - val_loss: 0.4724\n",
            "Epoch 440/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4494 - val_loss: 0.4722\n",
            "Epoch 441/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4490 - val_loss: 0.4721\n",
            "Epoch 442/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4488 - val_loss: 0.4713\n",
            "Epoch 443/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4485 - val_loss: 0.4714\n",
            "Epoch 444/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4481 - val_loss: 0.4716\n",
            "Epoch 445/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4478 - val_loss: 0.4712\n",
            "Epoch 446/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4474 - val_loss: 0.4710\n",
            "Epoch 447/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4470 - val_loss: 0.4705\n",
            "Epoch 448/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4468 - val_loss: 0.4706\n",
            "Epoch 449/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4465 - val_loss: 0.4699\n",
            "Epoch 450/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4462 - val_loss: 0.4697\n",
            "Epoch 451/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4459 - val_loss: 0.4687\n",
            "Epoch 452/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4452 - val_loss: 0.4710\n",
            "Epoch 453/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4455 - val_loss: 0.4694\n",
            "Epoch 454/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4449 - val_loss: 0.4686\n",
            "Epoch 455/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4448 - val_loss: 0.4678\n",
            "Epoch 456/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4446 - val_loss: 0.4679\n",
            "Epoch 457/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4442 - val_loss: 0.4679\n",
            "Epoch 458/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4439 - val_loss: 0.4674\n",
            "Epoch 459/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4435 - val_loss: 0.4675\n",
            "Epoch 460/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4434 - val_loss: 0.4666\n",
            "Epoch 461/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4431 - val_loss: 0.4667\n",
            "Epoch 462/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4428 - val_loss: 0.4669\n",
            "Epoch 463/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4426 - val_loss: 0.4668\n",
            "Epoch 464/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4422 - val_loss: 0.4658\n",
            "Epoch 465/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4421 - val_loss: 0.4658\n",
            "Epoch 466/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4418 - val_loss: 0.4651\n",
            "Epoch 467/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4415 - val_loss: 0.4655\n",
            "Epoch 468/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4413 - val_loss: 0.4649\n",
            "Epoch 469/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4411 - val_loss: 0.4651\n",
            "Epoch 470/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4408 - val_loss: 0.4648\n",
            "Epoch 471/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4407 - val_loss: 0.4642\n",
            "Epoch 472/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4402 - val_loss: 0.4639\n",
            "Epoch 473/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4403 - val_loss: 0.4634\n",
            "Epoch 474/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4398 - val_loss: 0.4628\n",
            "Epoch 475/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4398 - val_loss: 0.4631\n",
            "Epoch 476/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4395 - val_loss: 0.4630\n",
            "Epoch 477/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4390 - val_loss: 0.4634\n",
            "Epoch 478/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4389 - val_loss: 0.4629\n",
            "Epoch 479/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4385 - val_loss: 0.4624\n",
            "Epoch 480/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4384 - val_loss: 0.4627\n",
            "Epoch 481/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4382 - val_loss: 0.4626\n",
            "Epoch 482/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4380 - val_loss: 0.4616\n",
            "Epoch 483/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4379 - val_loss: 0.4609\n",
            "Epoch 484/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4375 - val_loss: 0.4615\n",
            "Epoch 485/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4373 - val_loss: 0.4608\n",
            "Epoch 486/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4373 - val_loss: 0.4604\n",
            "Epoch 487/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4369 - val_loss: 0.4600\n",
            "Epoch 488/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4367 - val_loss: 0.4598\n",
            "Epoch 489/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4364 - val_loss: 0.4608\n",
            "Epoch 490/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4363 - val_loss: 0.4600\n",
            "Epoch 491/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4360 - val_loss: 0.4599\n",
            "Epoch 492/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4357 - val_loss: 0.4591\n",
            "Epoch 493/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4357 - val_loss: 0.4592\n",
            "Epoch 494/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4352 - val_loss: 0.4602\n",
            "Epoch 495/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4352 - val_loss: 0.4593\n",
            "Epoch 496/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4349 - val_loss: 0.4589\n",
            "Epoch 497/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4350 - val_loss: 0.4585\n",
            "Epoch 498/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4346 - val_loss: 0.4593\n",
            "Epoch 499/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4343 - val_loss: 0.4581\n",
            "Epoch 500/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4342 - val_loss: 0.4581\n",
            "Epoch 501/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4339 - val_loss: 0.4578\n",
            "Epoch 502/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4337 - val_loss: 0.4571\n",
            "Epoch 503/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4335 - val_loss: 0.4574\n",
            "Epoch 504/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4334 - val_loss: 0.4575\n",
            "Epoch 505/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4331 - val_loss: 0.4571\n",
            "Epoch 506/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4328 - val_loss: 0.4564\n",
            "Epoch 507/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4327 - val_loss: 0.4561\n",
            "Epoch 508/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4324 - val_loss: 0.4563\n",
            "Epoch 509/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4325 - val_loss: 0.4566\n",
            "Epoch 510/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4325 - val_loss: 0.4556\n",
            "Epoch 511/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4320 - val_loss: 0.4556\n",
            "Epoch 512/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4318 - val_loss: 0.4560\n",
            "Epoch 513/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4317 - val_loss: 0.4556\n",
            "Epoch 514/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4314 - val_loss: 0.4556\n",
            "Epoch 515/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4312 - val_loss: 0.4548\n",
            "Epoch 516/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4310 - val_loss: 0.4549\n",
            "Epoch 517/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4307 - val_loss: 0.4548\n",
            "Epoch 518/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4308 - val_loss: 0.4543\n",
            "Epoch 519/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4307 - val_loss: 0.4545\n",
            "Epoch 520/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4303 - val_loss: 0.4544\n",
            "Epoch 521/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4300 - val_loss: 0.4540\n",
            "Epoch 522/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4302 - val_loss: 0.4536\n",
            "Epoch 523/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4298 - val_loss: 0.4532\n",
            "Epoch 524/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4295 - val_loss: 0.4539\n",
            "Epoch 525/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4294 - val_loss: 0.4539\n",
            "Epoch 526/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4292 - val_loss: 0.4533\n",
            "Epoch 527/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4290 - val_loss: 0.4531\n",
            "Epoch 528/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4289 - val_loss: 0.4528\n",
            "Epoch 529/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4287 - val_loss: 0.4528\n",
            "Epoch 530/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4285 - val_loss: 0.4529\n",
            "Epoch 531/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4282 - val_loss: 0.4521\n",
            "Epoch 532/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4281 - val_loss: 0.4530\n",
            "Epoch 533/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4279 - val_loss: 0.4522\n",
            "Epoch 534/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4279 - val_loss: 0.4523\n",
            "Epoch 535/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4276 - val_loss: 0.4530\n",
            "Epoch 536/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4274 - val_loss: 0.4525\n",
            "Epoch 537/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4272 - val_loss: 0.4519\n",
            "Epoch 538/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4270 - val_loss: 0.4511\n",
            "Epoch 539/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4269 - val_loss: 0.4512\n",
            "Epoch 540/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4267 - val_loss: 0.4521\n",
            "Epoch 541/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4266 - val_loss: 0.4510\n",
            "Epoch 542/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4265 - val_loss: 0.4507\n",
            "Epoch 543/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.4508\n",
            "Epoch 544/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4263 - val_loss: 0.4507\n",
            "Epoch 545/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4258 - val_loss: 0.4507\n",
            "Epoch 546/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4258 - val_loss: 0.4505\n",
            "Epoch 547/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4260 - val_loss: 0.4502\n",
            "Epoch 548/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4254 - val_loss: 0.4501\n",
            "Epoch 549/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4253 - val_loss: 0.4501\n",
            "Epoch 550/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4252 - val_loss: 0.4499\n",
            "Epoch 551/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4250 - val_loss: 0.4497\n",
            "Epoch 552/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4247 - val_loss: 0.4491\n",
            "Epoch 553/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4247 - val_loss: 0.4494\n",
            "Epoch 554/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4245 - val_loss: 0.4492\n",
            "Epoch 555/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4244 - val_loss: 0.4486\n",
            "Epoch 556/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4241 - val_loss: 0.4496\n",
            "Epoch 557/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4240 - val_loss: 0.4484\n",
            "Epoch 558/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4238 - val_loss: 0.4488\n",
            "Epoch 559/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4237 - val_loss: 0.4490\n",
            "Epoch 560/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4236 - val_loss: 0.4487\n",
            "Epoch 561/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4235 - val_loss: 0.4492\n",
            "Epoch 562/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4234 - val_loss: 0.4484\n",
            "Epoch 563/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4230 - val_loss: 0.4486\n",
            "Epoch 564/10000\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.4231 - val_loss: 0.4482\n",
            "Epoch 565/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4229 - val_loss: 0.4483\n",
            "Epoch 566/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4227 - val_loss: 0.4477\n",
            "Epoch 567/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4227 - val_loss: 0.4478\n",
            "Epoch 568/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4227 - val_loss: 0.4474\n",
            "Epoch 569/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4225 - val_loss: 0.4472\n",
            "Epoch 570/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4223 - val_loss: 0.4474\n",
            "Epoch 571/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4221 - val_loss: 0.4472\n",
            "Epoch 572/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4220 - val_loss: 0.4473\n",
            "Epoch 573/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4221 - val_loss: 0.4473\n",
            "Epoch 574/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4218 - val_loss: 0.4468\n",
            "Epoch 575/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4214 - val_loss: 0.4464\n",
            "Epoch 576/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4214 - val_loss: 0.4470\n",
            "Epoch 577/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4213 - val_loss: 0.4463\n",
            "Epoch 578/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4211 - val_loss: 0.4459\n",
            "Epoch 579/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4215 - val_loss: 0.4462\n",
            "Epoch 580/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4213 - val_loss: 0.4458\n",
            "Epoch 581/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4210 - val_loss: 0.4460\n",
            "Epoch 582/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4208 - val_loss: 0.4456\n",
            "Epoch 583/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4207 - val_loss: 0.4459\n",
            "Epoch 584/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4208 - val_loss: 0.4462\n",
            "Epoch 585/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4206 - val_loss: 0.4454\n",
            "Epoch 586/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4203 - val_loss: 0.4453\n",
            "Epoch 587/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4203 - val_loss: 0.4459\n",
            "Epoch 588/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4203 - val_loss: 0.4453\n",
            "Epoch 589/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4201 - val_loss: 0.4454\n",
            "Epoch 590/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4199 - val_loss: 0.4453\n",
            "Epoch 591/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4199 - val_loss: 0.4452\n",
            "Epoch 592/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4198 - val_loss: 0.4454\n",
            "Epoch 593/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4196 - val_loss: 0.4445\n",
            "Epoch 594/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4194 - val_loss: 0.4450\n",
            "Epoch 595/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4444\n",
            "Epoch 596/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4195 - val_loss: 0.4443\n",
            "Epoch 597/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4192 - val_loss: 0.4453\n",
            "Epoch 598/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4191 - val_loss: 0.4441\n",
            "Epoch 599/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4190 - val_loss: 0.4441\n",
            "Epoch 600/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4188 - val_loss: 0.4441\n",
            "Epoch 601/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4189 - val_loss: 0.4436\n",
            "Epoch 602/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4186 - val_loss: 0.4432\n",
            "Epoch 603/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.4431\n",
            "Epoch 604/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4185 - val_loss: 0.4434\n",
            "Epoch 605/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4184 - val_loss: 0.4436\n",
            "Epoch 606/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4184 - val_loss: 0.4429\n",
            "Epoch 607/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4181 - val_loss: 0.4433\n",
            "Epoch 608/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4180 - val_loss: 0.4438\n",
            "Epoch 609/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4181 - val_loss: 0.4428\n",
            "Epoch 610/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4179 - val_loss: 0.4426\n",
            "Epoch 611/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4178 - val_loss: 0.4425\n",
            "Epoch 612/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4176 - val_loss: 0.4434\n",
            "Epoch 613/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4174 - val_loss: 0.4421\n",
            "Epoch 614/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4174 - val_loss: 0.4426\n",
            "Epoch 615/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4175 - val_loss: 0.4427\n",
            "Epoch 616/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4419\n",
            "Epoch 617/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4171 - val_loss: 0.4428\n",
            "Epoch 618/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4169 - val_loss: 0.4428\n",
            "Epoch 619/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4170 - val_loss: 0.4424\n",
            "Epoch 620/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4169 - val_loss: 0.4423\n",
            "Epoch 621/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4167 - val_loss: 0.4422\n",
            "Epoch 622/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4166 - val_loss: 0.4420\n",
            "Epoch 623/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4166 - val_loss: 0.4414\n",
            "Epoch 624/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4163 - val_loss: 0.4414\n",
            "Epoch 625/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4162 - val_loss: 0.4417\n",
            "Epoch 626/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4162 - val_loss: 0.4417\n",
            "Epoch 627/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4162 - val_loss: 0.4414\n",
            "Epoch 628/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4161 - val_loss: 0.4414\n",
            "Epoch 629/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4159 - val_loss: 0.4412\n",
            "Epoch 630/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4159 - val_loss: 0.4416\n",
            "Epoch 631/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.4408\n",
            "Epoch 632/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4153 - val_loss: 0.4421\n",
            "Epoch 633/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4157 - val_loss: 0.4404\n",
            "Epoch 634/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4152 - val_loss: 0.4419\n",
            "Epoch 635/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4155 - val_loss: 0.4408\n",
            "Epoch 636/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.4407\n",
            "Epoch 637/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4154 - val_loss: 0.4409\n",
            "Epoch 638/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4153 - val_loss: 0.4402\n",
            "Epoch 639/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4152 - val_loss: 0.4399\n",
            "Epoch 640/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4150 - val_loss: 0.4407\n",
            "Epoch 641/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4149 - val_loss: 0.4405\n",
            "Epoch 642/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4149 - val_loss: 0.4401\n",
            "Epoch 643/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4148 - val_loss: 0.4406\n",
            "Epoch 644/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.4404\n",
            "Epoch 645/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4146 - val_loss: 0.4398\n",
            "Epoch 646/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4145 - val_loss: 0.4406\n",
            "Epoch 647/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4143 - val_loss: 0.4402\n",
            "Epoch 648/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4144 - val_loss: 0.4408\n",
            "Epoch 649/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4142 - val_loss: 0.4400\n",
            "Epoch 650/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4143 - val_loss: 0.4401\n",
            "Epoch 651/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4140 - val_loss: 0.4403\n",
            "Epoch 652/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4140 - val_loss: 0.4392\n",
            "Epoch 653/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4138 - val_loss: 0.4404\n",
            "Epoch 654/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4138 - val_loss: 0.4390\n",
            "Epoch 655/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4136 - val_loss: 0.4394\n",
            "Epoch 656/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4137 - val_loss: 0.4387\n",
            "Epoch 657/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 0.4392\n",
            "Epoch 658/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4137 - val_loss: 0.4392\n",
            "Epoch 659/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4134 - val_loss: 0.4396\n",
            "Epoch 660/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4393\n",
            "Epoch 661/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4133 - val_loss: 0.4389\n",
            "Epoch 662/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4132 - val_loss: 0.4394\n",
            "Epoch 663/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4129 - val_loss: 0.4392\n",
            "Epoch 664/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4130 - val_loss: 0.4386\n",
            "Epoch 665/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4128 - val_loss: 0.4397\n",
            "Epoch 666/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4128 - val_loss: 0.4386\n",
            "Epoch 667/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4384\n",
            "Epoch 668/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4128 - val_loss: 0.4383\n",
            "Epoch 669/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4390\n",
            "Epoch 670/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4387\n",
            "Epoch 671/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4127 - val_loss: 0.4387\n",
            "Epoch 672/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4383\n",
            "Epoch 673/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4125 - val_loss: 0.4387\n",
            "Epoch 674/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.4381\n",
            "Epoch 675/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4123 - val_loss: 0.4384\n",
            "Epoch 676/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4121 - val_loss: 0.4381\n",
            "Epoch 677/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.4375\n",
            "Epoch 678/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4120 - val_loss: 0.4391\n",
            "Epoch 679/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.4379\n",
            "Epoch 680/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4119 - val_loss: 0.4372\n",
            "Epoch 681/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4117 - val_loss: 0.4377\n",
            "Epoch 682/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4379\n",
            "Epoch 683/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4376\n",
            "Epoch 684/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4392\n",
            "Epoch 685/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4116 - val_loss: 0.4379\n",
            "Epoch 686/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4115 - val_loss: 0.4376\n",
            "Epoch 687/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4114 - val_loss: 0.4371\n",
            "Epoch 688/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4112 - val_loss: 0.4370\n",
            "Epoch 689/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4113 - val_loss: 0.4369\n",
            "Epoch 690/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4110 - val_loss: 0.4376\n",
            "Epoch 691/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4110 - val_loss: 0.4380\n",
            "Epoch 692/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4111 - val_loss: 0.4371\n",
            "Epoch 693/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4371\n",
            "Epoch 694/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4372\n",
            "Epoch 695/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4108 - val_loss: 0.4376\n",
            "Epoch 696/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4367\n",
            "Epoch 697/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4107 - val_loss: 0.4370\n",
            "Epoch 698/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4106 - val_loss: 0.4368\n",
            "Epoch 699/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4105 - val_loss: 0.4373\n",
            "Epoch 700/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4109 - val_loss: 0.4371\n",
            "Epoch 701/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4103 - val_loss: 0.4370\n",
            "Epoch 702/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4367\n",
            "Epoch 703/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4105 - val_loss: 0.4367\n",
            "Epoch 704/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4102 - val_loss: 0.4369\n",
            "Epoch 705/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4102 - val_loss: 0.4366\n",
            "Epoch 706/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4102 - val_loss: 0.4366\n",
            "Epoch 707/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4103 - val_loss: 0.4370\n",
            "Epoch 708/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4099 - val_loss: 0.4360\n",
            "Epoch 709/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4099 - val_loss: 0.4363\n",
            "Epoch 710/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4100 - val_loss: 0.4357\n",
            "Epoch 711/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4099 - val_loss: 0.4363\n",
            "Epoch 712/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4099 - val_loss: 0.4360\n",
            "Epoch 713/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4098 - val_loss: 0.4357\n",
            "Epoch 714/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4097 - val_loss: 0.4367\n",
            "Epoch 715/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4095 - val_loss: 0.4361\n",
            "Epoch 716/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4361\n",
            "Epoch 717/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4096 - val_loss: 0.4357\n",
            "Epoch 718/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.4354\n",
            "Epoch 719/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4352\n",
            "Epoch 720/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4096 - val_loss: 0.4352\n",
            "Epoch 721/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4094 - val_loss: 0.4353\n",
            "Epoch 722/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4092 - val_loss: 0.4363\n",
            "Epoch 723/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.4357\n",
            "Epoch 724/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4089 - val_loss: 0.4362\n",
            "Epoch 725/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4091 - val_loss: 0.4365\n",
            "Epoch 726/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4090 - val_loss: 0.4363\n",
            "Epoch 727/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4091 - val_loss: 0.4360\n",
            "Epoch 728/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4088 - val_loss: 0.4353\n",
            "Epoch 729/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4088 - val_loss: 0.4358\n",
            "Epoch 730/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4355\n",
            "Epoch 731/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4087 - val_loss: 0.4349\n",
            "Epoch 732/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4087 - val_loss: 0.4353\n",
            "Epoch 733/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4085 - val_loss: 0.4370\n",
            "Epoch 734/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4087 - val_loss: 0.4355\n",
            "Epoch 735/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4085 - val_loss: 0.4359\n",
            "Epoch 736/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4086 - val_loss: 0.4359\n",
            "Epoch 737/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.4353\n",
            "Epoch 738/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4084 - val_loss: 0.4353\n",
            "Epoch 739/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4083 - val_loss: 0.4350\n",
            "Epoch 740/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4084 - val_loss: 0.4348\n",
            "Epoch 741/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4082 - val_loss: 0.4346\n",
            "Epoch 742/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4081 - val_loss: 0.4351\n",
            "Epoch 743/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4082 - val_loss: 0.4356\n",
            "Epoch 744/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4349\n",
            "Epoch 745/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4350\n",
            "Epoch 746/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4349\n",
            "Epoch 747/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4345\n",
            "Epoch 748/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4349\n",
            "Epoch 749/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4079 - val_loss: 0.4353\n",
            "Epoch 750/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4078 - val_loss: 0.4347\n",
            "Epoch 751/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4077 - val_loss: 0.4346\n",
            "Epoch 752/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4080 - val_loss: 0.4351\n",
            "Epoch 753/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4079 - val_loss: 0.4346\n",
            "Epoch 754/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4075 - val_loss: 0.4347\n",
            "Epoch 755/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4074 - val_loss: 0.4348\n",
            "Epoch 756/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4075 - val_loss: 0.4344\n",
            "Epoch 757/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4344\n",
            "Epoch 758/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4074 - val_loss: 0.4342\n",
            "Epoch 759/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4073 - val_loss: 0.4344\n",
            "Epoch 760/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4074 - val_loss: 0.4344\n",
            "Epoch 761/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4345\n",
            "Epoch 762/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.4343\n",
            "Epoch 763/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4072 - val_loss: 0.4341\n",
            "Epoch 764/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4072 - val_loss: 0.4342\n",
            "Epoch 765/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4344\n",
            "Epoch 766/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4071 - val_loss: 0.4341\n",
            "Epoch 767/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4068 - val_loss: 0.4348\n",
            "Epoch 768/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4069 - val_loss: 0.4341\n",
            "Epoch 769/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4069 - val_loss: 0.4348\n",
            "Epoch 770/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4066 - val_loss: 0.4344\n",
            "Epoch 771/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4067 - val_loss: 0.4343\n",
            "Epoch 772/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4336\n",
            "Epoch 773/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4066 - val_loss: 0.4338\n",
            "Epoch 774/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4334\n",
            "Epoch 775/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4068 - val_loss: 0.4332\n",
            "Epoch 776/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.4340\n",
            "Epoch 777/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4066 - val_loss: 0.4341\n",
            "Epoch 778/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4064 - val_loss: 0.4333\n",
            "Epoch 779/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4065 - val_loss: 0.4337\n",
            "Epoch 780/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4063 - val_loss: 0.4333\n",
            "Epoch 781/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4065 - val_loss: 0.4341\n",
            "Epoch 782/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4343\n",
            "Epoch 783/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4338\n",
            "Epoch 784/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4060 - val_loss: 0.4342\n",
            "Epoch 785/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4332\n",
            "Epoch 786/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4336\n",
            "Epoch 787/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4063 - val_loss: 0.4335\n",
            "Epoch 788/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4340\n",
            "Epoch 789/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4062 - val_loss: 0.4340\n",
            "Epoch 790/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4059 - val_loss: 0.4337\n",
            "Epoch 791/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4335\n",
            "Epoch 792/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4337\n",
            "Epoch 793/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4056 - val_loss: 0.4325\n",
            "Epoch 794/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4338\n",
            "Epoch 795/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4057 - val_loss: 0.4332\n",
            "Epoch 796/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4058 - val_loss: 0.4341\n",
            "Epoch 797/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4337\n",
            "Epoch 798/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4333\n",
            "Epoch 799/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4055 - val_loss: 0.4335\n",
            "Epoch 800/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4054 - val_loss: 0.4332\n",
            "Epoch 801/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4053 - val_loss: 0.4334\n",
            "Epoch 802/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4053 - val_loss: 0.4334\n",
            "Epoch 803/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4056 - val_loss: 0.4337\n",
            "Epoch 804/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4052 - val_loss: 0.4331\n",
            "Epoch 805/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4052 - val_loss: 0.4335\n",
            "Epoch 806/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4051 - val_loss: 0.4347\n",
            "Epoch 807/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4338\n",
            "Epoch 808/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4332\n",
            "Epoch 809/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4051 - val_loss: 0.4332\n",
            "Epoch 810/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4331\n",
            "Epoch 811/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4048 - val_loss: 0.4337\n",
            "Epoch 812/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4050 - val_loss: 0.4331\n",
            "Epoch 813/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4333\n",
            "Epoch 814/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4046 - val_loss: 0.4327\n",
            "Epoch 815/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4340\n",
            "Epoch 816/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4331\n",
            "Epoch 817/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4322\n",
            "Epoch 818/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4046 - val_loss: 0.4323\n",
            "Epoch 819/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4047 - val_loss: 0.4326\n",
            "Epoch 820/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4326\n",
            "Epoch 821/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4044 - val_loss: 0.4332\n",
            "Epoch 822/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4342\n",
            "Epoch 823/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4326\n",
            "Epoch 824/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4318\n",
            "Epoch 825/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4045 - val_loss: 0.4321\n",
            "Epoch 826/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4043 - val_loss: 0.4330\n",
            "Epoch 827/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4322\n",
            "Epoch 828/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4040 - val_loss: 0.4325\n",
            "Epoch 829/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4325\n",
            "Epoch 830/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4041 - val_loss: 0.4325\n",
            "Epoch 831/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4322\n",
            "Epoch 832/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4317\n",
            "Epoch 833/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4039 - val_loss: 0.4321\n",
            "Epoch 834/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4038 - val_loss: 0.4325\n",
            "Epoch 835/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.4321\n",
            "Epoch 836/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4037 - val_loss: 0.4318\n",
            "Epoch 837/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.4317\n",
            "Epoch 838/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.4320\n",
            "Epoch 839/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.4325\n",
            "Epoch 840/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.4326\n",
            "Epoch 841/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4323\n",
            "Epoch 842/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4035 - val_loss: 0.4317\n",
            "Epoch 843/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4318\n",
            "Epoch 844/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4036 - val_loss: 0.4318\n",
            "Epoch 845/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4032 - val_loss: 0.4321\n",
            "Epoch 846/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4321\n",
            "Epoch 847/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4033 - val_loss: 0.4319\n",
            "Epoch 848/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4034 - val_loss: 0.4324\n",
            "Epoch 849/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4323\n",
            "Epoch 850/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4325\n",
            "Epoch 851/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4314\n",
            "Epoch 852/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4029 - val_loss: 0.4318\n",
            "Epoch 853/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4322\n",
            "Epoch 854/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4030 - val_loss: 0.4315\n",
            "Epoch 855/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4028 - val_loss: 0.4313\n",
            "Epoch 856/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4028 - val_loss: 0.4325\n",
            "Epoch 857/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4028 - val_loss: 0.4315\n",
            "Epoch 858/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.4317\n",
            "Epoch 859/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4028 - val_loss: 0.4314\n",
            "Epoch 860/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4026 - val_loss: 0.4316\n",
            "Epoch 861/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4025 - val_loss: 0.4311\n",
            "Epoch 862/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4025 - val_loss: 0.4310\n",
            "Epoch 863/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4025 - val_loss: 0.4313\n",
            "Epoch 864/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4025 - val_loss: 0.4306\n",
            "Epoch 865/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4025 - val_loss: 0.4311\n",
            "Epoch 866/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4023 - val_loss: 0.4308\n",
            "Epoch 867/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4023 - val_loss: 0.4313\n",
            "Epoch 868/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4307\n",
            "Epoch 869/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4024 - val_loss: 0.4312\n",
            "Epoch 870/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4023 - val_loss: 0.4311\n",
            "Epoch 871/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4022 - val_loss: 0.4309\n",
            "Epoch 872/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4020 - val_loss: 0.4320\n",
            "Epoch 873/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4310\n",
            "Epoch 874/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4021 - val_loss: 0.4305\n",
            "Epoch 875/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4019 - val_loss: 0.4303\n",
            "Epoch 876/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.4302\n",
            "Epoch 877/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4019 - val_loss: 0.4315\n",
            "Epoch 878/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.4306\n",
            "Epoch 879/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4020 - val_loss: 0.4308\n",
            "Epoch 880/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4021 - val_loss: 0.4309\n",
            "Epoch 881/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4017 - val_loss: 0.4306\n",
            "Epoch 882/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4015 - val_loss: 0.4315\n",
            "Epoch 883/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4018 - val_loss: 0.4309\n",
            "Epoch 884/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4017 - val_loss: 0.4303\n",
            "Epoch 885/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4016 - val_loss: 0.4308\n",
            "Epoch 886/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.4013 - val_loss: 0.4309\n",
            "Epoch 887/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4016 - val_loss: 0.4308\n",
            "Epoch 888/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4015 - val_loss: 0.4312\n",
            "Epoch 889/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4014 - val_loss: 0.4302\n",
            "Epoch 890/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4313\n",
            "Epoch 891/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4016 - val_loss: 0.4302\n",
            "Epoch 892/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4012 - val_loss: 0.4303\n",
            "Epoch 893/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4302\n",
            "Epoch 894/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.4304\n",
            "Epoch 895/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.4012 - val_loss: 0.4300\n",
            "Epoch 896/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.4305\n",
            "Epoch 897/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4012 - val_loss: 0.4303\n",
            "Epoch 898/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.4300\n",
            "Epoch 899/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4010 - val_loss: 0.4297\n",
            "Epoch 900/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4008 - val_loss: 0.4296\n",
            "Epoch 901/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4011 - val_loss: 0.4297\n",
            "Epoch 902/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4009 - val_loss: 0.4295\n",
            "Epoch 903/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4008 - val_loss: 0.4297\n",
            "Epoch 904/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4292\n",
            "Epoch 905/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4010 - val_loss: 0.4292\n",
            "Epoch 906/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4006 - val_loss: 0.4292\n",
            "Epoch 907/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4005 - val_loss: 0.4295\n",
            "Epoch 908/10000\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.4007 - val_loss: 0.4296\n",
            "Epoch 909/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4005 - val_loss: 0.4296\n",
            "Epoch 910/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4003 - val_loss: 0.4305\n",
            "Epoch 911/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4003 - val_loss: 0.4296\n",
            "Epoch 912/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4002 - val_loss: 0.4297\n",
            "Epoch 913/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4304\n",
            "Epoch 914/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4003 - val_loss: 0.4295\n",
            "Epoch 915/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4299\n",
            "Epoch 916/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4293\n",
            "Epoch 917/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4002 - val_loss: 0.4296\n",
            "Epoch 918/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4003 - val_loss: 0.4298\n",
            "Epoch 919/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4000 - val_loss: 0.4289\n",
            "Epoch 920/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4004 - val_loss: 0.4295\n",
            "Epoch 921/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.4001 - val_loss: 0.4291\n",
            "Epoch 922/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4000 - val_loss: 0.4290\n",
            "Epoch 923/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3999 - val_loss: 0.4294\n",
            "Epoch 924/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3998 - val_loss: 0.4295\n",
            "Epoch 925/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3997 - val_loss: 0.4286\n",
            "Epoch 926/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.4001 - val_loss: 0.4285\n",
            "Epoch 927/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3997 - val_loss: 0.4293\n",
            "Epoch 928/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3997 - val_loss: 0.4292\n",
            "Epoch 929/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3996 - val_loss: 0.4289\n",
            "Epoch 930/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.4289\n",
            "Epoch 931/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3996 - val_loss: 0.4293\n",
            "Epoch 932/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.4293\n",
            "Epoch 933/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3995 - val_loss: 0.4287\n",
            "Epoch 934/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3994 - val_loss: 0.4296\n",
            "Epoch 935/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3994 - val_loss: 0.4293\n",
            "Epoch 936/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3997 - val_loss: 0.4290\n",
            "Epoch 937/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3996 - val_loss: 0.4287\n",
            "Epoch 938/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3993 - val_loss: 0.4289\n",
            "Epoch 939/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3992 - val_loss: 0.4297\n",
            "Epoch 940/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3992 - val_loss: 0.4290\n",
            "Epoch 941/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3996 - val_loss: 0.4289\n",
            "Epoch 942/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3993 - val_loss: 0.4290\n",
            "Epoch 943/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3992 - val_loss: 0.4288\n",
            "Epoch 944/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3993 - val_loss: 0.4295\n",
            "Epoch 945/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3990 - val_loss: 0.4285\n",
            "Epoch 946/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3990 - val_loss: 0.4294\n",
            "Epoch 947/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3991 - val_loss: 0.4285\n",
            "Epoch 948/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3991 - val_loss: 0.4283\n",
            "Epoch 949/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3989 - val_loss: 0.4286\n",
            "Epoch 950/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3991 - val_loss: 0.4285\n",
            "Epoch 951/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4289\n",
            "Epoch 952/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4287\n",
            "Epoch 953/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3988 - val_loss: 0.4284\n",
            "Epoch 954/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3988 - val_loss: 0.4298\n",
            "Epoch 955/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3989 - val_loss: 0.4293\n",
            "Epoch 956/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3987 - val_loss: 0.4290\n",
            "Epoch 957/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3988 - val_loss: 0.4292\n",
            "Epoch 958/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3986 - val_loss: 0.4280\n",
            "Epoch 959/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3988 - val_loss: 0.4279\n",
            "Epoch 960/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3985 - val_loss: 0.4283\n",
            "Epoch 961/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4287\n",
            "Epoch 962/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4284\n",
            "Epoch 963/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3986 - val_loss: 0.4284\n",
            "Epoch 964/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4290\n",
            "Epoch 965/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3985 - val_loss: 0.4281\n",
            "Epoch 966/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4286\n",
            "Epoch 967/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4278\n",
            "Epoch 968/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4282\n",
            "Epoch 969/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4289\n",
            "Epoch 970/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3982 - val_loss: 0.4282\n",
            "Epoch 971/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4285\n",
            "Epoch 972/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3982 - val_loss: 0.4282\n",
            "Epoch 973/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3981 - val_loss: 0.4276\n",
            "Epoch 974/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3980 - val_loss: 0.4281\n",
            "Epoch 975/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3983 - val_loss: 0.4280\n",
            "Epoch 976/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3980 - val_loss: 0.4279\n",
            "Epoch 977/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3980 - val_loss: 0.4279\n",
            "Epoch 978/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3979 - val_loss: 0.4280\n",
            "Epoch 979/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3978 - val_loss: 0.4280\n",
            "Epoch 980/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3977 - val_loss: 0.4278\n",
            "Epoch 981/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3980 - val_loss: 0.4280\n",
            "Epoch 982/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3976 - val_loss: 0.4280\n",
            "Epoch 983/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3977 - val_loss: 0.4281\n",
            "Epoch 984/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3976 - val_loss: 0.4277\n",
            "Epoch 985/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3976 - val_loss: 0.4275\n",
            "Epoch 986/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3975 - val_loss: 0.4282\n",
            "Epoch 987/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3975 - val_loss: 0.4285\n",
            "Epoch 988/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3974 - val_loss: 0.4288\n",
            "Epoch 989/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3975 - val_loss: 0.4278\n",
            "Epoch 990/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3977 - val_loss: 0.4278\n",
            "Epoch 991/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.4273\n",
            "Epoch 992/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.4277\n",
            "Epoch 993/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3974 - val_loss: 0.4272\n",
            "Epoch 994/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.4274\n",
            "Epoch 995/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.4276\n",
            "Epoch 996/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3971 - val_loss: 0.4280\n",
            "Epoch 997/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3971 - val_loss: 0.4278\n",
            "Epoch 998/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3973 - val_loss: 0.4274\n",
            "Epoch 999/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.4278\n",
            "Epoch 1000/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3971 - val_loss: 0.4280\n",
            "Epoch 1001/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3972 - val_loss: 0.4277\n",
            "Epoch 1002/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3971 - val_loss: 0.4279\n",
            "Epoch 1003/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3968 - val_loss: 0.4278\n",
            "Epoch 1004/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3969 - val_loss: 0.4276\n",
            "Epoch 1005/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3969 - val_loss: 0.4275\n",
            "Epoch 1006/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3969 - val_loss: 0.4272\n",
            "Epoch 1007/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3967 - val_loss: 0.4273\n",
            "Epoch 1008/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3969 - val_loss: 0.4275\n",
            "Epoch 1009/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4276\n",
            "Epoch 1010/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4272\n",
            "Epoch 1011/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3967 - val_loss: 0.4270\n",
            "Epoch 1012/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4274\n",
            "Epoch 1013/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3964 - val_loss: 0.4269\n",
            "Epoch 1014/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3965 - val_loss: 0.4274\n",
            "Epoch 1015/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4285\n",
            "Epoch 1016/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3967 - val_loss: 0.4269\n",
            "Epoch 1017/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3964 - val_loss: 0.4278\n",
            "Epoch 1018/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4266\n",
            "Epoch 1019/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3966 - val_loss: 0.4274\n",
            "Epoch 1020/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3963 - val_loss: 0.4265\n",
            "Epoch 1021/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.4270\n",
            "Epoch 1022/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3964 - val_loss: 0.4264\n",
            "Epoch 1023/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3961 - val_loss: 0.4278\n",
            "Epoch 1024/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3961 - val_loss: 0.4268\n",
            "Epoch 1025/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3963 - val_loss: 0.4265\n",
            "Epoch 1026/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3963 - val_loss: 0.4273\n",
            "Epoch 1027/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.4266\n",
            "Epoch 1028/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3961 - val_loss: 0.4275\n",
            "Epoch 1029/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3962 - val_loss: 0.4266\n",
            "Epoch 1030/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3960 - val_loss: 0.4271\n",
            "Epoch 1031/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3962 - val_loss: 0.4271\n",
            "Epoch 1032/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3962 - val_loss: 0.4271\n",
            "Epoch 1033/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3958 - val_loss: 0.4273\n",
            "Epoch 1034/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3958 - val_loss: 0.4267\n",
            "Epoch 1035/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.4272\n",
            "Epoch 1036/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3959 - val_loss: 0.4272\n",
            "Epoch 1037/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3956 - val_loss: 0.4259\n",
            "Epoch 1038/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3959 - val_loss: 0.4265\n",
            "Epoch 1039/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3956 - val_loss: 0.4269\n",
            "Epoch 1040/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3959 - val_loss: 0.4271\n",
            "Epoch 1041/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3959 - val_loss: 0.4270\n",
            "Epoch 1042/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3956 - val_loss: 0.4262\n",
            "Epoch 1043/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3957 - val_loss: 0.4263\n",
            "Epoch 1044/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3955 - val_loss: 0.4263\n",
            "Epoch 1045/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3954 - val_loss: 0.4267\n",
            "Epoch 1046/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3956 - val_loss: 0.4261\n",
            "Epoch 1047/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3954 - val_loss: 0.4271\n",
            "Epoch 1048/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3956 - val_loss: 0.4264\n",
            "Epoch 1049/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3955 - val_loss: 0.4258\n",
            "Epoch 1050/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3955 - val_loss: 0.4263\n",
            "Epoch 1051/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.4262\n",
            "Epoch 1052/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3952 - val_loss: 0.4266\n",
            "Epoch 1053/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3952 - val_loss: 0.4259\n",
            "Epoch 1054/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3951 - val_loss: 0.4266\n",
            "Epoch 1055/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3952 - val_loss: 0.4261\n",
            "Epoch 1056/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.4261\n",
            "Epoch 1057/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3950 - val_loss: 0.4258\n",
            "Epoch 1058/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3951 - val_loss: 0.4258\n",
            "Epoch 1059/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3948 - val_loss: 0.4261\n",
            "Epoch 1060/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3953 - val_loss: 0.4260\n",
            "Epoch 1061/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3952 - val_loss: 0.4262\n",
            "Epoch 1062/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3950 - val_loss: 0.4265\n",
            "Epoch 1063/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3949 - val_loss: 0.4262\n",
            "Epoch 1064/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3949 - val_loss: 0.4264\n",
            "Epoch 1065/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4260\n",
            "Epoch 1066/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3948 - val_loss: 0.4257\n",
            "Epoch 1067/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3949 - val_loss: 0.4260\n",
            "Epoch 1068/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4278\n",
            "Epoch 1069/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3950 - val_loss: 0.4261\n",
            "Epoch 1070/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4259\n",
            "Epoch 1071/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4261\n",
            "Epoch 1072/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4260\n",
            "Epoch 1073/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4258\n",
            "Epoch 1074/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3947 - val_loss: 0.4259\n",
            "Epoch 1075/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3945 - val_loss: 0.4258\n",
            "Epoch 1076/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3944 - val_loss: 0.4257\n",
            "Epoch 1077/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3946 - val_loss: 0.4255\n",
            "Epoch 1078/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4266\n",
            "Epoch 1079/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3944 - val_loss: 0.4260\n",
            "Epoch 1080/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3944 - val_loss: 0.4257\n",
            "Epoch 1081/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3944 - val_loss: 0.4260\n",
            "Epoch 1082/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3944 - val_loss: 0.4263\n",
            "Epoch 1083/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4261\n",
            "Epoch 1084/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4254\n",
            "Epoch 1085/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3946 - val_loss: 0.4254\n",
            "Epoch 1086/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3942 - val_loss: 0.4250\n",
            "Epoch 1087/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3943 - val_loss: 0.4254\n",
            "Epoch 1088/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3940 - val_loss: 0.4258\n",
            "Epoch 1089/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3941 - val_loss: 0.4254\n",
            "Epoch 1090/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4267\n",
            "Epoch 1091/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3939 - val_loss: 0.4255\n",
            "Epoch 1092/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3940 - val_loss: 0.4253\n",
            "Epoch 1093/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4254\n",
            "Epoch 1094/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3938 - val_loss: 0.4266\n",
            "Epoch 1095/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3941 - val_loss: 0.4256\n",
            "Epoch 1096/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3938 - val_loss: 0.4256\n",
            "Epoch 1097/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3940 - val_loss: 0.4260\n",
            "Epoch 1098/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3938 - val_loss: 0.4257\n",
            "Epoch 1099/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4250\n",
            "Epoch 1100/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3937 - val_loss: 0.4258\n",
            "Epoch 1101/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3936 - val_loss: 0.4255\n",
            "Epoch 1102/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3934 - val_loss: 0.4250\n",
            "Epoch 1103/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3933 - val_loss: 0.4270\n",
            "Epoch 1104/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3937 - val_loss: 0.4264\n",
            "Epoch 1105/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3935 - val_loss: 0.4253\n",
            "Epoch 1106/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3935 - val_loss: 0.4254\n",
            "Epoch 1107/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3934 - val_loss: 0.4253\n",
            "Epoch 1108/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3935 - val_loss: 0.4250\n",
            "Epoch 1109/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3933 - val_loss: 0.4256\n",
            "Epoch 1110/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3935 - val_loss: 0.4258\n",
            "Epoch 1111/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3932 - val_loss: 0.4253\n",
            "Epoch 1112/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3933 - val_loss: 0.4256\n",
            "Epoch 1113/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3934 - val_loss: 0.4253\n",
            "Epoch 1114/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3931 - val_loss: 0.4250\n",
            "Epoch 1115/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3932 - val_loss: 0.4251\n",
            "Epoch 1116/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3932 - val_loss: 0.4249\n",
            "Epoch 1117/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.4249\n",
            "Epoch 1118/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.4256\n",
            "Epoch 1119/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3929 - val_loss: 0.4255\n",
            "Epoch 1120/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.4245\n",
            "Epoch 1121/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3930 - val_loss: 0.4250\n",
            "Epoch 1122/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.4255\n",
            "Epoch 1123/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3931 - val_loss: 0.4253\n",
            "Epoch 1124/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3927 - val_loss: 0.4244\n",
            "Epoch 1125/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3929 - val_loss: 0.4241\n",
            "Epoch 1126/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3927 - val_loss: 0.4244\n",
            "Epoch 1127/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3928 - val_loss: 0.4249\n",
            "Epoch 1128/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3927 - val_loss: 0.4245\n",
            "Epoch 1129/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3924 - val_loss: 0.4260\n",
            "Epoch 1130/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3928 - val_loss: 0.4252\n",
            "Epoch 1131/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3926 - val_loss: 0.4244\n",
            "Epoch 1132/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3926 - val_loss: 0.4247\n",
            "Epoch 1133/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3924 - val_loss: 0.4244\n",
            "Epoch 1134/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3924 - val_loss: 0.4244\n",
            "Epoch 1135/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3924 - val_loss: 0.4250\n",
            "Epoch 1136/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.4242\n",
            "Epoch 1137/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3923 - val_loss: 0.4245\n",
            "Epoch 1138/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3925 - val_loss: 0.4248\n",
            "Epoch 1139/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.4247\n",
            "Epoch 1140/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3922 - val_loss: 0.4247\n",
            "Epoch 1141/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.4244\n",
            "Epoch 1142/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.4244\n",
            "Epoch 1143/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3920 - val_loss: 0.4244\n",
            "Epoch 1144/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3923 - val_loss: 0.4240\n",
            "Epoch 1145/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.4242\n",
            "Epoch 1146/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3917 - val_loss: 0.4251\n",
            "Epoch 1147/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.4244\n",
            "Epoch 1148/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3918 - val_loss: 0.4250\n",
            "Epoch 1149/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.4241\n",
            "Epoch 1150/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3919 - val_loss: 0.4241\n",
            "Epoch 1151/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.4241\n",
            "Epoch 1152/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3916 - val_loss: 0.4240\n",
            "Epoch 1153/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3920 - val_loss: 0.4235\n",
            "Epoch 1154/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3915 - val_loss: 0.4239\n",
            "Epoch 1155/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3915 - val_loss: 0.4247\n",
            "Epoch 1156/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3918 - val_loss: 0.4243\n",
            "Epoch 1157/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3915 - val_loss: 0.4240\n",
            "Epoch 1158/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3915 - val_loss: 0.4243\n",
            "Epoch 1159/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3915 - val_loss: 0.4243\n",
            "Epoch 1160/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3915 - val_loss: 0.4242\n",
            "Epoch 1161/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3912 - val_loss: 0.4240\n",
            "Epoch 1162/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3914 - val_loss: 0.4239\n",
            "Epoch 1163/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3913 - val_loss: 0.4237\n",
            "Epoch 1164/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3913 - val_loss: 0.4235\n",
            "Epoch 1165/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3912 - val_loss: 0.4235\n",
            "Epoch 1166/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3914 - val_loss: 0.4235\n",
            "Epoch 1167/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3910 - val_loss: 0.4233\n",
            "Epoch 1168/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3911 - val_loss: 0.4233\n",
            "Epoch 1169/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3909 - val_loss: 0.4235\n",
            "Epoch 1170/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3911 - val_loss: 0.4238\n",
            "Epoch 1171/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3909 - val_loss: 0.4242\n",
            "Epoch 1172/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3912 - val_loss: 0.4238\n",
            "Epoch 1173/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3909 - val_loss: 0.4241\n",
            "Epoch 1174/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3910 - val_loss: 0.4235\n",
            "Epoch 1175/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3908 - val_loss: 0.4233\n",
            "Epoch 1176/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3905 - val_loss: 0.4233\n",
            "Epoch 1177/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3905 - val_loss: 0.4245\n",
            "Epoch 1178/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3908 - val_loss: 0.4242\n",
            "Epoch 1179/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3908 - val_loss: 0.4235\n",
            "Epoch 1180/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3907 - val_loss: 0.4236\n",
            "Epoch 1181/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3908 - val_loss: 0.4232\n",
            "Epoch 1182/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3906 - val_loss: 0.4243\n",
            "Epoch 1183/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3906 - val_loss: 0.4234\n",
            "Epoch 1184/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3905 - val_loss: 0.4230\n",
            "Epoch 1185/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3903 - val_loss: 0.4234\n",
            "Epoch 1186/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3905 - val_loss: 0.4233\n",
            "Epoch 1187/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3903 - val_loss: 0.4233\n",
            "Epoch 1188/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3904 - val_loss: 0.4236\n",
            "Epoch 1189/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3904 - val_loss: 0.4233\n",
            "Epoch 1190/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3903 - val_loss: 0.4234\n",
            "Epoch 1191/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3903 - val_loss: 0.4239\n",
            "Epoch 1192/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3905 - val_loss: 0.4233\n",
            "Epoch 1193/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3903 - val_loss: 0.4231\n",
            "Epoch 1194/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3901 - val_loss: 0.4233\n",
            "Epoch 1195/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3899 - val_loss: 0.4243\n",
            "Epoch 1196/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3902 - val_loss: 0.4235\n",
            "Epoch 1197/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3901 - val_loss: 0.4236\n",
            "Epoch 1198/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3901 - val_loss: 0.4228\n",
            "Epoch 1199/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4242\n",
            "Epoch 1200/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3898 - val_loss: 0.4228\n",
            "Epoch 1201/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4238\n",
            "Epoch 1202/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3898 - val_loss: 0.4230\n",
            "Epoch 1203/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3900 - val_loss: 0.4228\n",
            "Epoch 1204/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3899 - val_loss: 0.4230\n",
            "Epoch 1205/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3898 - val_loss: 0.4232\n",
            "Epoch 1206/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4229\n",
            "Epoch 1207/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4227\n",
            "Epoch 1208/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3896 - val_loss: 0.4230\n",
            "Epoch 1209/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3896 - val_loss: 0.4226\n",
            "Epoch 1210/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3895 - val_loss: 0.4230\n",
            "Epoch 1211/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3890 - val_loss: 0.4246\n",
            "Epoch 1212/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3897 - val_loss: 0.4230\n",
            "Epoch 1213/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3893 - val_loss: 0.4233\n",
            "Epoch 1214/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3893 - val_loss: 0.4231\n",
            "Epoch 1215/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3892 - val_loss: 0.4238\n",
            "Epoch 1216/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3890 - val_loss: 0.4242\n",
            "Epoch 1217/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3895 - val_loss: 0.4231\n",
            "Epoch 1218/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3892 - val_loss: 0.4236\n",
            "Epoch 1219/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3895 - val_loss: 0.4235\n",
            "Epoch 1220/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3893 - val_loss: 0.4235\n",
            "Epoch 1221/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3893 - val_loss: 0.4230\n",
            "Epoch 1222/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3890 - val_loss: 0.4233\n",
            "Epoch 1223/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3890 - val_loss: 0.4232\n",
            "Epoch 1224/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3890 - val_loss: 0.4229\n",
            "Epoch 1225/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3890 - val_loss: 0.4232\n",
            "Epoch 1226/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3888 - val_loss: 0.4228\n",
            "Epoch 1227/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3889 - val_loss: 0.4227\n",
            "Epoch 1228/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3888 - val_loss: 0.4227\n",
            "Epoch 1229/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3888 - val_loss: 0.4227\n",
            "Epoch 1230/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3885 - val_loss: 0.4236\n",
            "Epoch 1231/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.4232\n",
            "Epoch 1232/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.4237\n",
            "Epoch 1233/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3885 - val_loss: 0.4226\n",
            "Epoch 1234/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3886 - val_loss: 0.4225\n",
            "Epoch 1235/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 0.4227\n",
            "Epoch 1236/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3887 - val_loss: 0.4228\n",
            "Epoch 1237/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3885 - val_loss: 0.4235\n",
            "Epoch 1238/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3886 - val_loss: 0.4225\n",
            "Epoch 1239/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3884 - val_loss: 0.4229\n",
            "Epoch 1240/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3886 - val_loss: 0.4227\n",
            "Epoch 1241/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3883 - val_loss: 0.4222\n",
            "Epoch 1242/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3883 - val_loss: 0.4227\n",
            "Epoch 1243/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3882 - val_loss: 0.4226\n",
            "Epoch 1244/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3882 - val_loss: 0.4225\n",
            "Epoch 1245/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3881 - val_loss: 0.4237\n",
            "Epoch 1246/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3883 - val_loss: 0.4233\n",
            "Epoch 1247/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3882 - val_loss: 0.4235\n",
            "Epoch 1248/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3880 - val_loss: 0.4226\n",
            "Epoch 1249/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3880 - val_loss: 0.4222\n",
            "Epoch 1250/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3882 - val_loss: 0.4225\n",
            "Epoch 1251/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3879 - val_loss: 0.4241\n",
            "Epoch 1252/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3879 - val_loss: 0.4230\n",
            "Epoch 1253/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3878 - val_loss: 0.4226\n",
            "Epoch 1254/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3878 - val_loss: 0.4224\n",
            "Epoch 1255/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3878 - val_loss: 0.4231\n",
            "Epoch 1256/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3877 - val_loss: 0.4236\n",
            "Epoch 1257/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3875 - val_loss: 0.4226\n",
            "Epoch 1258/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3879 - val_loss: 0.4231\n",
            "Epoch 1259/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3876 - val_loss: 0.4223\n",
            "Epoch 1260/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3874 - val_loss: 0.4231\n",
            "Epoch 1261/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3874 - val_loss: 0.4242\n",
            "Epoch 1262/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3878 - val_loss: 0.4235\n",
            "Epoch 1263/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3871 - val_loss: 0.4224\n",
            "Epoch 1264/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3877 - val_loss: 0.4229\n",
            "Epoch 1265/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3874 - val_loss: 0.4225\n",
            "Epoch 1266/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3876 - val_loss: 0.4226\n",
            "Epoch 1267/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3877 - val_loss: 0.4220\n",
            "Epoch 1268/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3872 - val_loss: 0.4234\n",
            "Epoch 1269/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3875 - val_loss: 0.4226\n",
            "Epoch 1270/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3874 - val_loss: 0.4222\n",
            "Epoch 1271/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3871 - val_loss: 0.4220\n",
            "Epoch 1272/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3874 - val_loss: 0.4218\n",
            "Epoch 1273/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3871 - val_loss: 0.4222\n",
            "Epoch 1274/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3873 - val_loss: 0.4223\n",
            "Epoch 1275/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3870 - val_loss: 0.4237\n",
            "Epoch 1276/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3872 - val_loss: 0.4222\n",
            "Epoch 1277/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3870 - val_loss: 0.4232\n",
            "Epoch 1278/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3872 - val_loss: 0.4227\n",
            "Epoch 1279/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3869 - val_loss: 0.4225\n",
            "Epoch 1280/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3867 - val_loss: 0.4224\n",
            "Epoch 1281/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3871 - val_loss: 0.4219\n",
            "Epoch 1282/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3868 - val_loss: 0.4232\n",
            "Epoch 1283/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3869 - val_loss: 0.4228\n",
            "Epoch 1284/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3868 - val_loss: 0.4220\n",
            "Epoch 1285/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3869 - val_loss: 0.4228\n",
            "Epoch 1286/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3865 - val_loss: 0.4233\n",
            "Epoch 1287/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3869 - val_loss: 0.4218\n",
            "Epoch 1288/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3867 - val_loss: 0.4229\n",
            "Epoch 1289/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3869 - val_loss: 0.4227\n",
            "Epoch 1290/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3867 - val_loss: 0.4232\n",
            "Epoch 1291/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3868 - val_loss: 0.4230\n",
            "Epoch 1292/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3865 - val_loss: 0.4226\n",
            "Epoch 1293/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3865 - val_loss: 0.4224\n",
            "Epoch 1294/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3865 - val_loss: 0.4221\n",
            "Epoch 1295/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3865 - val_loss: 0.4224\n",
            "Epoch 1296/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3862 - val_loss: 0.4229\n",
            "Epoch 1297/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3865 - val_loss: 0.4222\n",
            "Epoch 1298/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3865 - val_loss: 0.4219\n",
            "Epoch 1299/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3865 - val_loss: 0.4225\n",
            "Epoch 1300/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3864 - val_loss: 0.4222\n",
            "Epoch 1301/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3864 - val_loss: 0.4224\n",
            "Epoch 1302/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3862 - val_loss: 0.4224\n",
            "Epoch 1303/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.4221\n",
            "Epoch 1304/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3862 - val_loss: 0.4215\n",
            "Epoch 1305/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3862 - val_loss: 0.4223\n",
            "Epoch 1306/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3860 - val_loss: 0.4221\n",
            "Epoch 1307/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3861 - val_loss: 0.4220\n",
            "Epoch 1308/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3861 - val_loss: 0.4226\n",
            "Epoch 1309/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3859 - val_loss: 0.4223\n",
            "Epoch 1310/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3861 - val_loss: 0.4222\n",
            "Epoch 1311/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3859 - val_loss: 0.4220\n",
            "Epoch 1312/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3860 - val_loss: 0.4220\n",
            "Epoch 1313/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3859 - val_loss: 0.4225\n",
            "Epoch 1314/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3860 - val_loss: 0.4221\n",
            "Epoch 1315/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3857 - val_loss: 0.4220\n",
            "Epoch 1316/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3857 - val_loss: 0.4228\n",
            "Epoch 1317/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3860 - val_loss: 0.4223\n",
            "Epoch 1318/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.4221\n",
            "Epoch 1319/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3859 - val_loss: 0.4216\n",
            "Epoch 1320/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3856 - val_loss: 0.4218\n",
            "Epoch 1321/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3857 - val_loss: 0.4216\n",
            "Epoch 1322/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3857 - val_loss: 0.4222\n",
            "Epoch 1323/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3858 - val_loss: 0.4218\n",
            "Epoch 1324/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3854 - val_loss: 0.4220\n",
            "Epoch 1325/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3855 - val_loss: 0.4216\n",
            "Epoch 1326/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3855 - val_loss: 0.4221\n",
            "Epoch 1327/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3856 - val_loss: 0.4216\n",
            "Epoch 1328/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3854 - val_loss: 0.4222\n",
            "Epoch 1329/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3856 - val_loss: 0.4220\n",
            "Epoch 1330/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3855 - val_loss: 0.4218\n",
            "Epoch 1331/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3852 - val_loss: 0.4215\n",
            "Epoch 1332/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3852 - val_loss: 0.4214\n",
            "Epoch 1333/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3853 - val_loss: 0.4219\n",
            "Epoch 1334/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3854 - val_loss: 0.4220\n",
            "Epoch 1335/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3854 - val_loss: 0.4225\n",
            "Epoch 1336/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3850 - val_loss: 0.4214\n",
            "Epoch 1337/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3851 - val_loss: 0.4222\n",
            "Epoch 1338/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3852 - val_loss: 0.4226\n",
            "Epoch 1339/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3851 - val_loss: 0.4217\n",
            "Epoch 1340/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3850 - val_loss: 0.4219\n",
            "Epoch 1341/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3850 - val_loss: 0.4218\n",
            "Epoch 1342/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3849 - val_loss: 0.4230\n",
            "Epoch 1343/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3850 - val_loss: 0.4220\n",
            "Epoch 1344/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3848 - val_loss: 0.4220\n",
            "Epoch 1345/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3849 - val_loss: 0.4216\n",
            "Epoch 1346/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3849 - val_loss: 0.4220\n",
            "Epoch 1347/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3849 - val_loss: 0.4218\n",
            "Epoch 1348/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3849 - val_loss: 0.4213\n",
            "Epoch 1349/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3848 - val_loss: 0.4216\n",
            "Epoch 1350/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3847 - val_loss: 0.4214\n",
            "Epoch 1351/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3847 - val_loss: 0.4213\n",
            "Epoch 1352/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3845 - val_loss: 0.4217\n",
            "Epoch 1353/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3847 - val_loss: 0.4219\n",
            "Epoch 1354/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3847 - val_loss: 0.4222\n",
            "Epoch 1355/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3844 - val_loss: 0.4217\n",
            "Epoch 1356/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3845 - val_loss: 0.4214\n",
            "Epoch 1357/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3846 - val_loss: 0.4222\n",
            "Epoch 1358/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3844 - val_loss: 0.4217\n",
            "Epoch 1359/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3846 - val_loss: 0.4215\n",
            "Epoch 1360/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.4227\n",
            "Epoch 1361/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3843 - val_loss: 0.4218\n",
            "Epoch 1362/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3843 - val_loss: 0.4219\n",
            "Epoch 1363/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3844 - val_loss: 0.4227\n",
            "Epoch 1364/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3846 - val_loss: 0.4230\n",
            "Epoch 1365/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3841 - val_loss: 0.4218\n",
            "Epoch 1366/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3841 - val_loss: 0.4220\n",
            "Epoch 1367/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.4231\n",
            "Epoch 1368/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3844 - val_loss: 0.4225\n",
            "Epoch 1369/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.4214\n",
            "Epoch 1370/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.4215\n",
            "Epoch 1371/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3842 - val_loss: 0.4220\n",
            "Epoch 1372/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.4220\n",
            "Epoch 1373/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3839 - val_loss: 0.4222\n",
            "Epoch 1374/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3839 - val_loss: 0.4220\n",
            "Epoch 1375/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.4212\n",
            "Epoch 1376/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3839 - val_loss: 0.4214\n",
            "Epoch 1377/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3840 - val_loss: 0.4215\n",
            "Epoch 1378/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.4212\n",
            "Epoch 1379/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.4212\n",
            "Epoch 1380/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3841 - val_loss: 0.4214\n",
            "Epoch 1381/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.4215\n",
            "Epoch 1382/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3838 - val_loss: 0.4214\n",
            "Epoch 1383/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.4217\n",
            "Epoch 1384/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.4219\n",
            "Epoch 1385/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.4218\n",
            "Epoch 1386/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.4214\n",
            "Epoch 1387/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.4214\n",
            "Epoch 1388/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3834 - val_loss: 0.4219\n",
            "Epoch 1389/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.4213\n",
            "Epoch 1390/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.4212\n",
            "Epoch 1391/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.4233\n",
            "Epoch 1392/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3836 - val_loss: 0.4214\n",
            "Epoch 1393/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3832 - val_loss: 0.4213\n",
            "Epoch 1394/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3835 - val_loss: 0.4213\n",
            "Epoch 1395/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3830 - val_loss: 0.4222\n",
            "Epoch 1396/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3832 - val_loss: 0.4215\n",
            "Epoch 1397/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3832 - val_loss: 0.4215\n",
            "Epoch 1398/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.4208\n",
            "Epoch 1399/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.4216\n",
            "Epoch 1400/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3833 - val_loss: 0.4213\n",
            "Epoch 1401/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3829 - val_loss: 0.4213\n",
            "Epoch 1402/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.4220\n",
            "Epoch 1403/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3830 - val_loss: 0.4212\n",
            "Epoch 1404/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3829 - val_loss: 0.4217\n",
            "Epoch 1405/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3830 - val_loss: 0.4213\n",
            "Epoch 1406/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3828 - val_loss: 0.4210\n",
            "Epoch 1407/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3828 - val_loss: 0.4220\n",
            "Epoch 1408/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3829 - val_loss: 0.4208\n",
            "Epoch 1409/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3831 - val_loss: 0.4212\n",
            "Epoch 1410/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.4215\n",
            "Epoch 1411/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3827 - val_loss: 0.4219\n",
            "Epoch 1412/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3825 - val_loss: 0.4211\n",
            "Epoch 1413/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3829 - val_loss: 0.4211\n",
            "Epoch 1414/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3827 - val_loss: 0.4214\n",
            "Epoch 1415/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.4214\n",
            "Epoch 1416/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.4212\n",
            "Epoch 1417/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3828 - val_loss: 0.4215\n",
            "Epoch 1418/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.4212\n",
            "Epoch 1419/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3824 - val_loss: 0.4215\n",
            "Epoch 1420/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3826 - val_loss: 0.4211\n",
            "Epoch 1421/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3825 - val_loss: 0.4207\n",
            "Epoch 1422/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3826 - val_loss: 0.4212\n",
            "Epoch 1423/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3824 - val_loss: 0.4216\n",
            "Epoch 1424/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3824 - val_loss: 0.4225\n",
            "Epoch 1425/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3823 - val_loss: 0.4213\n",
            "Epoch 1426/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3823 - val_loss: 0.4218\n",
            "Epoch 1427/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3823 - val_loss: 0.4215\n",
            "Epoch 1428/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3822 - val_loss: 0.4211\n",
            "Epoch 1429/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3822 - val_loss: 0.4208\n",
            "Epoch 1430/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.4208\n",
            "Epoch 1431/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3821 - val_loss: 0.4210\n",
            "Epoch 1432/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3821 - val_loss: 0.4209\n",
            "Epoch 1433/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3822 - val_loss: 0.4212\n",
            "Epoch 1434/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3822 - val_loss: 0.4212\n",
            "Epoch 1435/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3819 - val_loss: 0.4209\n",
            "Epoch 1436/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3820 - val_loss: 0.4219\n",
            "Epoch 1437/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3818 - val_loss: 0.4210\n",
            "Epoch 1438/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3820 - val_loss: 0.4215\n",
            "Epoch 1439/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3820 - val_loss: 0.4212\n",
            "Epoch 1440/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3820 - val_loss: 0.4205\n",
            "Epoch 1441/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.4207\n",
            "Epoch 1442/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3818 - val_loss: 0.4207\n",
            "Epoch 1443/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.4210\n",
            "Epoch 1444/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3817 - val_loss: 0.4214\n",
            "Epoch 1445/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.4214\n",
            "Epoch 1446/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3819 - val_loss: 0.4208\n",
            "Epoch 1447/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.4208\n",
            "Epoch 1448/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3813 - val_loss: 0.4203\n",
            "Epoch 1449/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3817 - val_loss: 0.4205\n",
            "Epoch 1450/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.4214\n",
            "Epoch 1451/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.4213\n",
            "Epoch 1452/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3815 - val_loss: 0.4215\n",
            "Epoch 1453/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3814 - val_loss: 0.4210\n",
            "Epoch 1454/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3813 - val_loss: 0.4216\n",
            "Epoch 1455/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3814 - val_loss: 0.4207\n",
            "Epoch 1456/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3812 - val_loss: 0.4211\n",
            "Epoch 1457/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3812 - val_loss: 0.4204\n",
            "Epoch 1458/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3812 - val_loss: 0.4211\n",
            "Epoch 1459/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3812 - val_loss: 0.4217\n",
            "Epoch 1460/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3814 - val_loss: 0.4207\n",
            "Epoch 1461/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3808 - val_loss: 0.4220\n",
            "Epoch 1462/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3814 - val_loss: 0.4210\n",
            "Epoch 1463/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3812 - val_loss: 0.4207\n",
            "Epoch 1464/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3810 - val_loss: 0.4208\n",
            "Epoch 1465/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3812 - val_loss: 0.4205\n",
            "Epoch 1466/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.4203\n",
            "Epoch 1467/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3808 - val_loss: 0.4207\n",
            "Epoch 1468/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.4209\n",
            "Epoch 1469/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3810 - val_loss: 0.4209\n",
            "Epoch 1470/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3806 - val_loss: 0.4199\n",
            "Epoch 1471/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3808 - val_loss: 0.4206\n",
            "Epoch 1472/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3808 - val_loss: 0.4207\n",
            "Epoch 1473/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3809 - val_loss: 0.4207\n",
            "Epoch 1474/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3809 - val_loss: 0.4207\n",
            "Epoch 1475/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3806 - val_loss: 0.4205\n",
            "Epoch 1476/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3807 - val_loss: 0.4204\n",
            "Epoch 1477/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3805 - val_loss: 0.4205\n",
            "Epoch 1478/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3806 - val_loss: 0.4210\n",
            "Epoch 1479/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3808 - val_loss: 0.4209\n",
            "Epoch 1480/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.4207\n",
            "Epoch 1481/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3804 - val_loss: 0.4205\n",
            "Epoch 1482/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3804 - val_loss: 0.4209\n",
            "Epoch 1483/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3805 - val_loss: 0.4208\n",
            "Epoch 1484/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3803 - val_loss: 0.4205\n",
            "Epoch 1485/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3803 - val_loss: 0.4209\n",
            "Epoch 1486/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3801 - val_loss: 0.4217\n",
            "Epoch 1487/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3803 - val_loss: 0.4210\n",
            "Epoch 1488/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3801 - val_loss: 0.4207\n",
            "Epoch 1489/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3802 - val_loss: 0.4206\n",
            "Epoch 1490/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.4205\n",
            "Epoch 1491/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.4210\n",
            "Epoch 1492/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.4211\n",
            "Epoch 1493/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3800 - val_loss: 0.4207\n",
            "Epoch 1494/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.4207\n",
            "Epoch 1495/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3797 - val_loss: 0.4214\n",
            "Epoch 1496/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3797 - val_loss: 0.4218\n",
            "Epoch 1497/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3797 - val_loss: 0.4202\n",
            "Epoch 1498/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3800 - val_loss: 0.4209\n",
            "Epoch 1499/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3797 - val_loss: 0.4209\n",
            "Epoch 1500/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3797 - val_loss: 0.4210\n",
            "Epoch 1501/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3797 - val_loss: 0.4207\n",
            "Epoch 1502/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3795 - val_loss: 0.4210\n",
            "Epoch 1503/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3797 - val_loss: 0.4203\n",
            "Epoch 1504/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3793 - val_loss: 0.4207\n",
            "Epoch 1505/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3794 - val_loss: 0.4218\n",
            "Epoch 1506/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3796 - val_loss: 0.4208\n",
            "Epoch 1507/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3795 - val_loss: 0.4204\n",
            "Epoch 1508/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3794 - val_loss: 0.4201\n",
            "Epoch 1509/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3794 - val_loss: 0.4209\n",
            "Epoch 1510/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3793 - val_loss: 0.4206\n",
            "Epoch 1511/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3794 - val_loss: 0.4206\n",
            "Epoch 1512/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3792 - val_loss: 0.4203\n",
            "Epoch 1513/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3793 - val_loss: 0.4204\n",
            "Epoch 1514/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3792 - val_loss: 0.4207\n",
            "Epoch 1515/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3791 - val_loss: 0.4198\n",
            "Epoch 1516/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3793 - val_loss: 0.4201\n",
            "Epoch 1517/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3789 - val_loss: 0.4204\n",
            "Epoch 1518/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3792 - val_loss: 0.4205\n",
            "Epoch 1519/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3794 - val_loss: 0.4200\n",
            "Epoch 1520/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.4201\n",
            "Epoch 1521/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3790 - val_loss: 0.4197\n",
            "Epoch 1522/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3790 - val_loss: 0.4195\n",
            "Epoch 1523/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3792 - val_loss: 0.4200\n",
            "Epoch 1524/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3789 - val_loss: 0.4195\n",
            "Epoch 1525/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.4199\n",
            "Epoch 1526/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3787 - val_loss: 0.4196\n",
            "Epoch 1527/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3787 - val_loss: 0.4197\n",
            "Epoch 1528/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3788 - val_loss: 0.4202\n",
            "Epoch 1529/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3788 - val_loss: 0.4199\n",
            "Epoch 1530/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3786 - val_loss: 0.4196\n",
            "Epoch 1531/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3785 - val_loss: 0.4203\n",
            "Epoch 1532/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3784 - val_loss: 0.4203\n",
            "Epoch 1533/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3787 - val_loss: 0.4197\n",
            "Epoch 1534/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3786 - val_loss: 0.4197\n",
            "Epoch 1535/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3785 - val_loss: 0.4201\n",
            "Epoch 1536/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.4200\n",
            "Epoch 1537/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3782 - val_loss: 0.4193\n",
            "Epoch 1538/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.4196\n",
            "Epoch 1539/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.4204\n",
            "Epoch 1540/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3784 - val_loss: 0.4201\n",
            "Epoch 1541/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3782 - val_loss: 0.4197\n",
            "Epoch 1542/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3784 - val_loss: 0.4203\n",
            "Epoch 1543/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3783 - val_loss: 0.4199\n",
            "Epoch 1544/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3780 - val_loss: 0.4198\n",
            "Epoch 1545/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3785 - val_loss: 0.4196\n",
            "Epoch 1546/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3782 - val_loss: 0.4200\n",
            "Epoch 1547/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3782 - val_loss: 0.4203\n",
            "Epoch 1548/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3780 - val_loss: 0.4191\n",
            "Epoch 1549/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3782 - val_loss: 0.4199\n",
            "Epoch 1550/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3780 - val_loss: 0.4206\n",
            "Epoch 1551/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3783 - val_loss: 0.4200\n",
            "Epoch 1552/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3780 - val_loss: 0.4193\n",
            "Epoch 1553/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.4196\n",
            "Epoch 1554/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3780 - val_loss: 0.4195\n",
            "Epoch 1555/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3781 - val_loss: 0.4194\n",
            "Epoch 1556/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.4194\n",
            "Epoch 1557/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3779 - val_loss: 0.4201\n",
            "Epoch 1558/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3784 - val_loss: 0.4195\n",
            "Epoch 1559/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3777 - val_loss: 0.4196\n",
            "Epoch 1560/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3780 - val_loss: 0.4196\n",
            "Epoch 1561/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3779 - val_loss: 0.4195\n",
            "Epoch 1562/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3775 - val_loss: 0.4207\n",
            "Epoch 1563/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3777 - val_loss: 0.4191\n",
            "Epoch 1564/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3776 - val_loss: 0.4195\n",
            "Epoch 1565/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4203\n",
            "Epoch 1566/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.4198\n",
            "Epoch 1567/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3777 - val_loss: 0.4196\n",
            "Epoch 1568/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3775 - val_loss: 0.4194\n",
            "Epoch 1569/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3776 - val_loss: 0.4195\n",
            "Epoch 1570/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4191\n",
            "Epoch 1571/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3776 - val_loss: 0.4193\n",
            "Epoch 1572/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3774 - val_loss: 0.4191\n",
            "Epoch 1573/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3777 - val_loss: 0.4190\n",
            "Epoch 1574/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3775 - val_loss: 0.4202\n",
            "Epoch 1575/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3773 - val_loss: 0.4196\n",
            "Epoch 1576/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3775 - val_loss: 0.4194\n",
            "Epoch 1577/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 0.4203\n",
            "Epoch 1578/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.4195\n",
            "Epoch 1579/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3777 - val_loss: 0.4195\n",
            "Epoch 1580/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3773 - val_loss: 0.4193\n",
            "Epoch 1581/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3772 - val_loss: 0.4192\n",
            "Epoch 1582/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3774 - val_loss: 0.4190\n",
            "Epoch 1583/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3773 - val_loss: 0.4192\n",
            "Epoch 1584/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 0.4190\n",
            "Epoch 1585/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3772 - val_loss: 0.4193\n",
            "Epoch 1586/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3771 - val_loss: 0.4191\n",
            "Epoch 1587/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.4195\n",
            "Epoch 1588/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3772 - val_loss: 0.4198\n",
            "Epoch 1589/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3772 - val_loss: 0.4191\n",
            "Epoch 1590/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3772 - val_loss: 0.4187\n",
            "Epoch 1591/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.4194\n",
            "Epoch 1592/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3771 - val_loss: 0.4192\n",
            "Epoch 1593/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3771 - val_loss: 0.4190\n",
            "Epoch 1594/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.4189\n",
            "Epoch 1595/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.4191\n",
            "Epoch 1596/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.4190\n",
            "Epoch 1597/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.4188\n",
            "Epoch 1598/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3768 - val_loss: 0.4194\n",
            "Epoch 1599/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3768 - val_loss: 0.4189\n",
            "Epoch 1600/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3767 - val_loss: 0.4186\n",
            "Epoch 1601/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.4192\n",
            "Epoch 1602/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3770 - val_loss: 0.4196\n",
            "Epoch 1603/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3769 - val_loss: 0.4201\n",
            "Epoch 1604/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3770 - val_loss: 0.4189\n",
            "Epoch 1605/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3768 - val_loss: 0.4192\n",
            "Epoch 1606/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.4195\n",
            "Epoch 1607/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3768 - val_loss: 0.4186\n",
            "Epoch 1608/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3765 - val_loss: 0.4188\n",
            "Epoch 1609/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4187\n",
            "Epoch 1610/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.4185\n",
            "Epoch 1611/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3766 - val_loss: 0.4196\n",
            "Epoch 1612/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.4189\n",
            "Epoch 1613/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3763 - val_loss: 0.4191\n",
            "Epoch 1614/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3765 - val_loss: 0.4185\n",
            "Epoch 1615/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3766 - val_loss: 0.4189\n",
            "Epoch 1616/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3765 - val_loss: 0.4185\n",
            "Epoch 1617/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3765 - val_loss: 0.4191\n",
            "Epoch 1618/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3766 - val_loss: 0.4185\n",
            "Epoch 1619/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3762 - val_loss: 0.4187\n",
            "Epoch 1620/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.4204\n",
            "Epoch 1621/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3763 - val_loss: 0.4187\n",
            "Epoch 1622/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3764 - val_loss: 0.4191\n",
            "Epoch 1623/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3765 - val_loss: 0.4191\n",
            "Epoch 1624/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3762 - val_loss: 0.4195\n",
            "Epoch 1625/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3757 - val_loss: 0.4189\n",
            "Epoch 1626/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3765 - val_loss: 0.4182\n",
            "Epoch 1627/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3764 - val_loss: 0.4186\n",
            "Epoch 1628/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3763 - val_loss: 0.4188\n",
            "Epoch 1629/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.4190\n",
            "Epoch 1630/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3762 - val_loss: 0.4187\n",
            "Epoch 1631/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3762 - val_loss: 0.4185\n",
            "Epoch 1632/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3764 - val_loss: 0.4193\n",
            "Epoch 1633/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3761 - val_loss: 0.4190\n",
            "Epoch 1634/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3761 - val_loss: 0.4190\n",
            "Epoch 1635/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3764 - val_loss: 0.4198\n",
            "Epoch 1636/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3761 - val_loss: 0.4188\n",
            "Epoch 1637/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3761 - val_loss: 0.4187\n",
            "Epoch 1638/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.4183\n",
            "Epoch 1639/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3759 - val_loss: 0.4184\n",
            "Epoch 1640/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3761 - val_loss: 0.4189\n",
            "Epoch 1641/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.4186\n",
            "Epoch 1642/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3762 - val_loss: 0.4185\n",
            "Epoch 1643/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3760 - val_loss: 0.4186\n",
            "Epoch 1644/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3757 - val_loss: 0.4187\n",
            "Epoch 1645/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3759 - val_loss: 0.4186\n",
            "Epoch 1646/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3757 - val_loss: 0.4191\n",
            "Epoch 1647/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3759 - val_loss: 0.4189\n",
            "Epoch 1648/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3759 - val_loss: 0.4186\n",
            "Epoch 1649/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3759 - val_loss: 0.4189\n",
            "Epoch 1650/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.4198\n",
            "Epoch 1651/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3755 - val_loss: 0.4202\n",
            "Epoch 1652/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3757 - val_loss: 0.4186\n",
            "Epoch 1653/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3755 - val_loss: 0.4189\n",
            "Epoch 1654/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3758 - val_loss: 0.4180\n",
            "Epoch 1655/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3756 - val_loss: 0.4184\n",
            "Epoch 1656/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3755 - val_loss: 0.4187\n",
            "Epoch 1657/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3759 - val_loss: 0.4185\n",
            "Epoch 1658/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.4188\n",
            "Epoch 1659/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3757 - val_loss: 0.4185\n",
            "Epoch 1660/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3755 - val_loss: 0.4188\n",
            "Epoch 1661/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3755 - val_loss: 0.4183\n",
            "Epoch 1662/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3752 - val_loss: 0.4196\n",
            "Epoch 1663/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3753 - val_loss: 0.4179\n",
            "Epoch 1664/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3756 - val_loss: 0.4182\n",
            "Epoch 1665/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3756 - val_loss: 0.4184\n",
            "Epoch 1666/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4184\n",
            "Epoch 1667/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3754 - val_loss: 0.4178\n",
            "Epoch 1668/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3752 - val_loss: 0.4184\n",
            "Epoch 1669/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3754 - val_loss: 0.4183\n",
            "Epoch 1670/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.4183\n",
            "Epoch 1671/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3754 - val_loss: 0.4185\n",
            "Epoch 1672/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3753 - val_loss: 0.4191\n",
            "Epoch 1673/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3753 - val_loss: 0.4181\n",
            "Epoch 1674/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.4184\n",
            "Epoch 1675/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3753 - val_loss: 0.4188\n",
            "Epoch 1676/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.4180\n",
            "Epoch 1677/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.4182\n",
            "Epoch 1678/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3749 - val_loss: 0.4186\n",
            "Epoch 1679/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3753 - val_loss: 0.4179\n",
            "Epoch 1680/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3753 - val_loss: 0.4182\n",
            "Epoch 1681/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.4181\n",
            "Epoch 1682/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3751 - val_loss: 0.4185\n",
            "Epoch 1683/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.4185\n",
            "Epoch 1684/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.4180\n",
            "Epoch 1685/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3749 - val_loss: 0.4186\n",
            "Epoch 1686/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.4186\n",
            "Epoch 1687/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3750 - val_loss: 0.4183\n",
            "Epoch 1688/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3751 - val_loss: 0.4177\n",
            "Epoch 1689/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.4181\n",
            "Epoch 1690/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3749 - val_loss: 0.4177\n",
            "Epoch 1691/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3750 - val_loss: 0.4183\n",
            "Epoch 1692/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.4186\n",
            "Epoch 1693/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.4182\n",
            "Epoch 1694/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.4181\n",
            "Epoch 1695/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3748 - val_loss: 0.4177\n",
            "Epoch 1696/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3747 - val_loss: 0.4180\n",
            "Epoch 1697/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.4182\n",
            "Epoch 1698/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3748 - val_loss: 0.4184\n",
            "Epoch 1699/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.4188\n",
            "Epoch 1700/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3746 - val_loss: 0.4182\n",
            "Epoch 1701/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3745 - val_loss: 0.4180\n",
            "Epoch 1702/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3747 - val_loss: 0.4175\n",
            "Epoch 1703/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.4183\n",
            "Epoch 1704/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3744 - val_loss: 0.4177\n",
            "Epoch 1705/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3747 - val_loss: 0.4186\n",
            "Epoch 1706/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3745 - val_loss: 0.4182\n",
            "Epoch 1707/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3748 - val_loss: 0.4179\n",
            "Epoch 1708/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.4185\n",
            "Epoch 1709/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3745 - val_loss: 0.4185\n",
            "Epoch 1710/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3745 - val_loss: 0.4180\n",
            "Epoch 1711/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3744 - val_loss: 0.4175\n",
            "Epoch 1712/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.4178\n",
            "Epoch 1713/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3744 - val_loss: 0.4177\n",
            "Epoch 1714/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3743 - val_loss: 0.4182\n",
            "Epoch 1715/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3743 - val_loss: 0.4179\n",
            "Epoch 1716/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4177\n",
            "Epoch 1717/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3742 - val_loss: 0.4185\n",
            "Epoch 1718/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.4177\n",
            "Epoch 1719/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3742 - val_loss: 0.4184\n",
            "Epoch 1720/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3741 - val_loss: 0.4181\n",
            "Epoch 1721/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3741 - val_loss: 0.4178\n",
            "Epoch 1722/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3744 - val_loss: 0.4178\n",
            "Epoch 1723/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3740 - val_loss: 0.4176\n",
            "Epoch 1724/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3741 - val_loss: 0.4173\n",
            "Epoch 1725/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3741 - val_loss: 0.4179\n",
            "Epoch 1726/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4173\n",
            "Epoch 1727/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3740 - val_loss: 0.4173\n",
            "Epoch 1728/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3741 - val_loss: 0.4173\n",
            "Epoch 1729/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3741 - val_loss: 0.4176\n",
            "Epoch 1730/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3740 - val_loss: 0.4177\n",
            "Epoch 1731/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3740 - val_loss: 0.4176\n",
            "Epoch 1732/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3738 - val_loss: 0.4175\n",
            "Epoch 1733/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3738 - val_loss: 0.4183\n",
            "Epoch 1734/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3740 - val_loss: 0.4185\n",
            "Epoch 1735/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3741 - val_loss: 0.4177\n",
            "Epoch 1736/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3737 - val_loss: 0.4181\n",
            "Epoch 1737/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.4176\n",
            "Epoch 1738/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3738 - val_loss: 0.4171\n",
            "Epoch 1739/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3740 - val_loss: 0.4179\n",
            "Epoch 1740/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3738 - val_loss: 0.4179\n",
            "Epoch 1741/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3736 - val_loss: 0.4178\n",
            "Epoch 1742/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3739 - val_loss: 0.4178\n",
            "Epoch 1743/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3737 - val_loss: 0.4175\n",
            "Epoch 1744/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.4176\n",
            "Epoch 1745/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3736 - val_loss: 0.4173\n",
            "Epoch 1746/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3736 - val_loss: 0.4174\n",
            "Epoch 1747/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3736 - val_loss: 0.4176\n",
            "Epoch 1748/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.4171\n",
            "Epoch 1749/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3734 - val_loss: 0.4175\n",
            "Epoch 1750/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3738 - val_loss: 0.4176\n",
            "Epoch 1751/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.4177\n",
            "Epoch 1752/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3733 - val_loss: 0.4176\n",
            "Epoch 1753/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3734 - val_loss: 0.4173\n",
            "Epoch 1754/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3737 - val_loss: 0.4173\n",
            "Epoch 1755/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3733 - val_loss: 0.4172\n",
            "Epoch 1756/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.4172\n",
            "Epoch 1757/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.4172\n",
            "Epoch 1758/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3734 - val_loss: 0.4177\n",
            "Epoch 1759/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4172\n",
            "Epoch 1760/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3735 - val_loss: 0.4175\n",
            "Epoch 1761/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3734 - val_loss: 0.4176\n",
            "Epoch 1762/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3733 - val_loss: 0.4183\n",
            "Epoch 1763/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3729 - val_loss: 0.4176\n",
            "Epoch 1764/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3735 - val_loss: 0.4170\n",
            "Epoch 1765/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 0.4172\n",
            "Epoch 1766/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4168\n",
            "Epoch 1767/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.4177\n",
            "Epoch 1768/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4174\n",
            "Epoch 1769/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3731 - val_loss: 0.4167\n",
            "Epoch 1770/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3731 - val_loss: 0.4172\n",
            "Epoch 1771/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3731 - val_loss: 0.4172\n",
            "Epoch 1772/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.4174\n",
            "Epoch 1773/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3731 - val_loss: 0.4172\n",
            "Epoch 1774/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3730 - val_loss: 0.4167\n",
            "Epoch 1775/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3730 - val_loss: 0.4171\n",
            "Epoch 1776/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 0.4174\n",
            "Epoch 1777/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3732 - val_loss: 0.4175\n",
            "Epoch 1778/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3730 - val_loss: 0.4171\n",
            "Epoch 1779/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.4169\n",
            "Epoch 1780/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.4180\n",
            "Epoch 1781/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3728 - val_loss: 0.4173\n",
            "Epoch 1782/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3727 - val_loss: 0.4175\n",
            "Epoch 1783/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3729 - val_loss: 0.4171\n",
            "Epoch 1784/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.4173\n",
            "Epoch 1785/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4171\n",
            "Epoch 1786/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3727 - val_loss: 0.4170\n",
            "Epoch 1787/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3727 - val_loss: 0.4175\n",
            "Epoch 1788/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4167\n",
            "Epoch 1789/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3726 - val_loss: 0.4170\n",
            "Epoch 1790/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3726 - val_loss: 0.4175\n",
            "Epoch 1791/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3722 - val_loss: 0.4186\n",
            "Epoch 1792/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3726 - val_loss: 0.4170\n",
            "Epoch 1793/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.4174\n",
            "Epoch 1794/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3725 - val_loss: 0.4169\n",
            "Epoch 1795/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3726 - val_loss: 0.4178\n",
            "Epoch 1796/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3727 - val_loss: 0.4180\n",
            "Epoch 1797/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3726 - val_loss: 0.4172\n",
            "Epoch 1798/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.4172\n",
            "Epoch 1799/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3726 - val_loss: 0.4170\n",
            "Epoch 1800/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.4181\n",
            "Epoch 1801/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3725 - val_loss: 0.4174\n",
            "Epoch 1802/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.4182\n",
            "Epoch 1803/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3724 - val_loss: 0.4172\n",
            "Epoch 1804/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3722 - val_loss: 0.4167\n",
            "Epoch 1805/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4168\n",
            "Epoch 1806/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3724 - val_loss: 0.4172\n",
            "Epoch 1807/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.4175\n",
            "Epoch 1808/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.4175\n",
            "Epoch 1809/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3723 - val_loss: 0.4169\n",
            "Epoch 1810/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3724 - val_loss: 0.4172\n",
            "Epoch 1811/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3722 - val_loss: 0.4177\n",
            "Epoch 1812/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3723 - val_loss: 0.4172\n",
            "Epoch 1813/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3724 - val_loss: 0.4171\n",
            "Epoch 1814/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3722 - val_loss: 0.4172\n",
            "Epoch 1815/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3721 - val_loss: 0.4170\n",
            "Epoch 1816/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3720 - val_loss: 0.4169\n",
            "Epoch 1817/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 0.4177\n",
            "Epoch 1818/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3722 - val_loss: 0.4174\n",
            "Epoch 1819/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.4172\n",
            "Epoch 1820/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3720 - val_loss: 0.4173\n",
            "Epoch 1821/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3719 - val_loss: 0.4170\n",
            "Epoch 1822/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3720 - val_loss: 0.4162\n",
            "Epoch 1823/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3723 - val_loss: 0.4165\n",
            "Epoch 1824/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3720 - val_loss: 0.4166\n",
            "Epoch 1825/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 0.4173\n",
            "Epoch 1826/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3718 - val_loss: 0.4165\n",
            "Epoch 1827/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 0.4170\n",
            "Epoch 1828/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3719 - val_loss: 0.4171\n",
            "Epoch 1829/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.4168\n",
            "Epoch 1830/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.4170\n",
            "Epoch 1831/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3719 - val_loss: 0.4171\n",
            "Epoch 1832/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.4167\n",
            "Epoch 1833/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3720 - val_loss: 0.4172\n",
            "Epoch 1834/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3721 - val_loss: 0.4165\n",
            "Epoch 1835/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3718 - val_loss: 0.4165\n",
            "Epoch 1836/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3717 - val_loss: 0.4163\n",
            "Epoch 1837/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3717 - val_loss: 0.4169\n",
            "Epoch 1838/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3717 - val_loss: 0.4166\n",
            "Epoch 1839/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3717 - val_loss: 0.4169\n",
            "Epoch 1840/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3717 - val_loss: 0.4165\n",
            "Epoch 1841/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.4170\n",
            "Epoch 1842/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3718 - val_loss: 0.4170\n",
            "Epoch 1843/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.4164\n",
            "Epoch 1844/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3714 - val_loss: 0.4168\n",
            "Epoch 1845/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3714 - val_loss: 0.4170\n",
            "Epoch 1846/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3716 - val_loss: 0.4166\n",
            "Epoch 1847/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3717 - val_loss: 0.4165\n",
            "Epoch 1848/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3715 - val_loss: 0.4163\n",
            "Epoch 1849/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3717 - val_loss: 0.4174\n",
            "Epoch 1850/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3714 - val_loss: 0.4171\n",
            "Epoch 1851/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3712 - val_loss: 0.4177\n",
            "Epoch 1852/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3714 - val_loss: 0.4171\n",
            "Epoch 1853/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3715 - val_loss: 0.4168\n",
            "Epoch 1854/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4159\n",
            "Epoch 1855/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.4161\n",
            "Epoch 1856/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3715 - val_loss: 0.4156\n",
            "Epoch 1857/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3712 - val_loss: 0.4172\n",
            "Epoch 1858/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3713 - val_loss: 0.4165\n",
            "Epoch 1859/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3713 - val_loss: 0.4164\n",
            "Epoch 1860/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3713 - val_loss: 0.4166\n",
            "Epoch 1861/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.4172\n",
            "Epoch 1862/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.4176\n",
            "Epoch 1863/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3707 - val_loss: 0.4171\n",
            "Epoch 1864/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3714 - val_loss: 0.4167\n",
            "Epoch 1865/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.4168\n",
            "Epoch 1866/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.4162\n",
            "Epoch 1867/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3712 - val_loss: 0.4162\n",
            "Epoch 1868/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3712 - val_loss: 0.4163\n",
            "Epoch 1869/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3709 - val_loss: 0.4164\n",
            "Epoch 1870/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3711 - val_loss: 0.4166\n",
            "Epoch 1871/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.4161\n",
            "Epoch 1872/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3712 - val_loss: 0.4164\n",
            "Epoch 1873/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3712 - val_loss: 0.4159\n",
            "Epoch 1874/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3709 - val_loss: 0.4164\n",
            "Epoch 1875/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3710 - val_loss: 0.4163\n",
            "Epoch 1876/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3709 - val_loss: 0.4163\n",
            "Epoch 1877/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3710 - val_loss: 0.4162\n",
            "Epoch 1878/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3709 - val_loss: 0.4160\n",
            "Epoch 1879/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.4159\n",
            "Epoch 1880/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3708 - val_loss: 0.4168\n",
            "Epoch 1881/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3711 - val_loss: 0.4164\n",
            "Epoch 1882/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3708 - val_loss: 0.4160\n",
            "Epoch 1883/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3708 - val_loss: 0.4163\n",
            "Epoch 1884/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3708 - val_loss: 0.4161\n",
            "Epoch 1885/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3705 - val_loss: 0.4172\n",
            "Epoch 1886/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3706 - val_loss: 0.4169\n",
            "Epoch 1887/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3707 - val_loss: 0.4155\n",
            "Epoch 1888/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3706 - val_loss: 0.4166\n",
            "Epoch 1889/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3707 - val_loss: 0.4163\n",
            "Epoch 1890/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3708 - val_loss: 0.4166\n",
            "Epoch 1891/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3708 - val_loss: 0.4166\n",
            "Epoch 1892/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3707 - val_loss: 0.4163\n",
            "Epoch 1893/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3705 - val_loss: 0.4162\n",
            "Epoch 1894/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3707 - val_loss: 0.4163\n",
            "Epoch 1895/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.4167\n",
            "Epoch 1896/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3707 - val_loss: 0.4170\n",
            "Epoch 1897/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.4165\n",
            "Epoch 1898/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3705 - val_loss: 0.4164\n",
            "Epoch 1899/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.4157\n",
            "Epoch 1900/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3706 - val_loss: 0.4161\n",
            "Epoch 1901/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3706 - val_loss: 0.4165\n",
            "Epoch 1902/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3705 - val_loss: 0.4161\n",
            "Epoch 1903/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.4164\n",
            "Epoch 1904/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3703 - val_loss: 0.4164\n",
            "Epoch 1905/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3703 - val_loss: 0.4166\n",
            "Epoch 1906/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3707 - val_loss: 0.4165\n",
            "Epoch 1907/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3703 - val_loss: 0.4163\n",
            "Epoch 1908/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3703 - val_loss: 0.4160\n",
            "Epoch 1909/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3705 - val_loss: 0.4173\n",
            "Epoch 1910/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3704 - val_loss: 0.4158\n",
            "Epoch 1911/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3701 - val_loss: 0.4158\n",
            "Epoch 1912/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.4157\n",
            "Epoch 1913/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.4162\n",
            "Epoch 1914/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3700 - val_loss: 0.4168\n",
            "Epoch 1915/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3704 - val_loss: 0.4163\n",
            "Epoch 1916/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.4165\n",
            "Epoch 1917/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.4163\n",
            "Epoch 1918/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3702 - val_loss: 0.4164\n",
            "Epoch 1919/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3701 - val_loss: 0.4164\n",
            "Epoch 1920/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3703 - val_loss: 0.4159\n",
            "Epoch 1921/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4162\n",
            "Epoch 1922/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.4163\n",
            "Epoch 1923/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4162\n",
            "Epoch 1924/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3700 - val_loss: 0.4163\n",
            "Epoch 1925/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4164\n",
            "Epoch 1926/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.4160\n",
            "Epoch 1927/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3700 - val_loss: 0.4157\n",
            "Epoch 1928/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4164\n",
            "Epoch 1929/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4157\n",
            "Epoch 1930/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4154\n",
            "Epoch 1931/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3697 - val_loss: 0.4156\n",
            "Epoch 1932/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4162\n",
            "Epoch 1933/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3701 - val_loss: 0.4162\n",
            "Epoch 1934/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3694 - val_loss: 0.4155\n",
            "Epoch 1935/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4163\n",
            "Epoch 1936/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3698 - val_loss: 0.4153\n",
            "Epoch 1937/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3693 - val_loss: 0.4165\n",
            "Epoch 1938/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3700 - val_loss: 0.4167\n",
            "Epoch 1939/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3698 - val_loss: 0.4162\n",
            "Epoch 1940/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3696 - val_loss: 0.4157\n",
            "Epoch 1941/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3695 - val_loss: 0.4160\n",
            "Epoch 1942/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3697 - val_loss: 0.4155\n",
            "Epoch 1943/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3696 - val_loss: 0.4158\n",
            "Epoch 1944/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3695 - val_loss: 0.4159\n",
            "Epoch 1945/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3699 - val_loss: 0.4165\n",
            "Epoch 1946/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3696 - val_loss: 0.4159\n",
            "Epoch 1947/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3695 - val_loss: 0.4156\n",
            "Epoch 1948/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3695 - val_loss: 0.4163\n",
            "Epoch 1949/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3695 - val_loss: 0.4158\n",
            "Epoch 1950/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3694 - val_loss: 0.4157\n",
            "Epoch 1951/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3696 - val_loss: 0.4162\n",
            "Epoch 1952/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3694 - val_loss: 0.4154\n",
            "Epoch 1953/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3694 - val_loss: 0.4158\n",
            "Epoch 1954/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3694 - val_loss: 0.4157\n",
            "Epoch 1955/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4152\n",
            "Epoch 1956/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3693 - val_loss: 0.4171\n",
            "Epoch 1957/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3693 - val_loss: 0.4154\n",
            "Epoch 1958/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3692 - val_loss: 0.4159\n",
            "Epoch 1959/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3693 - val_loss: 0.4163\n",
            "Epoch 1960/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3692 - val_loss: 0.4159\n",
            "Epoch 1961/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3690 - val_loss: 0.4157\n",
            "Epoch 1962/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3690 - val_loss: 0.4170\n",
            "Epoch 1963/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3692 - val_loss: 0.4154\n",
            "Epoch 1964/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3692 - val_loss: 0.4155\n",
            "Epoch 1965/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3693 - val_loss: 0.4157\n",
            "Epoch 1966/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.4190\n",
            "Epoch 1967/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3695 - val_loss: 0.4162\n",
            "Epoch 1968/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4159\n",
            "Epoch 1969/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3692 - val_loss: 0.4164\n",
            "Epoch 1970/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3689 - val_loss: 0.4157\n",
            "Epoch 1971/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4160\n",
            "Epoch 1972/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3690 - val_loss: 0.4157\n",
            "Epoch 1973/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3689 - val_loss: 0.4154\n",
            "Epoch 1974/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3690 - val_loss: 0.4155\n",
            "Epoch 1975/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3687 - val_loss: 0.4152\n",
            "Epoch 1976/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3689 - val_loss: 0.4158\n",
            "Epoch 1977/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4158\n",
            "Epoch 1978/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3688 - val_loss: 0.4153\n",
            "Epoch 1979/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3689 - val_loss: 0.4157\n",
            "Epoch 1980/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3691 - val_loss: 0.4166\n",
            "Epoch 1981/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3687 - val_loss: 0.4161\n",
            "Epoch 1982/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3690 - val_loss: 0.4161\n",
            "Epoch 1983/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3687 - val_loss: 0.4154\n",
            "Epoch 1984/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3689 - val_loss: 0.4155\n",
            "Epoch 1985/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3687 - val_loss: 0.4154\n",
            "Epoch 1986/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.4160\n",
            "Epoch 1987/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.4155\n",
            "Epoch 1988/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3688 - val_loss: 0.4155\n",
            "Epoch 1989/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3688 - val_loss: 0.4161\n",
            "Epoch 1990/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.4153\n",
            "Epoch 1991/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.4154\n",
            "Epoch 1992/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.4150\n",
            "Epoch 1993/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3685 - val_loss: 0.4159\n",
            "Epoch 1994/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3685 - val_loss: 0.4161\n",
            "Epoch 1995/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3687 - val_loss: 0.4153\n",
            "Epoch 1996/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.4154\n",
            "Epoch 1997/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.4160\n",
            "Epoch 1998/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.4158\n",
            "Epoch 1999/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.4154\n",
            "Epoch 2000/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3685 - val_loss: 0.4153\n",
            "Epoch 2001/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.4158\n",
            "Epoch 2002/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3686 - val_loss: 0.4152\n",
            "Epoch 2003/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3685 - val_loss: 0.4156\n",
            "Epoch 2004/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3684 - val_loss: 0.4154\n",
            "Epoch 2005/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.4156\n",
            "Epoch 2006/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3681 - val_loss: 0.4154\n",
            "Epoch 2007/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.4155\n",
            "Epoch 2008/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3682 - val_loss: 0.4159\n",
            "Epoch 2009/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3680 - val_loss: 0.4158\n",
            "Epoch 2010/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3684 - val_loss: 0.4152\n",
            "Epoch 2011/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3681 - val_loss: 0.4152\n",
            "Epoch 2012/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.4147\n",
            "Epoch 2013/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3685 - val_loss: 0.4157\n",
            "Epoch 2014/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3681 - val_loss: 0.4156\n",
            "Epoch 2015/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3681 - val_loss: 0.4157\n",
            "Epoch 2016/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3681 - val_loss: 0.4166\n",
            "Epoch 2017/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3682 - val_loss: 0.4162\n",
            "Epoch 2018/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3683 - val_loss: 0.4157\n",
            "Epoch 2019/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3681 - val_loss: 0.4148\n",
            "Epoch 2020/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3679 - val_loss: 0.4152\n",
            "Epoch 2021/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3681 - val_loss: 0.4153\n",
            "Epoch 2022/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3681 - val_loss: 0.4155\n",
            "Epoch 2023/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 0.4151\n",
            "Epoch 2024/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3679 - val_loss: 0.4156\n",
            "Epoch 2025/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3678 - val_loss: 0.4158\n",
            "Epoch 2026/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3679 - val_loss: 0.4153\n",
            "Epoch 2027/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3680 - val_loss: 0.4159\n",
            "Epoch 2028/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3680 - val_loss: 0.4160\n",
            "Epoch 2029/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3679 - val_loss: 0.4154\n",
            "Epoch 2030/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3678 - val_loss: 0.4149\n",
            "Epoch 2031/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3678 - val_loss: 0.4147\n",
            "Epoch 2032/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3679 - val_loss: 0.4151\n",
            "Epoch 2033/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 0.4148\n",
            "Epoch 2034/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.4154\n",
            "Epoch 2035/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3679 - val_loss: 0.4145\n",
            "Epoch 2036/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.4148\n",
            "Epoch 2037/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3679 - val_loss: 0.4152\n",
            "Epoch 2038/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 0.4154\n",
            "Epoch 2039/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.4163\n",
            "Epoch 2040/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3676 - val_loss: 0.4159\n",
            "Epoch 2041/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.4150\n",
            "Epoch 2042/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.4151\n",
            "Epoch 2043/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.4160\n",
            "Epoch 2044/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 0.4149\n",
            "Epoch 2045/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3674 - val_loss: 0.4154\n",
            "Epoch 2046/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3673 - val_loss: 0.4151\n",
            "Epoch 2047/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3674 - val_loss: 0.4149\n",
            "Epoch 2048/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3674 - val_loss: 0.4149\n",
            "Epoch 2049/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 0.4145\n",
            "Epoch 2050/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.4149\n",
            "Epoch 2051/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3674 - val_loss: 0.4152\n",
            "Epoch 2052/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.4145\n",
            "Epoch 2053/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.4144\n",
            "Epoch 2054/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3672 - val_loss: 0.4150\n",
            "Epoch 2055/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3674 - val_loss: 0.4145\n",
            "Epoch 2056/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.4149\n",
            "Epoch 2057/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3674 - val_loss: 0.4149\n",
            "Epoch 2058/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3669 - val_loss: 0.4160\n",
            "Epoch 2059/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3674 - val_loss: 0.4148\n",
            "Epoch 2060/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3674 - val_loss: 0.4143\n",
            "Epoch 2061/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.4153\n",
            "Epoch 2062/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3675 - val_loss: 0.4143\n",
            "Epoch 2063/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3670 - val_loss: 0.4160\n",
            "Epoch 2064/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3669 - val_loss: 0.4170\n",
            "Epoch 2065/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3664 - val_loss: 0.4144\n",
            "Epoch 2066/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3673 - val_loss: 0.4139\n",
            "Epoch 2067/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3670 - val_loss: 0.4153\n",
            "Epoch 2068/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3670 - val_loss: 0.4143\n",
            "Epoch 2069/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.4145\n",
            "Epoch 2070/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3669 - val_loss: 0.4141\n",
            "Epoch 2071/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3671 - val_loss: 0.4148\n",
            "Epoch 2072/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3669 - val_loss: 0.4152\n",
            "Epoch 2073/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3668 - val_loss: 0.4152\n",
            "Epoch 2074/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3669 - val_loss: 0.4144\n",
            "Epoch 2075/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3668 - val_loss: 0.4139\n",
            "Epoch 2076/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3668 - val_loss: 0.4147\n",
            "Epoch 2077/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3669 - val_loss: 0.4144\n",
            "Epoch 2078/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3668 - val_loss: 0.4145\n",
            "Epoch 2079/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3670 - val_loss: 0.4145\n",
            "Epoch 2080/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3668 - val_loss: 0.4144\n",
            "Epoch 2081/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3664 - val_loss: 0.4158\n",
            "Epoch 2082/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3667 - val_loss: 0.4148\n",
            "Epoch 2083/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3669 - val_loss: 0.4151\n",
            "Epoch 2084/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3668 - val_loss: 0.4145\n",
            "Epoch 2085/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.4145\n",
            "Epoch 2086/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3667 - val_loss: 0.4144\n",
            "Epoch 2087/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3667 - val_loss: 0.4139\n",
            "Epoch 2088/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4155\n",
            "Epoch 2089/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3666 - val_loss: 0.4148\n",
            "Epoch 2090/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4146\n",
            "Epoch 2091/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4153\n",
            "Epoch 2092/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4151\n",
            "Epoch 2093/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3668 - val_loss: 0.4145\n",
            "Epoch 2094/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4141\n",
            "Epoch 2095/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4145\n",
            "Epoch 2096/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3666 - val_loss: 0.4150\n",
            "Epoch 2097/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.4150\n",
            "Epoch 2098/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4145\n",
            "Epoch 2099/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4142\n",
            "Epoch 2100/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3665 - val_loss: 0.4138\n",
            "Epoch 2101/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3666 - val_loss: 0.4144\n",
            "Epoch 2102/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.4138\n",
            "Epoch 2103/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.4147\n",
            "Epoch 2104/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.4139\n",
            "Epoch 2105/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.4154\n",
            "Epoch 2106/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3664 - val_loss: 0.4142\n",
            "Epoch 2107/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.4141\n",
            "Epoch 2108/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.4156\n",
            "Epoch 2109/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.4148\n",
            "Epoch 2110/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3662 - val_loss: 0.4140\n",
            "Epoch 2111/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.4136\n",
            "Epoch 2112/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.4139\n",
            "Epoch 2113/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3663 - val_loss: 0.4147\n",
            "Epoch 2114/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3660 - val_loss: 0.4138\n",
            "Epoch 2115/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.4146\n",
            "Epoch 2116/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.4141\n",
            "Epoch 2117/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3661 - val_loss: 0.4140\n",
            "Epoch 2118/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3662 - val_loss: 0.4142\n",
            "Epoch 2119/10000\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.3659 - val_loss: 0.4145\n",
            "Epoch 2120/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3660 - val_loss: 0.4141\n",
            "Epoch 2121/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3661 - val_loss: 0.4137\n",
            "Epoch 2122/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3658 - val_loss: 0.4153\n",
            "Epoch 2123/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3658 - val_loss: 0.4142\n",
            "Epoch 2124/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.4144\n",
            "Epoch 2125/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3660 - val_loss: 0.4142\n",
            "Epoch 2126/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.4138\n",
            "Epoch 2127/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3661 - val_loss: 0.4142\n",
            "Epoch 2128/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3658 - val_loss: 0.4133\n",
            "Epoch 2129/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3657 - val_loss: 0.4142\n",
            "Epoch 2130/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3659 - val_loss: 0.4140\n",
            "Epoch 2131/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3658 - val_loss: 0.4142\n",
            "Epoch 2132/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3656 - val_loss: 0.4142\n",
            "Epoch 2133/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3658 - val_loss: 0.4137\n",
            "Epoch 2134/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3657 - val_loss: 0.4140\n",
            "Epoch 2135/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3657 - val_loss: 0.4139\n",
            "Epoch 2136/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3657 - val_loss: 0.4145\n",
            "Epoch 2137/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3658 - val_loss: 0.4133\n",
            "Epoch 2138/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3655 - val_loss: 0.4140\n",
            "Epoch 2139/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3658 - val_loss: 0.4137\n",
            "Epoch 2140/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3656 - val_loss: 0.4139\n",
            "Epoch 2141/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3656 - val_loss: 0.4140\n",
            "Epoch 2142/10000\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.3655 - val_loss: 0.4141\n",
            "Epoch 2143/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3655 - val_loss: 0.4149\n",
            "Epoch 2144/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3658 - val_loss: 0.4136\n",
            "Epoch 2145/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3654 - val_loss: 0.4139\n",
            "Epoch 2146/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3653 - val_loss: 0.4140\n",
            "Epoch 2147/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3657 - val_loss: 0.4134\n",
            "Epoch 2148/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3656 - val_loss: 0.4133\n",
            "Epoch 2149/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3655 - val_loss: 0.4140\n",
            "Epoch 2150/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3654 - val_loss: 0.4139\n",
            "Epoch 2151/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3653 - val_loss: 0.4144\n",
            "Epoch 2152/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3655 - val_loss: 0.4130\n",
            "Epoch 2153/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3651 - val_loss: 0.4138\n",
            "Epoch 2154/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3652 - val_loss: 0.4134\n",
            "Epoch 2155/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3653 - val_loss: 0.4136\n",
            "Epoch 2156/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.4134\n",
            "Epoch 2157/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3654 - val_loss: 0.4133\n",
            "Epoch 2158/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.4141\n",
            "Epoch 2159/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3653 - val_loss: 0.4138\n",
            "Epoch 2160/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.4137\n",
            "Epoch 2161/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3652 - val_loss: 0.4137\n",
            "Epoch 2162/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3652 - val_loss: 0.4128\n",
            "Epoch 2163/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3651 - val_loss: 0.4134\n",
            "Epoch 2164/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3649 - val_loss: 0.4145\n",
            "Epoch 2165/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3651 - val_loss: 0.4141\n",
            "Epoch 2166/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3651 - val_loss: 0.4135\n",
            "Epoch 2167/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.4135\n",
            "Epoch 2168/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3648 - val_loss: 0.4130\n",
            "Epoch 2169/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3649 - val_loss: 0.4133\n",
            "Epoch 2170/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3649 - val_loss: 0.4144\n",
            "Epoch 2171/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.4136\n",
            "Epoch 2172/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.4133\n",
            "Epoch 2173/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.4131\n",
            "Epoch 2174/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4142\n",
            "Epoch 2175/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.4127\n",
            "Epoch 2176/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3648 - val_loss: 0.4127\n",
            "Epoch 2177/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.4125\n",
            "Epoch 2178/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3646 - val_loss: 0.4136\n",
            "Epoch 2179/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3650 - val_loss: 0.4128\n",
            "Epoch 2180/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.4127\n",
            "Epoch 2181/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3645 - val_loss: 0.4139\n",
            "Epoch 2182/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3648 - val_loss: 0.4124\n",
            "Epoch 2183/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3646 - val_loss: 0.4128\n",
            "Epoch 2184/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3645 - val_loss: 0.4130\n",
            "Epoch 2185/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3645 - val_loss: 0.4133\n",
            "Epoch 2186/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3648 - val_loss: 0.4142\n",
            "Epoch 2187/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4131\n",
            "Epoch 2188/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4126\n",
            "Epoch 2189/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3647 - val_loss: 0.4125\n",
            "Epoch 2190/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3645 - val_loss: 0.4129\n",
            "Epoch 2191/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4125\n",
            "Epoch 2192/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4130\n",
            "Epoch 2193/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4130\n",
            "Epoch 2194/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4131\n",
            "Epoch 2195/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4121\n",
            "Epoch 2196/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3642 - val_loss: 0.4126\n",
            "Epoch 2197/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4129\n",
            "Epoch 2198/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4131\n",
            "Epoch 2199/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3644 - val_loss: 0.4129\n",
            "Epoch 2200/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3641 - val_loss: 0.4131\n",
            "Epoch 2201/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4130\n",
            "Epoch 2202/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4127\n",
            "Epoch 2203/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3642 - val_loss: 0.4138\n",
            "Epoch 2204/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3643 - val_loss: 0.4123\n",
            "Epoch 2205/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3640 - val_loss: 0.4130\n",
            "Epoch 2206/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3642 - val_loss: 0.4126\n",
            "Epoch 2207/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3638 - val_loss: 0.4141\n",
            "Epoch 2208/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3642 - val_loss: 0.4120\n",
            "Epoch 2209/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3638 - val_loss: 0.4127\n",
            "Epoch 2210/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3639 - val_loss: 0.4125\n",
            "Epoch 2211/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3640 - val_loss: 0.4121\n",
            "Epoch 2212/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3641 - val_loss: 0.4124\n",
            "Epoch 2213/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3638 - val_loss: 0.4124\n",
            "Epoch 2214/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3637 - val_loss: 0.4119\n",
            "Epoch 2215/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3638 - val_loss: 0.4129\n",
            "Epoch 2216/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3639 - val_loss: 0.4124\n",
            "Epoch 2217/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3639 - val_loss: 0.4123\n",
            "Epoch 2218/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3640 - val_loss: 0.4123\n",
            "Epoch 2219/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3638 - val_loss: 0.4128\n",
            "Epoch 2220/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3638 - val_loss: 0.4126\n",
            "Epoch 2221/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.4125\n",
            "Epoch 2222/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.4117\n",
            "Epoch 2223/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3635 - val_loss: 0.4132\n",
            "Epoch 2224/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3637 - val_loss: 0.4123\n",
            "Epoch 2225/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.4120\n",
            "Epoch 2226/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.4128\n",
            "Epoch 2227/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.4131\n",
            "Epoch 2228/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3635 - val_loss: 0.4127\n",
            "Epoch 2229/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.4120\n",
            "Epoch 2230/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.4119\n",
            "Epoch 2231/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.4125\n",
            "Epoch 2232/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3634 - val_loss: 0.4116\n",
            "Epoch 2233/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.4125\n",
            "Epoch 2234/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.4113\n",
            "Epoch 2235/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3636 - val_loss: 0.4118\n",
            "Epoch 2236/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3635 - val_loss: 0.4128\n",
            "Epoch 2237/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.4116\n",
            "Epoch 2238/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3636 - val_loss: 0.4121\n",
            "Epoch 2239/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.4120\n",
            "Epoch 2240/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4130\n",
            "Epoch 2241/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3635 - val_loss: 0.4122\n",
            "Epoch 2242/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.4116\n",
            "Epoch 2243/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4123\n",
            "Epoch 2244/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4125\n",
            "Epoch 2245/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4121\n",
            "Epoch 2246/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4128\n",
            "Epoch 2247/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4119\n",
            "Epoch 2248/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3633 - val_loss: 0.4123\n",
            "Epoch 2249/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4124\n",
            "Epoch 2250/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3632 - val_loss: 0.4115\n",
            "Epoch 2251/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.4114\n",
            "Epoch 2252/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4120\n",
            "Epoch 2253/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4120\n",
            "Epoch 2254/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.4111\n",
            "Epoch 2255/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3627 - val_loss: 0.4109\n",
            "Epoch 2256/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3628 - val_loss: 0.4116\n",
            "Epoch 2257/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4130\n",
            "Epoch 2258/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3627 - val_loss: 0.4134\n",
            "Epoch 2259/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3630 - val_loss: 0.4116\n",
            "Epoch 2260/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.4122\n",
            "Epoch 2261/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3627 - val_loss: 0.4116\n",
            "Epoch 2262/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3628 - val_loss: 0.4121\n",
            "Epoch 2263/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3628 - val_loss: 0.4119\n",
            "Epoch 2264/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3627 - val_loss: 0.4126\n",
            "Epoch 2265/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3625 - val_loss: 0.4123\n",
            "Epoch 2266/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3626 - val_loss: 0.4122\n",
            "Epoch 2267/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3629 - val_loss: 0.4117\n",
            "Epoch 2268/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3626 - val_loss: 0.4114\n",
            "Epoch 2269/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3621 - val_loss: 0.4116\n",
            "Epoch 2270/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3624 - val_loss: 0.4115\n",
            "Epoch 2271/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3623 - val_loss: 0.4120\n",
            "Epoch 2272/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.4118\n",
            "Epoch 2273/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3624 - val_loss: 0.4113\n",
            "Epoch 2274/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3625 - val_loss: 0.4117\n",
            "Epoch 2275/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3624 - val_loss: 0.4112\n",
            "Epoch 2276/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.4109\n",
            "Epoch 2277/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3623 - val_loss: 0.4113\n",
            "Epoch 2278/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3626 - val_loss: 0.4123\n",
            "Epoch 2279/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3623 - val_loss: 0.4117\n",
            "Epoch 2280/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3623 - val_loss: 0.4110\n",
            "Epoch 2281/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.4111\n",
            "Epoch 2282/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3621 - val_loss: 0.4116\n",
            "Epoch 2283/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3623 - val_loss: 0.4115\n",
            "Epoch 2284/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.4121\n",
            "Epoch 2285/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.4119\n",
            "Epoch 2286/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.4116\n",
            "Epoch 2287/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.4115\n",
            "Epoch 2288/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3622 - val_loss: 0.4122\n",
            "Epoch 2289/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4111\n",
            "Epoch 2290/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.4108\n",
            "Epoch 2291/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.4114\n",
            "Epoch 2292/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4119\n",
            "Epoch 2293/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4111\n",
            "Epoch 2294/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.4118\n",
            "Epoch 2295/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3621 - val_loss: 0.4110\n",
            "Epoch 2296/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4108\n",
            "Epoch 2297/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4107\n",
            "Epoch 2298/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3620 - val_loss: 0.4115\n",
            "Epoch 2299/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4116\n",
            "Epoch 2300/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3621 - val_loss: 0.4121\n",
            "Epoch 2301/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.4110\n",
            "Epoch 2302/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4115\n",
            "Epoch 2303/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4108\n",
            "Epoch 2304/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4115\n",
            "Epoch 2305/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.4108\n",
            "Epoch 2306/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.4121\n",
            "Epoch 2307/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3616 - val_loss: 0.4108\n",
            "Epoch 2308/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3616 - val_loss: 0.4110\n",
            "Epoch 2309/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3619 - val_loss: 0.4115\n",
            "Epoch 2310/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.4105\n",
            "Epoch 2311/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3616 - val_loss: 0.4112\n",
            "Epoch 2312/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.4111\n",
            "Epoch 2313/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.4113\n",
            "Epoch 2314/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.4121\n",
            "Epoch 2315/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3618 - val_loss: 0.4110\n",
            "Epoch 2316/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.4111\n",
            "Epoch 2317/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.4112\n",
            "Epoch 2318/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.4112\n",
            "Epoch 2319/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.4121\n",
            "Epoch 2320/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3614 - val_loss: 0.4113\n",
            "Epoch 2321/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.4112\n",
            "Epoch 2322/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.4107\n",
            "Epoch 2323/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3617 - val_loss: 0.4109\n",
            "Epoch 2324/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3612 - val_loss: 0.4113\n",
            "Epoch 2325/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3613 - val_loss: 0.4106\n",
            "Epoch 2326/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3614 - val_loss: 0.4107\n",
            "Epoch 2327/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.4104\n",
            "Epoch 2328/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.4110\n",
            "Epoch 2329/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3615 - val_loss: 0.4102\n",
            "Epoch 2330/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.4115\n",
            "Epoch 2331/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3612 - val_loss: 0.4109\n",
            "Epoch 2332/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.4112\n",
            "Epoch 2333/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.4109\n",
            "Epoch 2334/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.4110\n",
            "Epoch 2335/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3611 - val_loss: 0.4116\n",
            "Epoch 2336/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.4112\n",
            "Epoch 2337/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3612 - val_loss: 0.4108\n",
            "Epoch 2338/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3609 - val_loss: 0.4110\n",
            "Epoch 2339/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3609 - val_loss: 0.4109\n",
            "Epoch 2340/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.4107\n",
            "Epoch 2341/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3609 - val_loss: 0.4110\n",
            "Epoch 2342/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.4109\n",
            "Epoch 2343/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.4106\n",
            "Epoch 2344/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.4107\n",
            "Epoch 2345/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3606 - val_loss: 0.4104\n",
            "Epoch 2346/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3610 - val_loss: 0.4108\n",
            "Epoch 2347/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.4117\n",
            "Epoch 2348/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3604 - val_loss: 0.4110\n",
            "Epoch 2349/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.4111\n",
            "Epoch 2350/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.4105\n",
            "Epoch 2351/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.4104\n",
            "Epoch 2352/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3607 - val_loss: 0.4110\n",
            "Epoch 2353/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3605 - val_loss: 0.4111\n",
            "Epoch 2354/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3605 - val_loss: 0.4111\n",
            "Epoch 2355/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3605 - val_loss: 0.4118\n",
            "Epoch 2356/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3604 - val_loss: 0.4106\n",
            "Epoch 2357/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3605 - val_loss: 0.4107\n",
            "Epoch 2358/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3608 - val_loss: 0.4112\n",
            "Epoch 2359/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3604 - val_loss: 0.4114\n",
            "Epoch 2360/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.4103\n",
            "Epoch 2361/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3605 - val_loss: 0.4110\n",
            "Epoch 2362/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3604 - val_loss: 0.4111\n",
            "Epoch 2363/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3603 - val_loss: 0.4111\n",
            "Epoch 2364/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.4123\n",
            "Epoch 2365/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3604 - val_loss: 0.4105\n",
            "Epoch 2366/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3601 - val_loss: 0.4120\n",
            "Epoch 2367/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3604 - val_loss: 0.4100\n",
            "Epoch 2368/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.4114\n",
            "Epoch 2369/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3603 - val_loss: 0.4103\n",
            "Epoch 2370/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3603 - val_loss: 0.4102\n",
            "Epoch 2371/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.4109\n",
            "Epoch 2372/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3600 - val_loss: 0.4111\n",
            "Epoch 2373/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3600 - val_loss: 0.4106\n",
            "Epoch 2374/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3600 - val_loss: 0.4110\n",
            "Epoch 2375/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3604 - val_loss: 0.4105\n",
            "Epoch 2376/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3600 - val_loss: 0.4107\n",
            "Epoch 2377/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3600 - val_loss: 0.4116\n",
            "Epoch 2378/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3602 - val_loss: 0.4105\n",
            "Epoch 2379/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3600 - val_loss: 0.4105\n",
            "Epoch 2380/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.4112\n",
            "Epoch 2381/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.4106\n",
            "Epoch 2382/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3598 - val_loss: 0.4104\n",
            "Epoch 2383/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3598 - val_loss: 0.4109\n",
            "Epoch 2384/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.4107\n",
            "Epoch 2385/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.4103\n",
            "Epoch 2386/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.4107\n",
            "Epoch 2387/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.4104\n",
            "Epoch 2388/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3595 - val_loss: 0.4108\n",
            "Epoch 2389/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3597 - val_loss: 0.4108\n",
            "Epoch 2390/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3599 - val_loss: 0.4104\n",
            "Epoch 2391/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3597 - val_loss: 0.4107\n",
            "Epoch 2392/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3596 - val_loss: 0.4105\n",
            "Epoch 2393/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.4109\n",
            "Epoch 2394/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3596 - val_loss: 0.4108\n",
            "Epoch 2395/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3596 - val_loss: 0.4105\n",
            "Epoch 2396/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3595 - val_loss: 0.4104\n",
            "Epoch 2397/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3596 - val_loss: 0.4102\n",
            "Epoch 2398/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3596 - val_loss: 0.4111\n",
            "Epoch 2399/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.4110\n",
            "Epoch 2400/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3595 - val_loss: 0.4099\n",
            "Epoch 2401/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.4120\n",
            "Epoch 2402/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3596 - val_loss: 0.4105\n",
            "Epoch 2403/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3593 - val_loss: 0.4108\n",
            "Epoch 2404/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.4100\n",
            "Epoch 2405/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3597 - val_loss: 0.4113\n",
            "Epoch 2406/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3593 - val_loss: 0.4107\n",
            "Epoch 2407/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3591 - val_loss: 0.4107\n",
            "Epoch 2408/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.4098\n",
            "Epoch 2409/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3593 - val_loss: 0.4098\n",
            "Epoch 2410/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3595 - val_loss: 0.4100\n",
            "Epoch 2411/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.4103\n",
            "Epoch 2412/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3593 - val_loss: 0.4108\n",
            "Epoch 2413/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.4108\n",
            "Epoch 2414/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.4100\n",
            "Epoch 2415/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3591 - val_loss: 0.4112\n",
            "Epoch 2416/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3594 - val_loss: 0.4110\n",
            "Epoch 2417/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3591 - val_loss: 0.4103\n",
            "Epoch 2418/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.4118\n",
            "Epoch 2419/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3594 - val_loss: 0.4094\n",
            "Epoch 2420/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3590 - val_loss: 0.4100\n",
            "Epoch 2421/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3591 - val_loss: 0.4102\n",
            "Epoch 2422/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3589 - val_loss: 0.4098\n",
            "Epoch 2423/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.4101\n",
            "Epoch 2424/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3591 - val_loss: 0.4101\n",
            "Epoch 2425/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3589 - val_loss: 0.4097\n",
            "Epoch 2426/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3590 - val_loss: 0.4101\n",
            "Epoch 2427/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.4095\n",
            "Epoch 2428/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.4102\n",
            "Epoch 2429/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3590 - val_loss: 0.4097\n",
            "Epoch 2430/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3589 - val_loss: 0.4095\n",
            "Epoch 2431/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3589 - val_loss: 0.4104\n",
            "Epoch 2432/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3592 - val_loss: 0.4101\n",
            "Epoch 2433/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3589 - val_loss: 0.4099\n",
            "Epoch 2434/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.4101\n",
            "Epoch 2435/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3589 - val_loss: 0.4094\n",
            "Epoch 2436/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.4099\n",
            "Epoch 2437/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3586 - val_loss: 0.4111\n",
            "Epoch 2438/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3588 - val_loss: 0.4094\n",
            "Epoch 2439/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.4097\n",
            "Epoch 2440/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3589 - val_loss: 0.4114\n",
            "Epoch 2441/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.4098\n",
            "Epoch 2442/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.4104\n",
            "Epoch 2443/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3586 - val_loss: 0.4101\n",
            "Epoch 2444/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.4100\n",
            "Epoch 2445/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3583 - val_loss: 0.4095\n",
            "Epoch 2446/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3587 - val_loss: 0.4103\n",
            "Epoch 2447/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.4102\n",
            "Epoch 2448/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3583 - val_loss: 0.4114\n",
            "Epoch 2449/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.4103\n",
            "Epoch 2450/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.4099\n",
            "Epoch 2451/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.4107\n",
            "Epoch 2452/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.4112\n",
            "Epoch 2453/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3583 - val_loss: 0.4103\n",
            "Epoch 2454/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.4108\n",
            "Epoch 2455/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3583 - val_loss: 0.4106\n",
            "Epoch 2456/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3585 - val_loss: 0.4104\n",
            "Epoch 2457/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3586 - val_loss: 0.4106\n",
            "Epoch 2458/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3583 - val_loss: 0.4101\n",
            "Epoch 2459/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.4097\n",
            "Epoch 2460/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3584 - val_loss: 0.4094\n",
            "Epoch 2461/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3583 - val_loss: 0.4102\n",
            "Epoch 2462/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.4104\n",
            "Epoch 2463/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3581 - val_loss: 0.4114\n",
            "Epoch 2464/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3581 - val_loss: 0.4106\n",
            "Epoch 2465/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3581 - val_loss: 0.4108\n",
            "Epoch 2466/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.4100\n",
            "Epoch 2467/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.4096\n",
            "Epoch 2468/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3581 - val_loss: 0.4097\n",
            "Epoch 2469/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.4095\n",
            "Epoch 2470/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3581 - val_loss: 0.4093\n",
            "Epoch 2471/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4101\n",
            "Epoch 2472/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4099\n",
            "Epoch 2473/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4106\n",
            "Epoch 2474/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3582 - val_loss: 0.4104\n",
            "Epoch 2475/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.4103\n",
            "Epoch 2476/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4098\n",
            "Epoch 2477/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4095\n",
            "Epoch 2478/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.4099\n",
            "Epoch 2479/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.4108\n",
            "Epoch 2480/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.4102\n",
            "Epoch 2481/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.4106\n",
            "Epoch 2482/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3580 - val_loss: 0.4104\n",
            "Epoch 2483/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.4097\n",
            "Epoch 2484/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3579 - val_loss: 0.4095\n",
            "Epoch 2485/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.4099\n",
            "Epoch 2486/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.4097\n",
            "Epoch 2487/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.4102\n",
            "Epoch 2488/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.4099\n",
            "Epoch 2489/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.4095\n",
            "Epoch 2490/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3578 - val_loss: 0.4096\n",
            "Epoch 2491/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.4099\n",
            "Epoch 2492/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.4100\n",
            "Epoch 2493/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.4099\n",
            "Epoch 2494/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4099\n",
            "Epoch 2495/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4102\n",
            "Epoch 2496/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4108\n",
            "Epoch 2497/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3574 - val_loss: 0.4102\n",
            "Epoch 2498/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3577 - val_loss: 0.4099\n",
            "Epoch 2499/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4103\n",
            "Epoch 2500/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3574 - val_loss: 0.4101\n",
            "Epoch 2501/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4096\n",
            "Epoch 2502/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4096\n",
            "Epoch 2503/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4101\n",
            "Epoch 2504/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3574 - val_loss: 0.4098\n",
            "Epoch 2505/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3576 - val_loss: 0.4099\n",
            "Epoch 2506/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3573 - val_loss: 0.4094\n",
            "Epoch 2507/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4103\n",
            "Epoch 2508/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4096\n",
            "Epoch 2509/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3573 - val_loss: 0.4101\n",
            "Epoch 2510/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4101\n",
            "Epoch 2511/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4106\n",
            "Epoch 2512/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3575 - val_loss: 0.4090\n",
            "Epoch 2513/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4090\n",
            "Epoch 2514/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4093\n",
            "Epoch 2515/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4115\n",
            "Epoch 2516/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3571 - val_loss: 0.4091\n",
            "Epoch 2517/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.4095\n",
            "Epoch 2518/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.4103\n",
            "Epoch 2519/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4104\n",
            "Epoch 2520/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.4099\n",
            "Epoch 2521/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3573 - val_loss: 0.4102\n",
            "Epoch 2522/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4100\n",
            "Epoch 2523/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.4093\n",
            "Epoch 2524/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.4093\n",
            "Epoch 2525/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4095\n",
            "Epoch 2526/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4087\n",
            "Epoch 2527/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.4099\n",
            "Epoch 2528/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3571 - val_loss: 0.4091\n",
            "Epoch 2529/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.4089\n",
            "Epoch 2530/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.4095\n",
            "Epoch 2531/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3572 - val_loss: 0.4091\n",
            "Epoch 2532/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.4101\n",
            "Epoch 2533/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3571 - val_loss: 0.4092\n",
            "Epoch 2534/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.4098\n",
            "Epoch 2535/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.4088\n",
            "Epoch 2536/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3570 - val_loss: 0.4095\n",
            "Epoch 2537/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.4094\n",
            "Epoch 2538/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.4099\n",
            "Epoch 2539/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.4092\n",
            "Epoch 2540/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.4095\n",
            "Epoch 2541/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3568 - val_loss: 0.4104\n",
            "Epoch 2542/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4100\n",
            "Epoch 2543/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4095\n",
            "Epoch 2544/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4100\n",
            "Epoch 2545/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3569 - val_loss: 0.4099\n",
            "Epoch 2546/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3567 - val_loss: 0.4097\n",
            "Epoch 2547/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4099\n",
            "Epoch 2548/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4103\n",
            "Epoch 2549/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.4094\n",
            "Epoch 2550/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.4105\n",
            "Epoch 2551/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.4100\n",
            "Epoch 2552/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3566 - val_loss: 0.4095\n",
            "Epoch 2553/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3567 - val_loss: 0.4094\n",
            "Epoch 2554/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.4095\n",
            "Epoch 2555/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.4094\n",
            "Epoch 2556/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.4095\n",
            "Epoch 2557/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4096\n",
            "Epoch 2558/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.4100\n",
            "Epoch 2559/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.4097\n",
            "Epoch 2560/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3565 - val_loss: 0.4103\n",
            "Epoch 2561/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.4102\n",
            "Epoch 2562/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4088\n",
            "Epoch 2563/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4108\n",
            "Epoch 2564/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.4099\n",
            "Epoch 2565/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4103\n",
            "Epoch 2566/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3560 - val_loss: 0.4091\n",
            "Epoch 2567/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.4096\n",
            "Epoch 2568/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.4092\n",
            "Epoch 2569/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 0.4095\n",
            "Epoch 2570/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4095\n",
            "Epoch 2571/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4101\n",
            "Epoch 2572/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.4096\n",
            "Epoch 2573/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.4092\n",
            "Epoch 2574/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.4088\n",
            "Epoch 2575/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3562 - val_loss: 0.4093\n",
            "Epoch 2576/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 0.4098\n",
            "Epoch 2577/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4105\n",
            "Epoch 2578/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3563 - val_loss: 0.4101\n",
            "Epoch 2579/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3559 - val_loss: 0.4090\n",
            "Epoch 2580/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.4093\n",
            "Epoch 2581/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.4094\n",
            "Epoch 2582/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3564 - val_loss: 0.4097\n",
            "Epoch 2583/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3559 - val_loss: 0.4104\n",
            "Epoch 2584/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3560 - val_loss: 0.4096\n",
            "Epoch 2585/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 0.4097\n",
            "Epoch 2586/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3560 - val_loss: 0.4091\n",
            "Epoch 2587/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.4096\n",
            "Epoch 2588/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3559 - val_loss: 0.4091\n",
            "Epoch 2589/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.4091\n",
            "Epoch 2590/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3559 - val_loss: 0.4094\n",
            "Epoch 2591/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3559 - val_loss: 0.4090\n",
            "Epoch 2592/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.4096\n",
            "Epoch 2593/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3561 - val_loss: 0.4091\n",
            "Epoch 2594/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.4096\n",
            "Epoch 2595/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.4088\n",
            "Epoch 2596/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.4091\n",
            "Epoch 2597/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.4094\n",
            "Epoch 2598/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3556 - val_loss: 0.4105\n",
            "Epoch 2599/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.4086\n",
            "Epoch 2600/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3558 - val_loss: 0.4088\n",
            "Epoch 2601/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.4099\n",
            "Epoch 2602/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3553 - val_loss: 0.4091\n",
            "Epoch 2603/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3556 - val_loss: 0.4085\n",
            "Epoch 2604/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.4095\n",
            "Epoch 2605/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.4097\n",
            "Epoch 2606/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.4093\n",
            "Epoch 2607/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.4085\n",
            "Epoch 2608/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3553 - val_loss: 0.4103\n",
            "Epoch 2609/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.4095\n",
            "Epoch 2610/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3557 - val_loss: 0.4093\n",
            "Epoch 2611/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.4097\n",
            "Epoch 2612/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.4103\n",
            "Epoch 2613/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.4095\n",
            "Epoch 2614/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.4097\n",
            "Epoch 2615/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3556 - val_loss: 0.4098\n",
            "Epoch 2616/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.4082\n",
            "Epoch 2617/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.4095\n",
            "Epoch 2618/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3553 - val_loss: 0.4090\n",
            "Epoch 2619/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3554 - val_loss: 0.4094\n",
            "Epoch 2620/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.4101\n",
            "Epoch 2621/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.4085\n",
            "Epoch 2622/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3555 - val_loss: 0.4086\n",
            "Epoch 2623/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3554 - val_loss: 0.4089\n",
            "Epoch 2624/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3553 - val_loss: 0.4090\n",
            "Epoch 2625/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.4084\n",
            "Epoch 2626/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.4090\n",
            "Epoch 2627/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.4089\n",
            "Epoch 2628/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.4088\n",
            "Epoch 2629/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3552 - val_loss: 0.4089\n",
            "Epoch 2630/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.4088\n",
            "Epoch 2631/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.4102\n",
            "Epoch 2632/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.4089\n",
            "Epoch 2633/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.4089\n",
            "Epoch 2634/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3553 - val_loss: 0.4094\n",
            "Epoch 2635/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.4094\n",
            "Epoch 2636/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.4087\n",
            "Epoch 2637/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.4090\n",
            "Epoch 2638/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3552 - val_loss: 0.4090\n",
            "Epoch 2639/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.4085\n",
            "Epoch 2640/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.4091\n",
            "Epoch 2641/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.4089\n",
            "Epoch 2642/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3550 - val_loss: 0.4097\n",
            "Epoch 2643/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3551 - val_loss: 0.4086\n",
            "Epoch 2644/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.4084\n",
            "Epoch 2645/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.4090\n",
            "Epoch 2646/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.4086\n",
            "Epoch 2647/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.4098\n",
            "Epoch 2648/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.4092\n",
            "Epoch 2649/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.4093\n",
            "Epoch 2650/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.4094\n",
            "Epoch 2651/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.4092\n",
            "Epoch 2652/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.4082\n",
            "Epoch 2653/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3549 - val_loss: 0.4088\n",
            "Epoch 2654/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3549 - val_loss: 0.4083\n",
            "Epoch 2655/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.4087\n",
            "Epoch 2656/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3546 - val_loss: 0.4099\n",
            "Epoch 2657/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3546 - val_loss: 0.4086\n",
            "Epoch 2658/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3545 - val_loss: 0.4101\n",
            "Epoch 2659/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.4091\n",
            "Epoch 2660/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.4092\n",
            "Epoch 2661/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3546 - val_loss: 0.4089\n",
            "Epoch 2662/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3547 - val_loss: 0.4093\n",
            "Epoch 2663/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3546 - val_loss: 0.4093\n",
            "Epoch 2664/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3548 - val_loss: 0.4089\n",
            "Epoch 2665/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3547 - val_loss: 0.4088\n",
            "Epoch 2666/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3545 - val_loss: 0.4088\n",
            "Epoch 2667/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3545 - val_loss: 0.4094\n",
            "Epoch 2668/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3545 - val_loss: 0.4087\n",
            "Epoch 2669/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3546 - val_loss: 0.4092\n",
            "Epoch 2670/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3545 - val_loss: 0.4090\n",
            "Epoch 2671/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3542 - val_loss: 0.4105\n",
            "Epoch 2672/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3545 - val_loss: 0.4089\n",
            "Epoch 2673/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.4087\n",
            "Epoch 2674/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3544 - val_loss: 0.4083\n",
            "Epoch 2675/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.4087\n",
            "Epoch 2676/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.4085\n",
            "Epoch 2677/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.4096\n",
            "Epoch 2678/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.4084\n",
            "Epoch 2679/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3545 - val_loss: 0.4094\n",
            "Epoch 2680/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.4089\n",
            "Epoch 2681/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3541 - val_loss: 0.4096\n",
            "Epoch 2682/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3544 - val_loss: 0.4093\n",
            "Epoch 2683/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3541 - val_loss: 0.4089\n",
            "Epoch 2684/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.4092\n",
            "Epoch 2685/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3542 - val_loss: 0.4093\n",
            "Epoch 2686/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3544 - val_loss: 0.4092\n",
            "Epoch 2687/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.4082\n",
            "Epoch 2688/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3544 - val_loss: 0.4083\n",
            "Epoch 2689/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3541 - val_loss: 0.4085\n",
            "Epoch 2690/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3541 - val_loss: 0.4093\n",
            "Epoch 2691/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3543 - val_loss: 0.4085\n",
            "Epoch 2692/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.4098\n",
            "Epoch 2693/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3545 - val_loss: 0.4104\n",
            "Epoch 2694/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3541 - val_loss: 0.4089\n",
            "Epoch 2695/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3538 - val_loss: 0.4105\n",
            "Epoch 2696/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.4105\n",
            "Epoch 2697/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.4082\n",
            "Epoch 2698/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.4084\n",
            "Epoch 2699/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.4101\n",
            "Epoch 2700/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.4093\n",
            "Epoch 2701/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.4088\n",
            "Epoch 2702/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.4091\n",
            "Epoch 2703/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3537 - val_loss: 0.4090\n",
            "Epoch 2704/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.4094\n",
            "Epoch 2705/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.4097\n",
            "Epoch 2706/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.4102\n",
            "Epoch 2707/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.4100\n",
            "Epoch 2708/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3537 - val_loss: 0.4097\n",
            "Epoch 2709/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3538 - val_loss: 0.4094\n",
            "Epoch 2710/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3538 - val_loss: 0.4095\n",
            "Epoch 2711/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3536 - val_loss: 0.4091\n",
            "Epoch 2712/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3536 - val_loss: 0.4087\n",
            "Epoch 2713/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3540 - val_loss: 0.4085\n",
            "Epoch 2714/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3537 - val_loss: 0.4086\n",
            "Epoch 2715/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3539 - val_loss: 0.4091\n",
            "Epoch 2716/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3537 - val_loss: 0.4098\n",
            "Epoch 2717/10000\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.3536 - val_loss: 0.4086\n",
            "Epoch 2718/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.4084\n",
            "Epoch 2719/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3537 - val_loss: 0.4085\n",
            "Epoch 2720/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3539 - val_loss: 0.4089\n",
            "Epoch 2721/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3533 - val_loss: 0.4089\n",
            "Epoch 2722/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3535 - val_loss: 0.4094\n",
            "Epoch 2723/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.4093\n",
            "Epoch 2724/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.4091\n",
            "Epoch 2725/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3536 - val_loss: 0.4090\n",
            "Epoch 2726/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.4089\n",
            "Epoch 2727/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3536 - val_loss: 0.4092\n",
            "Epoch 2728/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3536 - val_loss: 0.4083\n",
            "Epoch 2729/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3537 - val_loss: 0.4084\n",
            "Epoch 2730/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.4084\n",
            "Epoch 2731/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3534 - val_loss: 0.4092\n",
            "Epoch 2732/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.4098\n",
            "Epoch 2733/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.4093\n",
            "Epoch 2734/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.4095\n",
            "Epoch 2735/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.4085\n",
            "Epoch 2736/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.4087\n",
            "Epoch 2737/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.4090\n",
            "Epoch 2738/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.4094\n",
            "Epoch 2739/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.4085\n",
            "Epoch 2740/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.4082\n",
            "Epoch 2741/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3533 - val_loss: 0.4096\n",
            "Epoch 2742/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.4101\n",
            "Epoch 2743/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3535 - val_loss: 0.4089\n",
            "Epoch 2744/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.4084\n",
            "Epoch 2745/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3534 - val_loss: 0.4085\n",
            "Epoch 2746/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3531 - val_loss: 0.4084\n",
            "Epoch 2747/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.4083\n",
            "Epoch 2748/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3531 - val_loss: 0.4090\n",
            "Epoch 2749/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.4086\n",
            "Epoch 2750/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.4078\n",
            "Epoch 2751/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3531 - val_loss: 0.4079\n",
            "Epoch 2752/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3530 - val_loss: 0.4075\n",
            "Epoch 2753/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4100\n",
            "Epoch 2754/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3532 - val_loss: 0.4090\n",
            "Epoch 2755/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4104\n",
            "Epoch 2756/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.4088\n",
            "Epoch 2757/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4077\n",
            "Epoch 2758/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4080\n",
            "Epoch 2759/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3529 - val_loss: 0.4085\n",
            "Epoch 2760/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3528 - val_loss: 0.4089\n",
            "Epoch 2761/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4087\n",
            "Epoch 2762/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3529 - val_loss: 0.4089\n",
            "Epoch 2763/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4084\n",
            "Epoch 2764/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.4082\n",
            "Epoch 2765/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3526 - val_loss: 0.4088\n",
            "Epoch 2766/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4083\n",
            "Epoch 2767/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3525 - val_loss: 0.4086\n",
            "Epoch 2768/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3524 - val_loss: 0.4089\n",
            "Epoch 2769/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.4083\n",
            "Epoch 2770/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3525 - val_loss: 0.4097\n",
            "Epoch 2771/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4090\n",
            "Epoch 2772/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.4082\n",
            "Epoch 2773/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3526 - val_loss: 0.4087\n",
            "Epoch 2774/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3522 - val_loss: 0.4099\n",
            "Epoch 2775/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.4082\n",
            "Epoch 2776/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3523 - val_loss: 0.4080\n",
            "Epoch 2777/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.4084\n",
            "Epoch 2778/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3524 - val_loss: 0.4080\n",
            "Epoch 2779/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3522 - val_loss: 0.4078\n",
            "Epoch 2780/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.4083\n",
            "Epoch 2781/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3522 - val_loss: 0.4076\n",
            "Epoch 2782/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3523 - val_loss: 0.4075\n",
            "Epoch 2783/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3521 - val_loss: 0.4081\n",
            "Epoch 2784/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3522 - val_loss: 0.4077\n",
            "Epoch 2785/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.4081\n",
            "Epoch 2786/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3518 - val_loss: 0.4090\n",
            "Epoch 2787/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3522 - val_loss: 0.4083\n",
            "Epoch 2788/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3520 - val_loss: 0.4096\n",
            "Epoch 2789/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.4078\n",
            "Epoch 2790/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.4085\n",
            "Epoch 2791/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3521 - val_loss: 0.4079\n",
            "Epoch 2792/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3519 - val_loss: 0.4088\n",
            "Epoch 2793/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3522 - val_loss: 0.4081\n",
            "Epoch 2794/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3521 - val_loss: 0.4092\n",
            "Epoch 2795/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3521 - val_loss: 0.4084\n",
            "Epoch 2796/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.4083\n",
            "Epoch 2797/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3519 - val_loss: 0.4078\n",
            "Epoch 2798/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3520 - val_loss: 0.4083\n",
            "Epoch 2799/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3519 - val_loss: 0.4082\n",
            "Epoch 2800/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3519 - val_loss: 0.4080\n",
            "Epoch 2801/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.4087\n",
            "Epoch 2802/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3519 - val_loss: 0.4080\n",
            "Epoch 2803/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3515 - val_loss: 0.4092\n",
            "Epoch 2804/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.4073\n",
            "Epoch 2805/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3517 - val_loss: 0.4086\n",
            "Epoch 2806/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3518 - val_loss: 0.4079\n",
            "Epoch 2807/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3513 - val_loss: 0.4073\n",
            "Epoch 2808/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3517 - val_loss: 0.4085\n",
            "Epoch 2809/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.4076\n",
            "Epoch 2810/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.4082\n",
            "Epoch 2811/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.4085\n",
            "Epoch 2812/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.4087\n",
            "Epoch 2813/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3515 - val_loss: 0.4087\n",
            "Epoch 2814/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3516 - val_loss: 0.4085\n",
            "Epoch 2815/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3513 - val_loss: 0.4081\n",
            "Epoch 2816/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3513 - val_loss: 0.4073\n",
            "Epoch 2817/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3512 - val_loss: 0.4080\n",
            "Epoch 2818/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3514 - val_loss: 0.4073\n",
            "Epoch 2819/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3515 - val_loss: 0.4080\n",
            "Epoch 2820/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3512 - val_loss: 0.4081\n",
            "Epoch 2821/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3513 - val_loss: 0.4078\n",
            "Epoch 2822/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3512 - val_loss: 0.4073\n",
            "Epoch 2823/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3513 - val_loss: 0.4081\n",
            "Epoch 2824/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3515 - val_loss: 0.4083\n",
            "Epoch 2825/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.4079\n",
            "Epoch 2826/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3511 - val_loss: 0.4086\n",
            "Epoch 2827/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3511 - val_loss: 0.4083\n",
            "Epoch 2828/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3512 - val_loss: 0.4073\n",
            "Epoch 2829/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3511 - val_loss: 0.4075\n",
            "Epoch 2830/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3508 - val_loss: 0.4085\n",
            "Epoch 2831/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3510 - val_loss: 0.4079\n",
            "Epoch 2832/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3510 - val_loss: 0.4084\n",
            "Epoch 2833/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3511 - val_loss: 0.4079\n",
            "Epoch 2834/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3510 - val_loss: 0.4076\n",
            "Epoch 2835/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3512 - val_loss: 0.4076\n",
            "Epoch 2836/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3510 - val_loss: 0.4077\n",
            "Epoch 2837/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3508 - val_loss: 0.4077\n",
            "Epoch 2838/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3510 - val_loss: 0.4075\n",
            "Epoch 2839/10000\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.3510 - val_loss: 0.4070\n",
            "Epoch 2840/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.4074\n",
            "Epoch 2841/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3509 - val_loss: 0.4071\n",
            "Epoch 2842/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3509 - val_loss: 0.4078\n",
            "Epoch 2843/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3510 - val_loss: 0.4068\n",
            "Epoch 2844/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.4077\n",
            "Epoch 2845/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3508 - val_loss: 0.4081\n",
            "Epoch 2846/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3508 - val_loss: 0.4078\n",
            "Epoch 2847/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3507 - val_loss: 0.4072\n",
            "Epoch 2848/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3505 - val_loss: 0.4076\n",
            "Epoch 2849/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3507 - val_loss: 0.4071\n",
            "Epoch 2850/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3507 - val_loss: 0.4072\n",
            "Epoch 2851/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3509 - val_loss: 0.4080\n",
            "Epoch 2852/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3506 - val_loss: 0.4078\n",
            "Epoch 2853/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3507 - val_loss: 0.4076\n",
            "Epoch 2854/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3506 - val_loss: 0.4068\n",
            "Epoch 2855/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3507 - val_loss: 0.4078\n",
            "Epoch 2856/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3505 - val_loss: 0.4080\n",
            "Epoch 2857/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3502 - val_loss: 0.4072\n",
            "Epoch 2858/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.4095\n",
            "Epoch 2859/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3506 - val_loss: 0.4075\n",
            "Epoch 2860/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3505 - val_loss: 0.4077\n",
            "Epoch 2861/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3506 - val_loss: 0.4078\n",
            "Epoch 2862/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.4077\n",
            "Epoch 2863/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.4077\n",
            "Epoch 2864/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.4065\n",
            "Epoch 2865/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3503 - val_loss: 0.4071\n",
            "Epoch 2866/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.4067\n",
            "Epoch 2867/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.4079\n",
            "Epoch 2868/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3504 - val_loss: 0.4070\n",
            "Epoch 2869/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3506 - val_loss: 0.4068\n",
            "Epoch 2870/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3503 - val_loss: 0.4072\n",
            "Epoch 2871/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.4079\n",
            "Epoch 2872/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.4072\n",
            "Epoch 2873/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.4067\n",
            "Epoch 2874/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.4072\n",
            "Epoch 2875/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.4069\n",
            "Epoch 2876/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.4066\n",
            "Epoch 2877/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.4081\n",
            "Epoch 2878/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.4069\n",
            "Epoch 2879/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3502 - val_loss: 0.4065\n",
            "Epoch 2880/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.4077\n",
            "Epoch 2881/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3502 - val_loss: 0.4063\n",
            "Epoch 2882/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.4066\n",
            "Epoch 2883/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3502 - val_loss: 0.4069\n",
            "Epoch 2884/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.4069\n",
            "Epoch 2885/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3499 - val_loss: 0.4066\n",
            "Epoch 2886/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3498 - val_loss: 0.4074\n",
            "Epoch 2887/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.4069\n",
            "Epoch 2888/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3501 - val_loss: 0.4069\n",
            "Epoch 2889/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.4074\n",
            "Epoch 2890/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3498 - val_loss: 0.4081\n",
            "Epoch 2891/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.4075\n",
            "Epoch 2892/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3496 - val_loss: 0.4069\n",
            "Epoch 2893/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.4068\n",
            "Epoch 2894/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3498 - val_loss: 0.4064\n",
            "Epoch 2895/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.4063\n",
            "Epoch 2896/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3496 - val_loss: 0.4073\n",
            "Epoch 2897/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3496 - val_loss: 0.4072\n",
            "Epoch 2898/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3500 - val_loss: 0.4069\n",
            "Epoch 2899/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.4067\n",
            "Epoch 2900/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3497 - val_loss: 0.4075\n",
            "Epoch 2901/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3498 - val_loss: 0.4070\n",
            "Epoch 2902/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.4069\n",
            "Epoch 2903/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3499 - val_loss: 0.4072\n",
            "Epoch 2904/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.4066\n",
            "Epoch 2905/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.4075\n",
            "Epoch 2906/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3494 - val_loss: 0.4069\n",
            "Epoch 2907/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3493 - val_loss: 0.4070\n",
            "Epoch 2908/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3493 - val_loss: 0.4072\n",
            "Epoch 2909/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3496 - val_loss: 0.4066\n",
            "Epoch 2910/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3493 - val_loss: 0.4085\n",
            "Epoch 2911/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3494 - val_loss: 0.4075\n",
            "Epoch 2912/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3494 - val_loss: 0.4070\n",
            "Epoch 2913/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3494 - val_loss: 0.4077\n",
            "Epoch 2914/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.4063\n",
            "Epoch 2915/10000\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.3494 - val_loss: 0.4073\n",
            "Epoch 2916/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3493 - val_loss: 0.4074\n",
            "Epoch 2917/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3493 - val_loss: 0.4068\n",
            "Epoch 2918/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3493 - val_loss: 0.4070\n",
            "Epoch 2919/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3492 - val_loss: 0.4068\n",
            "Epoch 2920/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.4074\n",
            "Epoch 2921/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3493 - val_loss: 0.4062\n",
            "Epoch 2922/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.4072\n",
            "Epoch 2923/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3492 - val_loss: 0.4070\n",
            "Epoch 2924/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3490 - val_loss: 0.4070\n",
            "Epoch 2925/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3491 - val_loss: 0.4073\n",
            "Epoch 2926/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.4074\n",
            "Epoch 2927/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.4067\n",
            "Epoch 2928/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3491 - val_loss: 0.4067\n",
            "Epoch 2929/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.4070\n",
            "Epoch 2930/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3489 - val_loss: 0.4065\n",
            "Epoch 2931/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3489 - val_loss: 0.4080\n",
            "Epoch 2932/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3492 - val_loss: 0.4064\n",
            "Epoch 2933/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3486 - val_loss: 0.4080\n",
            "Epoch 2934/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.4067\n",
            "Epoch 2935/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.4072\n",
            "Epoch 2936/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3489 - val_loss: 0.4082\n",
            "Epoch 2937/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.4061\n",
            "Epoch 2938/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3489 - val_loss: 0.4059\n",
            "Epoch 2939/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.4066\n",
            "Epoch 2940/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3490 - val_loss: 0.4067\n",
            "Epoch 2941/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.4068\n",
            "Epoch 2942/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3486 - val_loss: 0.4071\n",
            "Epoch 2943/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.4065\n",
            "Epoch 2944/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3485 - val_loss: 0.4065\n",
            "Epoch 2945/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.4077\n",
            "Epoch 2946/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3486 - val_loss: 0.4074\n",
            "Epoch 2947/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3491 - val_loss: 0.4078\n",
            "Epoch 2948/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3486 - val_loss: 0.4067\n",
            "Epoch 2949/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.4060\n",
            "Epoch 2950/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.4070\n",
            "Epoch 2951/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3487 - val_loss: 0.4064\n",
            "Epoch 2952/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3484 - val_loss: 0.4062\n",
            "Epoch 2953/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3486 - val_loss: 0.4063\n",
            "Epoch 2954/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3483 - val_loss: 0.4067\n",
            "Epoch 2955/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.4072\n",
            "Epoch 2956/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3486 - val_loss: 0.4073\n",
            "Epoch 2957/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3483 - val_loss: 0.4070\n",
            "Epoch 2958/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.4069\n",
            "Epoch 2959/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.4066\n",
            "Epoch 2960/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3484 - val_loss: 0.4069\n",
            "Epoch 2961/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3483 - val_loss: 0.4069\n",
            "Epoch 2962/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3484 - val_loss: 0.4072\n",
            "Epoch 2963/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.4073\n",
            "Epoch 2964/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3484 - val_loss: 0.4068\n",
            "Epoch 2965/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.4067\n",
            "Epoch 2966/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 0.4066\n",
            "Epoch 2967/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 0.4071\n",
            "Epoch 2968/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.4069\n",
            "Epoch 2969/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.4071\n",
            "Epoch 2970/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3485 - val_loss: 0.4066\n",
            "Epoch 2971/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.4065\n",
            "Epoch 2972/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3482 - val_loss: 0.4064\n",
            "Epoch 2973/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.4071\n",
            "Epoch 2974/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3479 - val_loss: 0.4070\n",
            "Epoch 2975/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.4081\n",
            "Epoch 2976/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3481 - val_loss: 0.4080\n",
            "Epoch 2977/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.4073\n",
            "Epoch 2978/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.4072\n",
            "Epoch 2979/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3478 - val_loss: 0.4073\n",
            "Epoch 2980/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3478 - val_loss: 0.4073\n",
            "Epoch 2981/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.4070\n",
            "Epoch 2982/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3480 - val_loss: 0.4072\n",
            "Epoch 2983/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4081\n",
            "Epoch 2984/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3481 - val_loss: 0.4073\n",
            "Epoch 2985/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3478 - val_loss: 0.4069\n",
            "Epoch 2986/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3477 - val_loss: 0.4074\n",
            "Epoch 2987/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.4070\n",
            "Epoch 2988/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.4072\n",
            "Epoch 2989/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3477 - val_loss: 0.4078\n",
            "Epoch 2990/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.4077\n",
            "Epoch 2991/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.4064\n",
            "Epoch 2992/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4073\n",
            "Epoch 2993/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3479 - val_loss: 0.4068\n",
            "Epoch 2994/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3478 - val_loss: 0.4067\n",
            "Epoch 2995/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4066\n",
            "Epoch 2996/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4068\n",
            "Epoch 2997/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3474 - val_loss: 0.4065\n",
            "Epoch 2998/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4066\n",
            "Epoch 2999/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3477 - val_loss: 0.4070\n",
            "Epoch 3000/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3474 - val_loss: 0.4071\n",
            "Epoch 3001/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4072\n",
            "Epoch 3002/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4067\n",
            "Epoch 3003/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3475 - val_loss: 0.4070\n",
            "Epoch 3004/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3476 - val_loss: 0.4068\n",
            "Epoch 3005/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4069\n",
            "Epoch 3006/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3474 - val_loss: 0.4079\n",
            "Epoch 3007/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3473 - val_loss: 0.4068\n",
            "Epoch 3008/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3474 - val_loss: 0.4079\n",
            "Epoch 3009/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3474 - val_loss: 0.4065\n",
            "Epoch 3010/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.4077\n",
            "Epoch 3011/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4064\n",
            "Epoch 3012/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.4079\n",
            "Epoch 3013/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3473 - val_loss: 0.4072\n",
            "Epoch 3014/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3468 - val_loss: 0.4070\n",
            "Epoch 3015/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3475 - val_loss: 0.4068\n",
            "Epoch 3016/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.4069\n",
            "Epoch 3017/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3471 - val_loss: 0.4067\n",
            "Epoch 3018/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3472 - val_loss: 0.4068\n",
            "Epoch 3019/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3470 - val_loss: 0.4069\n",
            "Epoch 3020/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.4078\n",
            "Epoch 3021/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3472 - val_loss: 0.4067\n",
            "Epoch 3022/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.4068\n",
            "Epoch 3023/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3470 - val_loss: 0.4071\n",
            "Epoch 3024/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.4089\n",
            "Epoch 3025/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.4074\n",
            "Epoch 3026/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3470 - val_loss: 0.4069\n",
            "Epoch 3027/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.4072\n",
            "Epoch 3028/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.4073\n",
            "Epoch 3029/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.4072\n",
            "Epoch 3030/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3470 - val_loss: 0.4074\n",
            "Epoch 3031/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3471 - val_loss: 0.4071\n",
            "Epoch 3032/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.4073\n",
            "Epoch 3033/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3467 - val_loss: 0.4073\n",
            "Epoch 3034/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.4069\n",
            "Epoch 3035/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.4068\n",
            "Epoch 3036/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.4063\n",
            "Epoch 3037/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3468 - val_loss: 0.4074\n",
            "Epoch 3038/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3469 - val_loss: 0.4069\n",
            "Epoch 3039/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3467 - val_loss: 0.4061\n",
            "Epoch 3040/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.4071\n",
            "Epoch 3041/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3464 - val_loss: 0.4080\n",
            "Epoch 3042/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3467 - val_loss: 0.4062\n",
            "Epoch 3043/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3467 - val_loss: 0.4063\n",
            "Epoch 3044/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 0.4067\n",
            "Epoch 3045/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.4067\n",
            "Epoch 3046/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3466 - val_loss: 0.4062\n",
            "Epoch 3047/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.4066\n",
            "Epoch 3048/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3466 - val_loss: 0.4068\n",
            "Epoch 3049/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.4067\n",
            "Epoch 3050/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3465 - val_loss: 0.4069\n",
            "Epoch 3051/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.4074\n",
            "Epoch 3052/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.4072\n",
            "Epoch 3053/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.4076\n",
            "Epoch 3054/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.4068\n",
            "Epoch 3055/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3465 - val_loss: 0.4069\n",
            "Epoch 3056/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.4075\n",
            "Epoch 3057/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.4066\n",
            "Epoch 3058/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3464 - val_loss: 0.4069\n",
            "Epoch 3059/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3464 - val_loss: 0.4060\n",
            "Epoch 3060/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3462 - val_loss: 0.4067\n",
            "Epoch 3061/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3463 - val_loss: 0.4072\n",
            "Epoch 3062/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.4065\n",
            "Epoch 3063/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.4059\n",
            "Epoch 3064/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3462 - val_loss: 0.4070\n",
            "Epoch 3065/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3462 - val_loss: 0.4069\n",
            "Epoch 3066/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.4062\n",
            "Epoch 3067/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3463 - val_loss: 0.4066\n",
            "Epoch 3068/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.4071\n",
            "Epoch 3069/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3458 - val_loss: 0.4069\n",
            "Epoch 3070/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.4061\n",
            "Epoch 3071/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.4067\n",
            "Epoch 3072/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.4065\n",
            "Epoch 3073/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3461 - val_loss: 0.4068\n",
            "Epoch 3074/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3460 - val_loss: 0.4075\n",
            "Epoch 3075/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3459 - val_loss: 0.4064\n",
            "Epoch 3076/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3459 - val_loss: 0.4056\n",
            "Epoch 3077/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.4056\n",
            "Epoch 3078/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3459 - val_loss: 0.4060\n",
            "Epoch 3079/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.4064\n",
            "Epoch 3080/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3459 - val_loss: 0.4064\n",
            "Epoch 3081/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.4062\n",
            "Epoch 3082/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.4063\n",
            "Epoch 3083/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3457 - val_loss: 0.4062\n",
            "Epoch 3084/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3458 - val_loss: 0.4052\n",
            "Epoch 3085/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.4063\n",
            "Epoch 3086/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3456 - val_loss: 0.4059\n",
            "Epoch 3087/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.4060\n",
            "Epoch 3088/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3455 - val_loss: 0.4068\n",
            "Epoch 3089/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.4062\n",
            "Epoch 3090/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3457 - val_loss: 0.4063\n",
            "Epoch 3091/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.4054\n",
            "Epoch 3092/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.4054\n",
            "Epoch 3093/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.4059\n",
            "Epoch 3094/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.4063\n",
            "Epoch 3095/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.4061\n",
            "Epoch 3096/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3452 - val_loss: 0.4063\n",
            "Epoch 3097/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3452 - val_loss: 0.4062\n",
            "Epoch 3098/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3453 - val_loss: 0.4066\n",
            "Epoch 3099/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.4056\n",
            "Epoch 3100/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.4054\n",
            "Epoch 3101/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3454 - val_loss: 0.4060\n",
            "Epoch 3102/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.4055\n",
            "Epoch 3103/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3452 - val_loss: 0.4058\n",
            "Epoch 3104/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3455 - val_loss: 0.4054\n",
            "Epoch 3105/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.4050\n",
            "Epoch 3106/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3452 - val_loss: 0.4052\n",
            "Epoch 3107/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.4060\n",
            "Epoch 3108/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.4044\n",
            "Epoch 3109/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.4049\n",
            "Epoch 3110/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3450 - val_loss: 0.4062\n",
            "Epoch 3111/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.4075\n",
            "Epoch 3112/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3452 - val_loss: 0.4063\n",
            "Epoch 3113/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3451 - val_loss: 0.4062\n",
            "Epoch 3114/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.4065\n",
            "Epoch 3115/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3450 - val_loss: 0.4063\n",
            "Epoch 3116/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3450 - val_loss: 0.4056\n",
            "Epoch 3117/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.4048\n",
            "Epoch 3118/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.4070\n",
            "Epoch 3119/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3450 - val_loss: 0.4053\n",
            "Epoch 3120/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.4057\n",
            "Epoch 3121/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.4061\n",
            "Epoch 3122/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.4057\n",
            "Epoch 3123/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3449 - val_loss: 0.4057\n",
            "Epoch 3124/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3446 - val_loss: 0.4055\n",
            "Epoch 3125/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.4067\n",
            "Epoch 3126/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.4053\n",
            "Epoch 3127/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.4059\n",
            "Epoch 3128/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.4053\n",
            "Epoch 3129/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.4054\n",
            "Epoch 3130/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.4068\n",
            "Epoch 3131/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3445 - val_loss: 0.4066\n",
            "Epoch 3132/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3443 - val_loss: 0.4055\n",
            "Epoch 3133/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3447 - val_loss: 0.4051\n",
            "Epoch 3134/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.4046\n",
            "Epoch 3135/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.4048\n",
            "Epoch 3136/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3443 - val_loss: 0.4060\n",
            "Epoch 3137/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3448 - val_loss: 0.4055\n",
            "Epoch 3138/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.4065\n",
            "Epoch 3139/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.4055\n",
            "Epoch 3140/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.4047\n",
            "Epoch 3141/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.4062\n",
            "Epoch 3142/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3442 - val_loss: 0.4054\n",
            "Epoch 3143/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.4056\n",
            "Epoch 3144/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3440 - val_loss: 0.4053\n",
            "Epoch 3145/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3443 - val_loss: 0.4056\n",
            "Epoch 3146/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3440 - val_loss: 0.4054\n",
            "Epoch 3147/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.4050\n",
            "Epoch 3148/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.4054\n",
            "Epoch 3149/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3442 - val_loss: 0.4045\n",
            "Epoch 3150/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3440 - val_loss: 0.4050\n",
            "Epoch 3151/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.4047\n",
            "Epoch 3152/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3440 - val_loss: 0.4061\n",
            "Epoch 3153/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3439 - val_loss: 0.4069\n",
            "Epoch 3154/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3444 - val_loss: 0.4062\n",
            "Epoch 3155/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.4057\n",
            "Epoch 3156/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3439 - val_loss: 0.4062\n",
            "Epoch 3157/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.4059\n",
            "Epoch 3158/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3439 - val_loss: 0.4067\n",
            "Epoch 3159/10000\n",
            "203/203 [==============================] - 1s 2ms/step - loss: 0.3439 - val_loss: 0.4065\n",
            "Epoch 3160/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3438 - val_loss: 0.4058\n",
            "Epoch 3161/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3437 - val_loss: 0.4055\n",
            "Epoch 3162/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.4056\n",
            "Epoch 3163/10000\n",
            "203/203 [==============================] - 0s 2ms/step - loss: 0.3439 - val_loss: 0.4059\n",
            "Epoch 3164/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3437 - val_loss: 0.4063\n",
            "Epoch 3165/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.4057\n",
            "Epoch 3166/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.4053\n",
            "Epoch 3167/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3436 - val_loss: 0.4049\n",
            "Epoch 3168/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3441 - val_loss: 0.4055\n",
            "Epoch 3169/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3437 - val_loss: 0.4070\n",
            "Epoch 3170/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3435 - val_loss: 0.4057\n",
            "Epoch 3171/10000\n",
            "203/203 [==============================] - 1s 3ms/step - loss: 0.3434 - val_loss: 0.4053\n",
            "Epoch 3172/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3438 - val_loss: 0.4067\n",
            "Epoch 3173/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3435 - val_loss: 0.4063\n",
            "Epoch 3174/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3437 - val_loss: 0.4055\n",
            "Epoch 3175/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3437 - val_loss: 0.4051\n",
            "Epoch 3176/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3436 - val_loss: 0.4056\n",
            "Epoch 3177/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3436 - val_loss: 0.4057\n",
            "Epoch 3178/10000\n",
            "203/203 [==============================] - 1s 5ms/step - loss: 0.3436 - val_loss: 0.4057\n",
            "Epoch 3179/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3435 - val_loss: 0.4064\n",
            "Epoch 3180/10000\n",
            "203/203 [==============================] - 1s 4ms/step - loss: 0.3437 - val_loss: 0.4050\n",
            "Epoch 3181/10000\n",
            " 52/203 [======>.......................] - ETA: 0s - loss: 0.3683"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [50], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Train the model on the training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10000\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val))\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train, epochs=1000, batch_size=64, validation_data=(X_val, y_val))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5 (default, May 18 2021, 14:42:02) [MSC v.1916 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "6c9f7b56b6eaed5ab35fb81da6d8091ab253c1aaa5f9b473ba8a3e5f020fe6ee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
