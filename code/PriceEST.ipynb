{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SpPd14Z54u1D"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['Filtered'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUsers\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mMohammad\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mDesktop\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUni\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mUni work\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mYear 4\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mTerm 7, fall 2022\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mCMPE 460 Deep Learning\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mproject\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mCMPE-460-Project\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mcar_price_prediction.csv.xls\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[39m# Split the data into features (inputs) and target (output)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m X \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mFiltered\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m y \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mFiltered\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[39m# Normalize the input features\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4774\u001b[0m \u001b[39m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, allowed_args\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   4775\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[0;32m   4776\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4783\u001b[0m     errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   4784\u001b[0m ):\n\u001b[0;32m   4785\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4786\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4787\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4904\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4905\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4906\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[0;32m   4907\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[0;32m   4908\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   4909\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   4910\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   4911\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   4912\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[0;32m   4913\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   4914\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:4150\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4148\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[0;32m   4149\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 4150\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4152\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m   4153\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:4185\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   4183\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[0;32m   4184\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 4185\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   4186\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{axis_name: new_axis})\n\u001b[0;32m   4188\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4189\u001b[0m \u001b[39melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\Mohammad\\miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6017\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6015\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[0;32m   6016\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m-> 6017\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6018\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[0;32m   6019\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
            "\u001b[1;31mKeyError\u001b[0m: \"['Filtered'] not found in axis\""
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv(\"C:\\\\Users\\\\Mohammad\\\\Desktop\\\\Uni\\\\Uni work\\\\Year 4\\\\Term 7, fall 2022\\\\CMPE 460 Deep Learning\\project\\CMPE-460-Project\\dataset\\\\car_price_prediction.csv.xls\")\n",
        "# Split the data into features (inputs) and target (output)\n",
        "X = data.drop('Filtered', axis=1)\n",
        "y = data['Filtered']\n",
        "\n",
        "# Normalize the input features\n",
        "X_num = X.select_dtypes(include=['float', 'int'])\n",
        "X_num = (X_num - X_num.mean()) / X_num.std()\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maPlrd_gBBCH"
      },
      "outputs": [],
      "source": [
        "print(X_num.shape[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36mcpwMS7Kzt"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.utils import shuffle\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "# from keras.optimizers import Adam\n",
        "\n",
        "\n",
        "# # Load the data\n",
        "# data = pd.read_csv('/content/drive/MyDrive/car_price_prediction_edited.csv')\n",
        "\n",
        "# # Split the data into features (inputs) and target (output)\n",
        "# X = data.drop('Filtered', axis=1)\n",
        "# y = data['Filtered']\n",
        "\n",
        "# # Normalize the input features\n",
        "# X_num = X.select_dtypes(include=['float', 'int'])\n",
        "# X_num = (X_num - X_num.mean()) / X_num.std()\n",
        "\n",
        "# # Shuffle the data\n",
        "# X_num, y = shuffle(X_num, y, random_state=42)\n",
        "\n",
        "# # Split the data into training, validation, and test sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=42)\n",
        "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Define the model\n",
        "# model = Sequential()\n",
        "# model.add(Dense(18, input_dim=X_num.shape[1], activation='relu'))\n",
        "# model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer=Adam(lr=0.001), loss='mean_squared_error')\n",
        "\n",
        "# # Training the model\n",
        "# history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# # Print the train and val loss\n",
        "# print(history.history['loss'])\n",
        "# print(history.history['val_loss'])\n",
        "\n",
        "# # evaluate the model on the test set\n",
        "# test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "# print('Test loss:', test_loss)\n",
        "\n",
        "# # Save the model\n",
        "# model.save('car_price_prediction_model.h5')\n",
        "\n",
        "# # Save the training history\n",
        "# import pickle\n",
        "# with open('car_price_prediction_history', 'wb') as f:\n",
        "#     pickle.dump(history.history, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt0Qbf1Dk22e",
        "outputId": "f7969d10-d413-4966-b3b2-0adb19caa2d6"
      },
      "outputs": [],
      "source": [
        "fuel_types = data[\"Fuel type\"].unique()\n",
        "for fuel in fuel_types:\n",
        "    print(fuel)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PysEY-EQkr0V",
        "outputId": "c1422a0d-9d47-4c05-8df7-f84f640b5d47"
      },
      "outputs": [],
      "source": [
        "fuel_counts = data['Fuel type'].value_counts()\n",
        "print(fuel_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmNazZM5p-9o",
        "outputId": "edaf8126-96ca-496d-b127-67168f0c8139"
      },
      "outputs": [],
      "source": [
        "ManufacturerS = data[\"Manufacturer\"].unique()\n",
        "x = 0\n",
        "for man in ManufacturerS :\n",
        "    x += 1\n",
        "    print(x, man)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bHCnNd4obZj"
      },
      "outputs": [],
      "source": [
        "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
        "#     print(data['Manufacturer'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoaVQa39Qg-2"
      },
      "source": [
        "### Start from here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsemivlgXABk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.set_floatx('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzylSfJqXB5k"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/car_price_prediction.csv')\n",
        "\n",
        "# drop rows where the price is less than 100\n",
        "data = data[data['Price'] >= 100]\n",
        "data = data[~data['Model'].isin([\"GONOW\",\"IVECO DAYLY\"])]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Drop the totalPrice column\n",
        "data = data.drop('totalPrice', axis=1)\n",
        "data = data.drop('Wheel', axis=1)\n",
        "data = data.drop('no-tax', axis=1)\n",
        "data = data.drop('Engine volume', axis=1)\n",
        "data['Doors'] = data['Doors'].replace({'-May':'','-Mar':''}, regex=True)\n",
        "data['Doors'] = data['Doors'].str.replace('>5','5')\n",
        "\n",
        "# Drop rows with missing or empty values in the \"Doors\" column\n",
        "data = data[data['Doors'].str.strip() !='']\n",
        "data['Doors'] = data['Doors'].astype(int)\n",
        "\n",
        "data['Doors'] = data['Doors'].astype(int)\n",
        "\n",
        "# Gear box editing\n",
        "data['Gear box type'] = data['Gear box type'].replace({'Automatic': 1, 'Tiptronic': 2,'Variator':3, 'Manual':4})\n",
        "data = data[data['Gear box type'].isin([1,2,3,4])]\n",
        "\n",
        "data[\"Gear box type\"] = data[\"Gear box type\"].astype(int)\n",
        "\n",
        "# 'Automatic' is changed to 1\n",
        "# 'Tiptronic' is changed to 2\n",
        "# 'Variator' is changed to 3\n",
        "# 'Manual' is changed to 4\n",
        "\n",
        "\n",
        "# Replace values in the \"Leather interior\" column based on conditions\n",
        "data[\"Leather interior\"] = data[\"Leather interior\"].replace({\"Yes\": 1, \"No\": 0}) # Yes is 1; No is 0\n",
        "# keep the rows where the value of \"Leather interior\" is 0 or 1\n",
        "data = data[data[\"Leather interior\"].apply(lambda x: x in [0, 1])]\n",
        "\n",
        "\n",
        "\n",
        "# fuel type edit\n",
        "data[\"Fuel type\"] = data[\"Fuel type\"].replace({\"Hybrid\":1, \"Petrol\":2,\"Diesel\":3,\"CNG\":4,\"Plug-in Hybrid\":5,\"LPG\":6,\"Hydrogen\":7})\n",
        "allowed_fuel_types = [1, 2, 3, 4, 5, 6, 7]\n",
        "data = data[data[\"Fuel type\"].apply(lambda x: x in allowed_fuel_types)]\n",
        "\n",
        "# 'Hybrid' is changed to 1,\n",
        "# 'Petrol' is changed to 2, \n",
        "# 'Diesel' is changed to 3, \n",
        "# 'CNG' is changed to 4, \n",
        "# 'Plug-in Hybrid' is changed to 5, \n",
        "# 'LPG' is changed to 6,\n",
        "# 'Hydrogen' is changed to 7\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y270nIi73Or1"
      },
      "outputs": [],
      "source": [
        "# Mapping\n",
        "\n",
        "data[\"Manufacturer\"] = data[\"Manufacturer\"].replace({\"LEXUS\":1, \"CHEVROLET\":2,\"GREATWALL\":3,\"HONDA\":4,\"FORD\":5,\"HYUNDAI\":6,\"TOYOTA\":7,\n",
        "                                                     \"MERCEDES-BENZ\":8, \"OPEL\":9,\"PORSCHE\":10,\"BMW\":11,\"JEEP\":12,\"VOLKSWAGEN\":13,\"AUDI\":14,\n",
        "                                                     \"RENAULT\":15, \"NISSAN\":16,\"SUBARU\":17,\"DAEWOO\":18,\"KIA\":19,\"MITSUBISHI\":20,\"SSANGYONG\":21,\n",
        "                                                     \"MAZDA\":22, \"GMC\":23,\"FIAT\":24,\"INFINITI\":25,\"ALFA ROMEO\":26,\"SUZUKI\":27,\"ACURA\":28,\n",
        "                                                     \"LINCOLN\":29, \"VAZ\":30,\"GAZ\":31,\"CITROEN\":32,\"LAND ROVER\":33,\"MINI\":34,\"DODGE\":35,\n",
        "                                                     \"CHRYSLER\":36, \"JAGUAR\":37,\"ISUZU\":38,\"SKODA\":39,\"DAIHATSU\":40,\"BUICK\":41,\"TESLA\":42,\n",
        "                                                     \"CADILLAC\":43, \"PEUGEOT\":44,\"BENTLEY\":45,\"VOLVO\":46,\"HAVAL\":47,\"HUMMER\":48,\"SCION\":49,\n",
        "                                                     \"UAZ\":50, \"MERCURY\":51,\"ZAZ\":52,\"ROVER\":53,\"SEAT\":54,\"LANCIA\":55,\"MOSKVICH\":56,\n",
        "                                                     \"MASERATI\":57, \"FERRARI\":58,\"SAAB\":59,\"LAMBORGHINI\":60,\"PONTIAC\":61,\"SATURN\":62,\"ASTON MARTIN\":63})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDm5L0ceoDwP"
      },
      "outputs": [],
      "source": [
        "# Remove \"KM\"\n",
        "data[\"Mileage\"] = data[\"Mileage\"].str.replace(\"km\",\"\")\n",
        "data[\"Mileage\"] = data[\"Mileage\"].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w69zpvwzBIOh"
      },
      "outputs": [],
      "source": [
        "data[\"Category\"] = data[\"Category\"].replace({\"Jeep\":1, \"Hatchback\":2,\"Sedan\":3,\"Microbus\":4,\"Goods wagon\":5,\"Universal\":6,\"Coupe\":7,\n",
        "                                             \"Minivan\":8, \"Cabriolet\":9,\"Limousine\":10,\"Pickup\":11})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAqu17dBCMXJ"
      },
      "outputs": [],
      "source": [
        "data[\"Color\"] = data[\"Color\"].replace({\"Silver\":1, \"Black\":2,\"White\":3,\"Grey\":4,\"Blue\":5,\"Green\":6,\"Red\":7,\n",
        "                                                     \"Sky blue\":8, \"Orange\":9,\"Yellow\":10,\"Golden\":11,\"Beige\":12,\"Brown\":13,\"Carnelian red\":14,\n",
        "                                                     \"Purple\":15, \"Pink\":16})\n",
        "\n",
        "data = pd.get_dummies(data, columns=[\"Color\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ8CH2hhDfBa"
      },
      "outputs": [],
      "source": [
        "data[\"Drive wheels\"] = data[\"Drive wheels\"].replace({\"4x4\":1, \"Front\":2,\"Rear\":3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "app2xqxfszs-"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the encoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the \"Model\" feature\n",
        "encoder.fit(data[\"Model\"])\n",
        "\n",
        "# Transform the \"Model\" feature to numeric\n",
        "data[\"Model\"] = encoder.transform(data[\"Model\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO-FIha7A4e9"
      },
      "outputs": [],
      "source": [
        "Cat_types = data[\"Model\"].unique()\n",
        "p = 0\n",
        "for c in Cat_types:\n",
        "    p += 1  \n",
        "    print(p,c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a5d314wl2Pu"
      },
      "outputs": [],
      "source": [
        "# # Assign each value of the \"Model\" column with the integer value of the corresponding \"Manufacturer\"\n",
        "# data[\"Model_enc\"] = data[\"Manufacturer\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "9vPK1p5-W52O",
        "outputId": "d68839e5-7b69-49ce-9930-80cd2bbf3096"
      },
      "outputs": [],
      "source": [
        "data.head(1100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "CSgsf32-t8NJ",
        "outputId": "bac973d4-af70-4f4c-8e94-92cb9f3964ad"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# # Define the features and labels\n",
        "# data = pd.DataFrame(data, columns=X.columns)\n",
        "\n",
        "\n",
        "# X = data.drop(\"Price\", axis=1)\n",
        "# y = np.log(data[\"Price\"])\n",
        "\n",
        "# # fit the scaler on X\n",
        "# scaler.fit(X)\n",
        "\n",
        "# # Scale the data\n",
        "# X = scaler.transform(X)\n",
        "\n",
        "# # Split the data into training and test sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pjY9KyfXQgNl",
        "outputId": "d23e395e-4584-4162-c498-81561f3da7ca"
      },
      "outputs": [],
      "source": [
        "# NOT WORKING\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "# Split the data into features (inputs) and target (output)\n",
        "X = data.drop('Price', axis=1)\n",
        "y = data['Price'].astype('float32')\n",
        "\n",
        "\n",
        "# Normalize the input features\n",
        "X_num = X.select_dtypes(include=['float', 'int'])\n",
        "X_num = (X_num - X_num.mean()) / X_num.std()\n",
        "\n",
        "# Shuffle the data\n",
        "X_num, y = shuffle(X_num, y, random_state=42)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "#Define the model\n",
        "model = Sequential()\n",
        "\n",
        "#Add layers to the model\n",
        "model.add(Dense(32, input_dim=X_num.shape[1], activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=root_mean_squared_error)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "test_loss = test_loss.ravel()[0]\n",
        "print('Test loss:', test_loss)\n",
        "\n",
        "# Save the model\n",
        "model.save('used_car_price_model.h5')\n",
        "\n",
        "# Save the training history\n",
        "import pickle\n",
        "with open('used_car_price_history', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "6c9f7b56b6eaed5ab35fb81da6d8091ab253c1aaa5f9b473ba8a3e5f020fe6ee"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
