{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Start from here\n"
      ],
      "metadata": {
        "id": "yoaVQa39Qg-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "FsemivlgXABk"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/car_price_prediction.csv')\n",
        "\n",
        "# drop rows where the price is less than 100\n",
        "data = data[data['Price'] >= 100]\n",
        "data = data[~data['Model'].isin([\"GONOW\",\"IVECO DAYLY\"])]\n",
        "\n",
        "\n",
        "\n",
        "# Drop the totalPrice column\n",
        "data = data.drop('totalPrice', axis=1)\n",
        "data = data.drop('Wheel', axis=1)\n",
        "data = data.drop('no-tax', axis=1)\n",
        "data = data.drop('Engine volume', axis=1)\n",
        "\n",
        "data = data.drop(\"ID\", axis=1)\n",
        "\n",
        "data['Doors'] = data['Doors'].replace({'-May':'','-Mar':''}, regex=True)\n",
        "data['Doors'] = data['Doors'].str.replace('>5','5')\n",
        "\n",
        "# Drop rows with missing or empty values in the \"Doors\" column\n",
        "data = data[data['Doors'].str.strip() !='']\n",
        "data['Doors'] = data['Doors'].astype(int)\n",
        "\n",
        "\n",
        "# Gear box editing\n",
        "data['Gear box type'] = data['Gear box type'].replace({'Automatic': 1, 'Tiptronic': 2,'Variator':3, 'Manual':4})\n",
        "data = data[data['Gear box type'].isin([1,2,3,4])]\n",
        "\n",
        "data[\"Gear box type\"] = data[\"Gear box type\"].astype(int)\n",
        "\n",
        "# 'Automatic' is changed to 1\n",
        "# 'Tiptronic' is changed to 2\n",
        "# 'Variator' is changed to 3\n",
        "# 'Manual' is changed to 4\n",
        "\n",
        "\n",
        "# Replace values in the \"Leather interior\" column based on conditions\n",
        "data[\"Leather interior\"] = data[\"Leather interior\"].replace({\"Yes\": 1, \"No\": 0}) # Yes is 1; No is 0\n",
        "# keep the rows where the value of \"Leather interior\" is 0 or 1\n",
        "data = data[data[\"Leather interior\"].apply(lambda x: x in [0, 1])]\n",
        "\n",
        "\n",
        "# fuel type edit\n",
        "data[\"Fuel type\"] = data[\"Fuel type\"].replace({\"Hybrid\":1, \"Petrol\":2,\"Diesel\":3,\"CNG\":4,\"Plug-in Hybrid\":5,\"LPG\":6,\"Hydrogen\":7})\n",
        "allowed_fuel_types = [1, 2, 3, 4, 5, 6, 7]\n",
        "data = data[data[\"Fuel type\"].apply(lambda x: x in allowed_fuel_types)]\n",
        "\n",
        "# 'Hybrid' is changed to 1,\n",
        "# 'Petrol' is changed to 2, \n",
        "# 'Diesel' is changed to 3, \n",
        "# 'CNG' is changed to 4, \n",
        "# 'Plug-in Hybrid' is changed to 5, \n",
        "# 'LPG' is changed to 6,\n",
        "# 'Hydrogen' is changed to 7\n"
      ],
      "metadata": {
        "id": "NzylSfJqXB5k"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping\n",
        "\n",
        "data[\"Manufacturer\"] = data[\"Manufacturer\"].replace({\"LEXUS\":1, \"CHEVROLET\":2,\"GREATWALL\":3,\"HONDA\":4,\"FORD\":5,\"HYUNDAI\":6,\"TOYOTA\":7,\n",
        "                                                     \"MERCEDES-BENZ\":8, \"OPEL\":9,\"PORSCHE\":10,\"BMW\":11,\"JEEP\":12,\"VOLKSWAGEN\":13,\"AUDI\":14,\n",
        "                                                     \"RENAULT\":15, \"NISSAN\":16,\"SUBARU\":17,\"DAEWOO\":18,\"KIA\":19,\"MITSUBISHI\":20,\"SSANGYONG\":21,\n",
        "                                                     \"MAZDA\":22, \"GMC\":23,\"FIAT\":24,\"INFINITI\":25,\"ALFA ROMEO\":26,\"SUZUKI\":27,\"ACURA\":28,\n",
        "                                                     \"LINCOLN\":29, \"VAZ\":30,\"GAZ\":31,\"CITROEN\":32,\"LAND ROVER\":33,\"MINI\":34,\"DODGE\":35,\n",
        "                                                     \"CHRYSLER\":36, \"JAGUAR\":37,\"ISUZU\":38,\"SKODA\":39,\"DAIHATSU\":40,\"BUICK\":41,\"TESLA\":42,\n",
        "                                                     \"CADILLAC\":43, \"PEUGEOT\":44,\"BENTLEY\":45,\"VOLVO\":46,\"HAVAL\":47,\"HUMMER\":48,\"SCION\":49,\n",
        "                                                     \"UAZ\":50, \"MERCURY\":51,\"ZAZ\":52,\"ROVER\":53,\"SEAT\":54,\"LANCIA\":55,\"MOSKVICH\":56,\n",
        "                                                     \"MASERATI\":57, \"FERRARI\":58,\"SAAB\":59,\"LAMBORGHINI\":60,\"PONTIAC\":61,\"SATURN\":62,\"ASTON MARTIN\":63})\n"
      ],
      "metadata": {
        "id": "y270nIi73Or1"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove \"KM\"\n",
        "data[\"Mileage\"] = data[\"Mileage\"].str.replace(\"km\",\"\")\n",
        "data[\"Mileage\"] = data[\"Mileage\"].astype(float)"
      ],
      "metadata": {
        "id": "QDm5L0ceoDwP"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Category\"] = data[\"Category\"].replace({\"Jeep\":1, \"Hatchback\":2,\"Sedan\":3,\"Microbus\":4,\"Goods wagon\":5,\"Universal\":6,\"Coupe\":7,\n",
        "                                             \"Minivan\":8, \"Cabriolet\":9,\"Limousine\":10,\"Pickup\":11})"
      ],
      "metadata": {
        "id": "w69zpvwzBIOh"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data[\"Color\"] = data[\"Color\"].replace({\"Silver\":1, \"Black\":2,\"White\":3,\"Grey\":4,\"Blue\":5,\"Green\":6,\"Red\":7,\n",
        "#                                                      \"Sky blue\":8, \"Orange\":9,\"Yellow\":10,\"Golden\":11,\"Beige\":12,\"Brown\":13,\"Carnelian red\":14,\n",
        "#                                                      \"Purple\":15, \"Pink\":16})\n",
        "\n",
        "# data = pd.get_dummies(data, columns=[\"Color\"])\n",
        "\n",
        "\n",
        "data = data.drop('Color', axis=1)"
      ],
      "metadata": {
        "id": "FAqu17dBCMXJ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"Drive wheels\"] = data[\"Drive wheels\"].replace({\"4x4\":1, \"Front\":2,\"Rear\":3})"
      ],
      "metadata": {
        "id": "zQ8CH2hhDfBa"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the encoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the \"Model\" feature\n",
        "encoder.fit(data[\"Model\"])\n",
        "\n",
        "# Transform the \"Model\" feature to numeric\n",
        "data[\"Model\"] = encoder.transform(data[\"Model\"])\n",
        "\n",
        "\n",
        "# Initialize the encoder\n",
        "encoder1 = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the \"Model\" feature\n",
        "encoder1.fit(data[\"Manufacturer\"])\n",
        "\n",
        "# Transform the \"Model\" feature to numeric\n",
        "data[\"Manufacturer\"] = encoder1.transform(data[\"Manufacturer\"])\n"
      ],
      "metadata": {
        "id": "app2xqxfszs-"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cat_types = data[\"Manufacturer\"].unique()\n",
        "# p = 0\n",
        "# for c in Cat_types:\n",
        "#     p += 1  \n",
        "#     print(p,c)"
      ],
      "metadata": {
        "id": "qO-FIha7A4e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assign each value of the \"Model\" column with the integer value of the corresponding \"Manufacturer\"\n",
        "# data[\"Model_enc\"] = data[\"Manufacturer\"]\n"
      ],
      "metadata": {
        "id": "7a5d314wl2Pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP1yYYHUHytI",
        "outputId": "82df13f5-3130-46be-a419-e8c721c20d36"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manufacturer             0.0\n",
            "Model                 1228.0\n",
            "Prod. year            2010.0\n",
            "Category                 1.0\n",
            "Leather interior         1.0\n",
            "Fuel type                1.0\n",
            "Mileage             186005.0\n",
            "Cylinders                6.0\n",
            "Gear box type            1.0\n",
            "Drive wheels             1.0\n",
            "Doors                    4.0\n",
            "Airbags                 12.0\n",
            "Price                14727.0\n",
            "Name: 0, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vPK1p5-W52O",
        "outputId": "90788919-ad3d-4350-950f-38fadc5e21e2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Manufacturer', 'Model', 'Prod. year', 'Category', 'Leather interior',\n",
              "       'Fuel type', 'Mileage', 'Cylinders', 'Gear box type', 'Drive wheels',\n",
              "       'Doors', 'Airbags', 'Price'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the features and labels\n",
        "X = data.drop(\"Price\", axis=1)\n",
        "y = data[\"Price\"]\n",
        "\n",
        "class CarPriceEstimator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CarPriceEstimator, self).__init__()\n",
        "        self.layer1 = nn.Linear(12, 60)\n",
        "        self.layer2 = nn.Linear(60, 30)\n",
        "        # self.layer3 = nn.Linear(150, 65)\n",
        "        # self.layer4 = nn.Linear(65, 30)\n",
        "        self.output_layer = nn.Linear(30, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        # x = torch.relu(self.layer3(x))\n",
        "        # x = torch.tanh(self.layer4(x))\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# normalize data \n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "# Convert data to Pytorch tensors\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "y_train = torch.from_numpy(y_train).float()\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "y_val = torch.from_numpy(y_val).float()\n",
        "X_test = torch.from_numpy(X_test).float()\n",
        "y_test = torch.from_numpy(y_test).float()\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "model = CarPriceEstimator()\n",
        "\n",
        "# define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
        "\n",
        "# train the model\n",
        "for epoch in range(1500):\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass\n",
        "    y_pred = model(X_train)\n",
        "    # compute the loss\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    # backward pass and optimize\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if epoch % 100 == 0:\n",
        "        print(f'Epoch {epoch}/1500: Loss = {loss.item()}')\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_val_pred = model(X_val)\n",
        "    val_loss = criterion(y_val_pred, y_val)    \n",
        "\n",
        "    print(\"validation loss:\", val_loss.item())\n",
        "\n",
        "    y_test_pred = model(X_test)\n",
        "    test_loss = criterion(y_test_pred, y_test)\n",
        "\n",
        "    print(\"test loss:\", test_loss.item())\n",
        "\n",
        "    y_pred = model(X_test)\n",
        "    y_pred = y_pred.numpy()\n",
        "\n",
        "    y_pred = scaler.inverse_transform(y_pred)\n",
        "\n",
        "    print(y_pred)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test)\n",
        "    y_pred = y_pred.numpy()\n",
        "    y_pred = scaler.inverse_transform(y_pred)\n",
        "    print(y_pred)\n",
        "\n",
        "torch.save(model.state_dict(), 'CarPriceEstimator.pt')\n",
        "\n",
        "loaded_model = CarPriceEstimator()\n",
        "loaded_model.load_state_dict(torch.load('CarPriceEstimator.pt'))\n",
        "loaded_model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = loaded_model(X_test)\n",
        "    y_pred = y_pred.numpy()\n",
        "    y_pred = scaler.inverse_transform(y_pred)\n",
        "    print(y_pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGbHdp9iX5yg",
        "outputId": "70eb11ca-0cb8-4d87-a9b1-3dc5579e2eee"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/1500: Loss = 1.461273431777954\n",
            "Epoch 100/1500: Loss = 1.421727180480957\n",
            "Epoch 200/1500: Loss = 1.418884515762329\n",
            "Epoch 300/1500: Loss = 1.417140245437622\n",
            "Epoch 400/1500: Loss = 1.415951132774353\n",
            "Epoch 500/1500: Loss = 1.414917230606079\n",
            "Epoch 600/1500: Loss = 1.4139519929885864\n",
            "Epoch 700/1500: Loss = 1.4129970073699951\n",
            "Epoch 800/1500: Loss = 1.4120222330093384\n",
            "Epoch 900/1500: Loss = 1.4109830856323242\n",
            "Epoch 1000/1500: Loss = 1.40981924533844\n",
            "Epoch 1100/1500: Loss = 1.408625602722168\n",
            "Epoch 1200/1500: Loss = 1.407446026802063\n",
            "Epoch 1300/1500: Loss = 1.4060487747192383\n",
            "Epoch 1400/1500: Loss = 1.4047377109527588\n",
            "validation loss: 0.014612083323299885\n",
            "test loss: 0.02423796057701111\n",
            "[[25306.705]\n",
            " [ 9852.696]\n",
            " [29330.906]\n",
            " ...\n",
            " [ 4532.311]\n",
            " [12758.143]\n",
            " [17486.55 ]]\n",
            "[[25306.705]\n",
            " [ 9852.696]\n",
            " [29330.906]\n",
            " ...\n",
            " [ 4532.311]\n",
            " [12758.143]\n",
            " [17486.55 ]]\n",
            "[[25306.705]\n",
            " [ 9852.696]\n",
            " [29330.906]\n",
            " ...\n",
            " [ 4532.311]\n",
            " [12758.143]\n",
            " [17486.55 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "\n",
        "# # Save the scaler\n",
        "# with open('scaler.pkl', 'wb') as f:\n",
        "#     pickle.dump(scaler, f)\n",
        "\n",
        "# # Load the scaler\n",
        "# with open('scaler.pkl', 'rb') as f:\n",
        "#     scaler = pickle.load(f)\n",
        "\n",
        "# test_data = X.iloc[1246]\n",
        "# test_data = scaler.transform(np.array(test_data).reshape(1,-1))\n",
        "# test_data = torch.from_numpy(test_data).float()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "lU5YVYH9MxTG",
        "outputId": "e2b532b6-268f-4b94-9010-383171b5da82"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-445e730a4bd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1246\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pickle\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# # Load the scaler\n",
        "# with open('scaler.pkl', 'rb') as f:\n",
        "#     scaler = pickle.load(f)\n",
        "\n",
        "# # load the model\n",
        "# loaded_model = CarPriceEstimator()\n",
        "# loaded_model.load_state_dict(torch.load('CarPriceEstimator.pt'))\n",
        "# loaded_model.eval()\n",
        "\n",
        "# # Scale and normalize the test data\n",
        "# test_data = X.iloc[1246]\n",
        "# test_data = np.array(test_data).reshape(1, -1)\n",
        "# test_data = scaler.transform(test_data)\n",
        "# test_data = torch.from_numpy(test_data).float()\n",
        "\n",
        "# # Make the prediction\n",
        "# with torch.no_grad():\n",
        "#     output = loaded_model(test_data)\n",
        "\n",
        "# # Inverse-transform the output to get the final prediction in the original scale\n",
        "# prediction = scaler.inverse_transform(output.numpy().reshape(-1, 1))\n",
        "# print(prediction)\n"
      ],
      "metadata": {
        "id": "gQvZQsuOVo3X"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(untrained_example):\n",
        "    # Scale the untrained example\n",
        "    example = scaler.transform(np.array(untrained_example).reshape(1, -1))\n",
        "    # Convert to Pytorch tensor\n",
        "    example = torch.from_numpy(example).float()\n",
        "    # Pass through the trained model to make a prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(example)\n",
        "    # Inverse-transform the output to get the final prediction in the original scale\n",
        "    prediction = scaler.inverse_transform(output.numpy())\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "9PA_KCEkTXi7"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Make the prediction\n",
        "loaded_model = CarPriceEstimator()\n",
        "loaded_model.load_state_dict(torch.load('CarPriceEstimator.pt'))\n",
        "loaded_model.eval()\n",
        "output = loaded_model.predict(test_data)\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "pAwCzBwfT4q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = CarPriceEstimator()\n",
        "loaded_model.load_state_dict(torch.load('CarPriceEstimator.pt'))\n",
        "loaded_model.eval()\n",
        "\n",
        "test_data = ... # some data you want to predict on\n",
        "output = predict(test_data)\n",
        "print(output)\n"
      ],
      "metadata": {
        "id": "CJVG_e_eTaLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------------"
      ],
      "metadata": {
        "id": "_9hbtYK8TU4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEt44AeB5y_g",
        "outputId": "1c9d5ed2-2fba-479a-b79b-88e4c4c46ba8"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CarPriceEstimator(\n",
              "  (layer1): Linear(in_features=12, out_features=60, bias=True)\n",
              "  (layer2): Linear(in_features=60, out_features=30, bias=True)\n",
              "  (output_layer): Linear(in_features=30, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the car prices\n",
        "with torch.no_grad():\n",
        "    y_pred = model(X_test[:5])\n",
        "    y_pred = y_pred.numpy()\n",
        "    y_pred = scaler.inverse_transform(y_pred)\n",
        "    print(y_pred)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDhYq-mreiTE",
        "outputId": "e3dcfeb3-28ed-45c1-a1a9-a1d793b4e510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[17164.734]\n",
            " [19937.605]\n",
            " [18788.215]\n",
            " [23920.457]\n",
            " [17113.928]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "------------------------NOT WORKING------------------------"
      ],
      "metadata": {
        "id": "WxAw9MoeX42D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers.optimizer_v2 import gradient_descent\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Define the features and labels\n",
        "X = data.drop(\"Price\", axis=1)\n",
        "\n",
        "\n",
        "y = data[\"Price\"]\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# from sklearn.preprocessing import QuantileTransformer\n",
        "# scaler = QuantileTransformer(output_distribution='normal')\n",
        "# y = scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# y = scaler.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Split the data into training and test sets\n",
        "X_train, X_val_and_test, y_train, y_val_and_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_and_test, y_val_and_test, test_size=0.5, random_state=42)\n",
        "\n",
        "\n",
        "# Convert data to Pytorch tensors\n",
        "X_train = torch.from_numpy(X_train).float()\n",
        "y_train = torch.from_numpy(y_train.values).float().reshape(-1,1)\n",
        "X_val = torch.from_numpy(X_val).float()\n",
        "y_val = torch.from_numpy(y_val.values).float().reshape(-1,1)\n",
        "X_test = torch.from_numpy(X_test).float()\n",
        "y_test = torch.from_numpy(y_test.values).float().reshape(-1,1)\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------------------\n",
        "# # Normalizing \n",
        "# tf.keras.layers.Normalization(\n",
        "#     axis=-1, mean=None, variance=None, invert=False)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = Sequential([\n",
        "    # keras.layers.Reshape(target_shape=(29 * 28,), input_shape=(28, 28)),\n",
        "    Dense(units=12, activation='relu'),\n",
        "    Dense(units=60, activation='relu'),\n",
        "    Dense(units=120, activation='relu'),\n",
        "    Dense(units=120, activation='relu'),\n",
        "    Dense(units=60, activation='relu'),\n",
        "    Dense(units=1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "from keras.optimizers import Adagrad\n",
        "optimizer = Adagrad(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
        "\n",
        "# model.compile(optimizer='adam',loss='mean_squared_error')\n",
        "\n",
        "# ---------------------------------------------------------------------------------------------------------------\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "class CarPriceEstimator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CarPriceEstimator, self).__init__()\n",
        "        self.layer1 = nn.Linear(12, 60)\n",
        "        self.layer2 = nn.Linear(60, 120)\n",
        "        self.layer3 = nn.Linear(120, 60)\n",
        "        self.output_layer = nn.Linear(60, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.layer1(x))\n",
        "        x = torch.relu(self.layer2(x))\n",
        "        x = torch.relu(self.layer3(x))\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# instantiate the model\n",
        "model = CarPriceEstimator()\n",
        "\n",
        "# define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# train the model\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass\n",
        "    y_pred = model(X_train)\n",
        "    # compute the loss\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    # backward pass and optimize\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qv7kVLdn5cO7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "d374128f-a8a6-4ecc-e647-625c1049429f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7e5b85673410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;31m# compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-7e5b85673410>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y.mean()\n",
        "X.mean()\n",
        "# y.std()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpJhfgP2DqHH",
        "outputId": "d6412a81-30af-49b4-f5c3-4c0d83c75fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3454137448806673e-15"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = X_train\n",
        "print(num_features)"
      ],
      "metadata": {
        "id": "aP9EccQ0A4Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build((12958, 12))\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJiYlXFZyVCX",
        "outputId": "4c0c44ba-df30-465c-adc6-589d858cc1b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (12958, 12)               156       \n",
            "                                                                 \n",
            " dense_31 (Dense)            (12958, 60)               780       \n",
            "                                                                 \n",
            " dense_32 (Dense)            (12958, 120)              7320      \n",
            "                                                                 \n",
            " dense_33 (Dense)            (12958, 120)              14520     \n",
            "                                                                 \n",
            " dense_34 (Dense)            (12958, 60)               7260      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (12958, 1)                61        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,097\n",
            "Trainable params: 30,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training data\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "id": "sIaA8LIC5cGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "Uqz_qitMRRzI",
        "outputId": "1044429b-d419-4cb2-9637-be3a0904307f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-fad05de2bff3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model on the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict() got multiple values for argument 'batch_size'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " -----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ],
      "metadata": {
        "id": "8N8C06PIC7Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOT WORKING\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "# Split the data into features (inputs) and target (output)\n",
        "X = data.drop('Price', axis=1)\n",
        "y = data['Price'].astype('float32')\n",
        "\n",
        "\n",
        "# Normalize the input features\n",
        "X_num = X.select_dtypes(include=['float', 'int'])\n",
        "X_num = (X_num - X_num.mean()) / X_num.std()\n",
        "\n",
        "# Shuffle the data\n",
        "X_num, y = shuffle(X_num, y, random_state=42)\n",
        "\n",
        "# Split the data into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_num, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "#Define the model\n",
        "model = Sequential()\n",
        "\n",
        "#Add layers to the model\n",
        "model.add(Dense(32, input_dim=X_num.shape[1], activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    return K.sqrt(K.mean(K.square(y_pred - y_true)))\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss=root_mean_squared_error)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "test_loss = test_loss.ravel()[0]\n",
        "print('Test loss:', test_loss)\n",
        "\n",
        "# Save the model\n",
        "model.save('used_car_price_model.h5')\n",
        "\n",
        "# Save the training history\n",
        "import pickle\n",
        "with open('used_car_price_history', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n"
      ],
      "metadata": {
        "id": "pjY9KyfXQgNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ALL THE CODE \n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "tf.keras.backend.set_floatx('float32')\n",
        "\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('/content/drive/MyDrive/car_price_prediction.csv')\n",
        "\n",
        "# drop rows where the price is less than 100\n",
        "data = data[data['Price'] >= 100]\n",
        "data = data[~data['Model'].isin([\"GONOW\",\"IVECO DAYLY\"])]\n",
        "\n",
        "\n",
        "\n",
        "# Drop the totalPrice column\n",
        "data = data.drop('totalPrice', axis=1)\n",
        "data = data.drop('Wheel', axis=1)\n",
        "data = data.drop('no-tax', axis=1)\n",
        "data = data.drop('Engine volume', axis=1)\n",
        "data['Doors'] = data['Doors'].replace({'-May':'','-Mar':''}, regex=True)\n",
        "data['Doors'] = data['Doors'].str.replace('>5','5')\n",
        "\n",
        "# Drop rows with missing or empty values in the \"Doors\" column\n",
        "data = data[data['Doors'].str.strip() !='']\n",
        "data['Doors'] = data['Doors'].astype(int)\n",
        "\n",
        "data['Doors'] = data['Doors'].astype(int)\n",
        "\n",
        "# Gear box editing\n",
        "data['Gear box type'] = data['Gear box type'].replace({'Automatic': 1, 'Tiptronic': 2,'Variator':3, 'Manual':4})\n",
        "data = data[data['Gear box type'].isin([1,2,3,4])]\n",
        "\n",
        "data[\"Gear box type\"] = data[\"Gear box type\"].astype(int)\n",
        "\n",
        "# 'Automatic' is changed to 1\n",
        "# 'Tiptronic' is changed to 2\n",
        "# 'Variator' is changed to 3\n",
        "# 'Manual' is changed to 4\n",
        "\n",
        "\n",
        "# Replace values in the \"Leather interior\" column based on conditions\n",
        "data[\"Leather interior\"] = data[\"Leather interior\"].replace({\"Yes\": 1, \"No\": 0}) # Yes is 1; No is 0\n",
        "# keep the rows where the value of \"Leather interior\" is 0 or 1\n",
        "data = data[data[\"Leather interior\"].apply(lambda x: x in [0, 1])]\n",
        "\n",
        "\n",
        "# fuel type edit\n",
        "data[\"Fuel type\"] = data[\"Fuel type\"].replace({\"Hybrid\":1, \"Petrol\":2,\"Diesel\":3,\"CNG\":4,\"Plug-in Hybrid\":5,\"LPG\":6,\"Hydrogen\":7})\n",
        "allowed_fuel_types = [1, 2, 3, 4, 5, 6, 7]\n",
        "data = data[data[\"Fuel type\"].apply(lambda x: x in allowed_fuel_types)]\n",
        "\n",
        "# 'Hybrid' is changed to 1,\n",
        "# 'Petrol' is changed to 2, \n",
        "# 'Diesel' is changed to 3, \n",
        "# 'CNG' is changed to 4, \n",
        "# 'Plug-in Hybrid' is changed to 5, \n",
        "# 'LPG' is changed to 6,\n",
        "# 'Hydrogen' is changed to 7\n",
        "\n",
        "# Mapping\n",
        "\n",
        "data[\"Manufacturer\"] = data[\"Manufacturer\"].replace({\"LEXUS\":1, \"CHEVROLET\":2,\"GREATWALL\":3,\"HONDA\":4,\"FORD\":5,\"HYUNDAI\":6,\"TOYOTA\":7,\n",
        "                                                     \"MERCEDES-BENZ\":8, \"OPEL\":9,\"PORSCHE\":10,\"BMW\":11,\"JEEP\":12,\"VOLKSWAGEN\":13,\"AUDI\":14,\n",
        "                                                     \"RENAULT\":15, \"NISSAN\":16,\"SUBARU\":17,\"DAEWOO\":18,\"KIA\":19,\"MITSUBISHI\":20,\"SSANGYONG\":21,\n",
        "                                                     \"MAZDA\":22, \"GMC\":23,\"FIAT\":24,\"INFINITI\":25,\"ALFA ROMEO\":26,\"SUZUKI\":27,\"ACURA\":28,\n",
        "                                                     \"LINCOLN\":29, \"VAZ\":30,\"GAZ\":31,\"CITROEN\":32,\"LAND ROVER\":33,\"MINI\":34,\"DODGE\":35,\n",
        "                                                     \"CHRYSLER\":36, \"JAGUAR\":37,\"ISUZU\":38,\"SKODA\":39,\"DAIHATSU\":40,\"BUICK\":41,\"TESLA\":42,\n",
        "                                                     \"CADILLAC\":43, \"PEUGEOT\":44,\"BENTLEY\":45,\"VOLVO\":46,\"HAVAL\":47,\"HUMMER\":48,\"SCION\":49,\n",
        "                                                     \"UAZ\":50, \"MERCURY\":51,\"ZAZ\":52,\"ROVER\":53,\"SEAT\":54,\"LANCIA\":55,\"MOSKVICH\":56,\n",
        "                                                     \"MASERATI\":57, \"FERRARI\":58,\"SAAB\":59,\"LAMBORGHINI\":60,\"PONTIAC\":61,\"SATURN\":62,\"ASTON MARTIN\":63})\n",
        "\n",
        "# Remove \"KM\"\n",
        "data[\"Mileage\"] = data[\"Mileage\"].str.replace(\"km\",\"\")\n",
        "data[\"Mileage\"] = data[\"Mileage\"].astype(float)\n",
        "\n",
        "data[\"Category\"] = data[\"Category\"].replace({\"Jeep\":1, \"Hatchback\":2,\"Sedan\":3,\"Microbus\":4,\"Goods wagon\":5,\"Universal\":6,\"Coupe\":7,\n",
        "                                             \"Minivan\":8, \"Cabriolet\":9,\"Limousine\":10,\"Pickup\":11})\n",
        "\n",
        "data[\"Color\"] = data[\"Color\"].replace({\"Silver\":1, \"Black\":2,\"White\":3,\"Grey\":4,\"Blue\":5,\"Green\":6,\"Red\":7,\n",
        "                                                     \"Sky blue\":8, \"Orange\":9,\"Yellow\":10,\"Golden\":11,\"Beige\":12,\"Brown\":13,\"Carnelian red\":14,\n",
        "                                                     \"Purple\":15, \"Pink\":16})\n",
        "\n",
        "data = pd.get_dummies(data, columns=[\"Color\"])\n",
        "\n",
        "data[\"Drive wheels\"] = data[\"Drive wheels\"].replace({\"4x4\":1, \"Front\":2,\"Rear\":3})\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the encoder\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the \"Model\" feature\n",
        "encoder.fit(data[\"Model\"])\n",
        "\n",
        "# Transform the \"Model\" feature to numeric\n",
        "data[\"Model\"] = encoder.transform(data[\"Model\"])\n"
      ],
      "metadata": {
        "id": "ctxi3-Fdw_pO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}